---
title: GPU Compiler Optimization Pass
date: 2024-05-08
permalink: /pages/45893/
---

1. Compiler Assisted Hybrid Implicit and Explicit GPU Memory Management under Unified Address Space
2. NUBA: Non-Uniform Bandwidth GPUs

---
## 1. Compiler Assisted Hybrid Implicit and Explicit GPU Memory Management under Unified Address Space

A compiler-runtime collaborative approach which requires no effort from application developers.

The compiler is responsible for analyzing high level data access behavior, while the runtime takes into account both dynamic execution status and the static information provided by the compiler to optimize data mapping and movement.

Unlike previous memory management proposals that rely heavily on the runtime or OS, our schemes have much lower execution overhead because most of the analysis is performed at compile time.

### Case Study
- Prefetching removes GPU page fault overhead effectively
- Unified memory helps avoid unnecessary data movement for irregular memory access patterns
- Data thrashing harms performance significantly for workloads that exceed the GPU memory capacity
- Pinning data to the CPU memory achieves reasonable performance for all workloads

### Target Reuse Distance

Ihe target reuse distance is measured in terms of the number of target regions encountered between two adjacent uses of the same data object, in order to simplify compiler analysis.

Its key idea is to preferentially keep data objects that will be reused sooner (i.e., have shorter reuse distance) in GPU memory. I

Given its reuse distance, the next reuse time of a data object can be predicted at a target region invocation.

To achieve this, first, a global timer target region counter (TRC) is employed by the runtime to keep track of the number of target regions that it has encountered so far, as the representation of the current “time”.

We employ a GPU object table (GOT) to track these objects. GOT also records other useful information related to such objects, such as locality per target region and global locality.

![image](https://github.com/user-attachments/assets/98005067-c960-4662-af1a-9e82c54c506a)


### Data Locality in a Single Target Region

The locality of a data object in one target region, a.k.a, regional locality, is the key information required by RLM.

In the LLVM IR, all memory objects are accessed through load and store instructions.

Therefore we can evaluate the regional locality of a data object by estimating the execution frequency of all related load and store instructions in a certain target region.

The existing LLVM pass **BlockFrequencyInfo** can help achieve this purpose. *It statically analyzes the execution frequency of every basic block based on the branch taken probability.*

*We enhance this pass to improve its accuracy by leveraging GPU specific information, for instance, each loop iteration is executed by exactly one GPU thread.*

The execution frequency of a load/store instruction is equal to that of its parent basic block.

Through pointer chasing that starts from the argument of a target region, all memory access instructions related to an object can be found.

By accumulating the execution frequency of these instructions, the regional locality of a data object is calculated.

---

## 2. NUBA: Non-Uniform Bandwidth GPUs

### Compiler Analysis and Runtime Support
In prior work, the compiler employs data flow analysis at the PTX intermediate code level to identify accesses to read-only data structures within a kernel boundary.

If a data structure is never written to within a kernel, it is marked as read-only; otherwise, it is marked as read-write.

Note that a data structure marked as read-only in one GPU kernel can be read-write in another kernel, e.g., the output of one kernel can serve as input to another kernel.

Load operations accessing read-only data structures using the **ld.global instruction** are then replaced by a newly introduced **ld.global.ro** instruction, indicating to hardware that these instructions operate on read-only data that can be replicated.

To differentiate requests to read-only and read-write shared data at runtime, the instruction decoder in hardware, upon decoding an ld.global.ro instruction adds a read-only bit to the memory request metadata which MDR uses to **identify candidates for replication**. 

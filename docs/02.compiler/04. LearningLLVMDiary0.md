---
title: Learning LLVM Notes
date: 2023-11-21
permalink: /pages/000004/
---

#### 1. Difference between ISelDAGToDAG and ISelLowering

In LLVM's backend, ISelLowering and ISelDAGToDAG are two important classes that play different roles in the instruction selection process. Here's the difference between them and the phases in which they are called:


***ISelLowering***

* Role: ISelLowering stands for "Instruction Selection Lowering". This class provides target-specific information and handling for aspects of instruction selection during the Selection DAG Construction phase.

* Phase: ISelLowering is called during the "Selection DAG Construction" phase of the compiler backend. This phase transforms the generic LLVM IR into a machine-independent representation, the Selection DAG.

* Functions: In ISelLowering, you will find functions that define how LLVM IR operations are translated into target-specific instructions. This includes custom lowering of specific LLVM IR operations, defining patterns for converting LLVM IR to target nodes, and providing information about target-specific features and constraints.

Typical Functions:

```
LowerCall: Lower calls to target-specific calling conventions.
LowerReturn: Lower return instructions to target-specific sequences.
EmitInstrWithCustomInserter: Handle target-specific instructions with custom insertion logic.
getTargetNodeName: Provide human-readable names for target nodes.
```

***ISelDAGToDAG***
* Role: ISelDAGToDAG stands for "Instruction Selection DAG to DAG". This class is responsible for translating the Selection DAG (Directed Acyclic Graph) into a sequence of target-specific instructions.

* Phase: ISelDAGToDAG is called during the "Instruction Selection" phase of the compiler backend. This phase comes after the DAG Legalization phase and before Register Allocation.

* Functions: In ISelDAGToDAG, you will find functions like Select, which is responsible for selecting target instructions for each node in the DAG.

Typical Functions:
```
Select: Select target instructions for nodes in the DAG.
SelectNode: Implement target-specific node selection.
PreprocessISelDAG: Prepare for instruction selection.
PostprocessISelDAG: Clean up after instruction selection.
```


***Phases in Summary***

* Selection DAG Construction:

  - ISelLowering is called during this phase.
  - This phase transforms the generic LLVM IR into a machine-independent representation (the Selection DAG).
  - Functions in ISelLowering handle how LLVM IR operations are translated into target-specific instructions.

* DAG Legalization:

  - Various transformations to ensure DAG conforms to target-specific constraints.
  - Typically, no specific user-defined classes are involved in this phase.

* Instruction Selection (ISelDAGToDAG):

  - ISelDAGToDAG is called during this phase.
  - Translates the Selection DAG into a sequence of target-specific instructions.
  - Functions in ISelDAGToDAG handle how DAG nodes are selected and transformed into machine instructions.

* Register Allocation:

  - Assigns virtual registers to physical registers.
  - Ensures that the generated code does not use more registers than available.

* Frame Lowering:

  - Manages the function's stack frame.
  - Sets up the stack frame, manages the frame pointer, and handles stack frame operations.

* Prologue and Epilogue Emission:

  - Generates the machine code for the function's entry and exit sequences.
  - Includes setting up the stack frame, saving/restoring callee-saved registers, etc.

In summary, ISelLowering is called during the Selection DAG Construction phase to handle translation of LLVM IR to target-specific instructions.\
ISelDAGToDAG is called during the Instruction Selection phase to translate the Selection DAG to a sequence of target-specific instructions.\
These phases work together to convert the LLVM IR into machine code for the target architecture.

---

#### 2. Analysis Pass and Tranform Pass

***Analysis Passes in LLVM:***

* Purpose:
 - Analysis passes in LLVM are used to gather information about the program without modifying it.
 - They analyze the program's code structure, control flow, data flow, and other properties.
 - This information is used by subsequent optimization passes to make informed decisions.

* Characteristics:
  - Do not modify the program.
  - Collect information about the program.
  - Used by other passes to guide optimizations.
  - Typically run early in the optimization pipeline.

* Major Analysis Passes:

  - DominatorTree Analysis:
  
    - Computes the dominator tree for a function.
    - Helps in various optimizations such as loop optimization, control flow analysis, etc.

  - LoopInfo Analysis:
  
    - Provides information about loops in a function.
    - Used by loop optimization passes for loop transformations.

  - ScalarEvolution Analysis:
    
    - Analyzes and characterizes scalar expressions in loops.
    - Helps in loop transformations like loop unrolling, loop vectorization, etc.

  - MemorySSA Analysis:
    
    - Provides a memory SSA representation of the program.
    - Used in optimizations related to memory access analysis, alias analysis, etc.

  - AliasAnalysis Analysis:
    
    - Determines the aliasing relationship between memory accesses.
    - Helps in optimizations that depend on memory aliasing information.

***Transform Passes in LLVM:***
* Purpose:
Transform passes in LLVM modify the program's IR to improve its performance or reduce its size.
They apply optimizations and transformations to the code.
* Characteristics:
  - Modify the program's IR.
  - Apply optimizations and transformations.
  - Can introduce new code or modify existing code.
  - Typically run after analysis passes.
  
* Major Transform Passes:
  
  - Instruction Combining:
  
    - Combines multiple instructions into simpler forms.
    - Reduces the number of instructions and improves code readability.
  
  - Dead Code Elimination:
    
    - Removes code that is guaranteed to have no effect on program output.
    - Improves code size and execution speed.
  
  - Loop Unrolling:
  
    - Duplicates the loop body multiple times to reduce loop overhead.
    - Improves instruction-level parallelism.
  
  - Function Inlining:
    - Replaces a function call with the body of the called function.
    - Reduces function call overhead and enables further optimizations.
  
  - Constant Propagation:
    - Propagates constant values through the program.
    - Enables further optimizations by replacing variables with constants.
  
  - Vectorization (Loop Vectorization):
    - Converts scalar operations in loops into SIMD (Single Instruction, Multiple Data) operations.
    - Improves performance by exploiting parallelism in hardware.
  
  - SROA (Scalar Replacement of Aggregates):
    - Breaks down aggregates (like structs) into individual scalar variables.
    - Improves optimization opportunities by working on individual scalar variables.
  
***Summary:***
* Analysis Passes:
  - Gather information about the program.
  - Do not modify the program.
  - Used by other passes for optimizations.
  - Examples: DominatorTree, LoopInfo, ScalarEvolution, MemorySSA, AliasAnalysis.
* Transform Passes:
  - Modify the program's IR.
  - Apply optimizations and transformations.
  - Examples: Instruction Combining, Dead Code Elimination, Loop Unrolling, Function Inlining, Constant Propagation, Vectorization, SROA (Scalar Replacement of Aggregates).
These are just a few examples of major analysis and transform passes in LLVM. The LLVM infrastructure provides a wide range of passes for various optimizations and analyses, allowing users to construct custom optimization pipelines tailored to their specific needs.

---

### 3. Knowledge Fragments

1. ***SROA is claimed to replace mem2reg.*** <br>
[discourse.llvm](https://discourse.llvm.org/t/llvm-ir-after-mem2reg-optimisation/63682)

2. ***Alias Analysis*** <br>
Alias Analysis (aka Pointer Analysis) is a class of techniques which attempt to determine whether or not two pointers ever can point to the same object in memory.<br>
Traditionally, alias analyses respond to a query with a Must, May, or No alias response, indicating that two pointers always point to the same object, might point to the same object, or are known to never point to the same object.<br>

3. ***RISCV Instruction Set Might deserves further explore.*** <br>
  [Berkely RISCV Instruction Set Manual](https://www2.eecs.berkeley.edu/Pubs/TechRpts/2015/EECS-2015-209.pdf) <br>

4. ***How LLVM Optimizes a Function*** <br>
   [How LLVM Optimizes a Function](https://blog.regehr.org/archives/1603) <br>
   This blog trace through different passes in llvm IR.<br>
6. ***CambridgeSlides*** <br>
   [Cambridge Modern Compiler Design](https://www.cl.cam.ac.uk/teaching/1617/L25/materials.html)
   * Introduction
   * Modern intermediate representations
   * LLVM IR and transform pipeline
   * Modern processor architectures
   * Dynamic dispatch and duck typing
   * Autovectorisation
   * Garbage collection
   * JIT Compilation
   

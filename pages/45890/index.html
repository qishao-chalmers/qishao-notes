<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>GPU Insturctions | CPU &amp; GPU Microarch. Qi Shao</title>
    <meta name="generator" content="VuePress 1.8.0">
    <link rel="stylesheet" href="custom.css">
    <script language="javascript" type="text/javascript" src="/qishao-notes/js/pgmanor-self.js"></script>
    <meta name="description" content="Computer System">
    <meta name="google-site-verification" content="66w5U9NY5gJWu7iBtHKMbhpXkV94jy31L_RHbvrZZzY">
    <meta name="keywords" content="Hitqishao,golang,vue,go-web,go-admin,go-ldap-admin">
    <meta name="theme-color" content="#11a8cd">
    <meta name="referrer" content="no-referrer-when-downgrade">
    
    <link rel="preload" href="/qishao-notes/assets/css/0.styles.922e50b3.css" as="style"><link rel="preload" href="/qishao-notes/assets/js/app.d6e24f61.js" as="script"><link rel="preload" href="/qishao-notes/assets/js/2.6d8a25ce.js" as="script"><link rel="preload" href="/qishao-notes/assets/js/76.55fb1852.js" as="script"><link rel="prefetch" href="/qishao-notes/assets/js/10.c53d023c.js"><link rel="prefetch" href="/qishao-notes/assets/js/100.a6846821.js"><link rel="prefetch" href="/qishao-notes/assets/js/101.d2879d9e.js"><link rel="prefetch" href="/qishao-notes/assets/js/102.8905e2e7.js"><link rel="prefetch" href="/qishao-notes/assets/js/103.66edd4a4.js"><link rel="prefetch" href="/qishao-notes/assets/js/104.f8220e22.js"><link rel="prefetch" href="/qishao-notes/assets/js/105.3d477ce6.js"><link rel="prefetch" href="/qishao-notes/assets/js/106.68726083.js"><link rel="prefetch" href="/qishao-notes/assets/js/107.5827ba3f.js"><link rel="prefetch" href="/qishao-notes/assets/js/108.4e8c64cb.js"><link rel="prefetch" href="/qishao-notes/assets/js/109.deb9a6dc.js"><link rel="prefetch" href="/qishao-notes/assets/js/11.b6f7d42d.js"><link rel="prefetch" href="/qishao-notes/assets/js/110.38867d9e.js"><link rel="prefetch" href="/qishao-notes/assets/js/111.ab388248.js"><link rel="prefetch" href="/qishao-notes/assets/js/112.a213a11f.js"><link rel="prefetch" href="/qishao-notes/assets/js/113.d67ed6e3.js"><link rel="prefetch" href="/qishao-notes/assets/js/114.aedbef92.js"><link rel="prefetch" href="/qishao-notes/assets/js/115.3f997a62.js"><link rel="prefetch" href="/qishao-notes/assets/js/116.313ed29f.js"><link rel="prefetch" href="/qishao-notes/assets/js/117.a0ff8713.js"><link rel="prefetch" href="/qishao-notes/assets/js/118.9cb83616.js"><link rel="prefetch" href="/qishao-notes/assets/js/119.6b330049.js"><link rel="prefetch" href="/qishao-notes/assets/js/12.ec184304.js"><link rel="prefetch" href="/qishao-notes/assets/js/120.ec76960f.js"><link rel="prefetch" href="/qishao-notes/assets/js/121.c8ed50ec.js"><link rel="prefetch" href="/qishao-notes/assets/js/122.3b24bc5c.js"><link rel="prefetch" href="/qishao-notes/assets/js/123.017be12d.js"><link rel="prefetch" href="/qishao-notes/assets/js/124.e086b106.js"><link rel="prefetch" href="/qishao-notes/assets/js/125.8aa1e7c3.js"><link rel="prefetch" href="/qishao-notes/assets/js/126.398ad1ae.js"><link rel="prefetch" href="/qishao-notes/assets/js/127.a5c5827e.js"><link rel="prefetch" href="/qishao-notes/assets/js/13.3f209eda.js"><link rel="prefetch" href="/qishao-notes/assets/js/14.11a9f996.js"><link rel="prefetch" href="/qishao-notes/assets/js/15.18b8bfd8.js"><link rel="prefetch" href="/qishao-notes/assets/js/16.1c803b2c.js"><link rel="prefetch" href="/qishao-notes/assets/js/17.b688542f.js"><link rel="prefetch" href="/qishao-notes/assets/js/18.ba9d4baf.js"><link rel="prefetch" href="/qishao-notes/assets/js/19.42f21f4f.js"><link rel="prefetch" href="/qishao-notes/assets/js/20.78b7313e.js"><link rel="prefetch" href="/qishao-notes/assets/js/21.49321259.js"><link rel="prefetch" href="/qishao-notes/assets/js/22.8d71df97.js"><link rel="prefetch" href="/qishao-notes/assets/js/23.53082807.js"><link rel="prefetch" href="/qishao-notes/assets/js/24.f485ff78.js"><link rel="prefetch" href="/qishao-notes/assets/js/25.18fc9823.js"><link rel="prefetch" href="/qishao-notes/assets/js/26.f10809d3.js"><link rel="prefetch" href="/qishao-notes/assets/js/27.65953f3e.js"><link rel="prefetch" href="/qishao-notes/assets/js/28.c0382aef.js"><link rel="prefetch" href="/qishao-notes/assets/js/29.21a8bb75.js"><link rel="prefetch" href="/qishao-notes/assets/js/3.a8431c6b.js"><link rel="prefetch" href="/qishao-notes/assets/js/30.c28eefd0.js"><link rel="prefetch" href="/qishao-notes/assets/js/31.141faad8.js"><link rel="prefetch" href="/qishao-notes/assets/js/32.d31e1099.js"><link rel="prefetch" href="/qishao-notes/assets/js/33.ac7b19be.js"><link rel="prefetch" href="/qishao-notes/assets/js/34.0b761d24.js"><link rel="prefetch" href="/qishao-notes/assets/js/35.6fe213dc.js"><link rel="prefetch" href="/qishao-notes/assets/js/36.fb1d1667.js"><link rel="prefetch" href="/qishao-notes/assets/js/37.c95eff2e.js"><link rel="prefetch" href="/qishao-notes/assets/js/38.d63a3d79.js"><link rel="prefetch" href="/qishao-notes/assets/js/39.fdab2a0b.js"><link rel="prefetch" href="/qishao-notes/assets/js/4.bae99c2a.js"><link rel="prefetch" href="/qishao-notes/assets/js/40.89b382c5.js"><link rel="prefetch" href="/qishao-notes/assets/js/41.ea1753be.js"><link rel="prefetch" href="/qishao-notes/assets/js/42.f70b72b4.js"><link rel="prefetch" href="/qishao-notes/assets/js/43.56a470f5.js"><link rel="prefetch" href="/qishao-notes/assets/js/44.0407cf17.js"><link rel="prefetch" href="/qishao-notes/assets/js/45.92df1709.js"><link rel="prefetch" href="/qishao-notes/assets/js/46.8538c3c9.js"><link rel="prefetch" href="/qishao-notes/assets/js/47.910ad426.js"><link rel="prefetch" href="/qishao-notes/assets/js/48.526dc690.js"><link rel="prefetch" href="/qishao-notes/assets/js/49.28e90c7e.js"><link rel="prefetch" href="/qishao-notes/assets/js/5.8b03d117.js"><link rel="prefetch" href="/qishao-notes/assets/js/50.6d6c79ff.js"><link rel="prefetch" href="/qishao-notes/assets/js/51.0995d9c1.js"><link rel="prefetch" href="/qishao-notes/assets/js/52.d8688b9f.js"><link rel="prefetch" href="/qishao-notes/assets/js/53.a9de2d3c.js"><link rel="prefetch" href="/qishao-notes/assets/js/54.27b29639.js"><link rel="prefetch" href="/qishao-notes/assets/js/55.4ce85ac1.js"><link rel="prefetch" href="/qishao-notes/assets/js/56.3e2072af.js"><link rel="prefetch" href="/qishao-notes/assets/js/57.8f4d7a26.js"><link rel="prefetch" href="/qishao-notes/assets/js/58.c8cc3baf.js"><link rel="prefetch" href="/qishao-notes/assets/js/59.861f9f7a.js"><link rel="prefetch" href="/qishao-notes/assets/js/6.f0fbf90b.js"><link rel="prefetch" href="/qishao-notes/assets/js/60.39abe135.js"><link rel="prefetch" href="/qishao-notes/assets/js/61.f32429ee.js"><link rel="prefetch" href="/qishao-notes/assets/js/62.6190f2a9.js"><link rel="prefetch" href="/qishao-notes/assets/js/63.19c15ad2.js"><link rel="prefetch" href="/qishao-notes/assets/js/64.ac00a31a.js"><link rel="prefetch" href="/qishao-notes/assets/js/65.d63f1f61.js"><link rel="prefetch" href="/qishao-notes/assets/js/66.b6e66761.js"><link rel="prefetch" href="/qishao-notes/assets/js/67.52e249a1.js"><link rel="prefetch" href="/qishao-notes/assets/js/68.65de4f52.js"><link rel="prefetch" href="/qishao-notes/assets/js/69.7d8bf00f.js"><link rel="prefetch" href="/qishao-notes/assets/js/7.1e07ff8f.js"><link rel="prefetch" href="/qishao-notes/assets/js/70.1905d6a8.js"><link rel="prefetch" href="/qishao-notes/assets/js/71.5b06b360.js"><link rel="prefetch" href="/qishao-notes/assets/js/72.bc22dca0.js"><link rel="prefetch" href="/qishao-notes/assets/js/73.3a589a2f.js"><link rel="prefetch" href="/qishao-notes/assets/js/74.8deb1a9c.js"><link rel="prefetch" href="/qishao-notes/assets/js/75.83e128af.js"><link rel="prefetch" href="/qishao-notes/assets/js/77.ccbb751a.js"><link rel="prefetch" href="/qishao-notes/assets/js/78.68538f63.js"><link rel="prefetch" href="/qishao-notes/assets/js/79.d0f19c6f.js"><link rel="prefetch" href="/qishao-notes/assets/js/8.f90e1643.js"><link rel="prefetch" href="/qishao-notes/assets/js/80.7280a683.js"><link rel="prefetch" href="/qishao-notes/assets/js/81.8c457734.js"><link rel="prefetch" href="/qishao-notes/assets/js/82.5d9b51d4.js"><link rel="prefetch" href="/qishao-notes/assets/js/83.1452152d.js"><link rel="prefetch" href="/qishao-notes/assets/js/84.6331f379.js"><link rel="prefetch" href="/qishao-notes/assets/js/85.d89f1896.js"><link rel="prefetch" href="/qishao-notes/assets/js/86.e0896c8e.js"><link rel="prefetch" href="/qishao-notes/assets/js/87.63f6bd24.js"><link rel="prefetch" href="/qishao-notes/assets/js/88.981f151e.js"><link rel="prefetch" href="/qishao-notes/assets/js/89.c94ca959.js"><link rel="prefetch" href="/qishao-notes/assets/js/9.d1b8e683.js"><link rel="prefetch" href="/qishao-notes/assets/js/90.d729ca45.js"><link rel="prefetch" href="/qishao-notes/assets/js/91.fcde5801.js"><link rel="prefetch" href="/qishao-notes/assets/js/92.8e749192.js"><link rel="prefetch" href="/qishao-notes/assets/js/93.9dfed52c.js"><link rel="prefetch" href="/qishao-notes/assets/js/94.6325628e.js"><link rel="prefetch" href="/qishao-notes/assets/js/95.4767cd75.js"><link rel="prefetch" href="/qishao-notes/assets/js/96.0a0aa512.js"><link rel="prefetch" href="/qishao-notes/assets/js/97.1f728656.js"><link rel="prefetch" href="/qishao-notes/assets/js/98.6294ae42.js"><link rel="prefetch" href="/qishao-notes/assets/js/99.71ed026c.js">
    <link rel="stylesheet" href="/qishao-notes/assets/css/0.styles.922e50b3.css">
  </head>
  <body class="theme-mode-light">
    <div id="app" data-server-rendered="true"><div class="theme-container sidebar-open have-rightmenu"><header class="navbar blur"><div title="目录" class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/qishao-notes/" class="home-link router-link-active"><!----> <span class="site-name">CPU &amp; GPU Microarch. Qi Shao</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/qishao-notes/" class="nav-link">Home</a></div><div class="nav-item"><a href="/qishao-notes/gpu/" class="nav-link">gpu</a></div><div class="nav-item"><a href="/qishao-notes/cpu/" class="nav-link">cpu</a></div><div class="nav-item"><a href="/qishao-notes/llm/" class="nav-link">ml&amp;llm</a></div><div class="nav-item"><a href="/qishao-notes/compiler/" class="nav-link">compiler</a></div><div class="nav-item"><a href="/qishao-notes/hbm/" class="nav-link">hbm</a></div><div class="nav-item"><a href="/qishao-notes/mix/" class="nav-link">program</a></div><div class="nav-item"><a href="/qishao-notes/unix/" class="nav-link">unix</a></div><div class="nav-item"><a href="https://blog.csdn.net/hit_shaoqi" target="_blank" rel="noopener noreferrer" class="nav-link external">
  CSDN
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></div> <a href="https://github.com/hitqshao/qishao-notes" target="_blank" rel="noopener noreferrer" class="repo-link">
    GitHub
    <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></nav></div></header> <div class="sidebar-mask"></div> <div class="sidebar-hover-trigger"></div> <aside class="sidebar" style="display:none;"><!----> <nav class="nav-links"><div class="nav-item"><a href="/qishao-notes/" class="nav-link">Home</a></div><div class="nav-item"><a href="/qishao-notes/gpu/" class="nav-link">gpu</a></div><div class="nav-item"><a href="/qishao-notes/cpu/" class="nav-link">cpu</a></div><div class="nav-item"><a href="/qishao-notes/llm/" class="nav-link">ml&amp;llm</a></div><div class="nav-item"><a href="/qishao-notes/compiler/" class="nav-link">compiler</a></div><div class="nav-item"><a href="/qishao-notes/hbm/" class="nav-link">hbm</a></div><div class="nav-item"><a href="/qishao-notes/mix/" class="nav-link">program</a></div><div class="nav-item"><a href="/qishao-notes/unix/" class="nav-link">unix</a></div><div class="nav-item"><a href="https://blog.csdn.net/hit_shaoqi" target="_blank" rel="noopener noreferrer" class="nav-link external">
  CSDN
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></div> <a href="https://github.com/hitqshao/qishao-notes" target="_blank" rel="noopener noreferrer" class="repo-link">
    GitHub
    <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></nav>  <ul class="sidebar-links"><li><a href="/qishao-notes/pages/cc7034/" class="sidebar-link">Operand Collector</a></li><li><a href="/qishao-notes/pages/2476ae/" class="sidebar-link">GPU WARP Scheduler</a></li><li><a href="/qishao-notes/pages/14769f/" class="sidebar-link">Precision Exception</a></li><li><a href="/qishao-notes/pages/44771e/" class="sidebar-link">Unified Memory Paper List</a></li><li><a href="/qishao-notes/pages/44871e/" class="sidebar-link">TensorCore Paper List</a></li><li><a href="/qishao-notes/pages/45871e/" class="sidebar-link">Memory Behaviour Paper List</a></li><li><a href="/qishao-notes/pages/45871f/" class="sidebar-link">GPU Virtualization Paper List</a></li><li><a href="/qishao-notes/pages/458720/" class="sidebar-link">Large Language Model Paper List</a></li><li><a href="/qishao-notes/pages/458721/" class="sidebar-link">GPU Simulator</a></li><li><a href="/qishao-notes/pages/458722/" class="sidebar-link">Architectural Survey</a></li><li><a href="/qishao-notes/pages/458724/" class="sidebar-link">Harnessing Integrated CPU-GPU System Memory for HPC a first look into Grace Hopper</a></li><li><a href="/qishao-notes/pages/458725/" class="sidebar-link">Understanding GPGPU-SIM 1 How to get Instruction</a></li><li><a href="/qishao-notes/pages/458726/" class="sidebar-link">Understanding GPGPU-SIM 2 Instruction Execution</a></li><li><a href="/qishao-notes/pages/458727/" class="sidebar-link">Understanding GPGPU-SIM 3 How is the simulation started</a></li><li><a href="/qishao-notes/pages/45872/" class="sidebar-link">Understanding GPGPU-SIM 4 Microarchitecture</a></li><li><a href="/qishao-notes/pages/45874/" class="sidebar-link">Understanding GPGPU-SIM 5  Memory Interface</a></li><li><a href="/qishao-notes/pages/45873/" class="sidebar-link">Warp Related Memory Optimization</a></li><li><a href="/qishao-notes/pages/45875/" class="sidebar-link">GPU Cache Coherency</a></li><li><a href="/qishao-notes/pages/45876/" class="sidebar-link">GPU Cache &amp; Memory Hirerarchy</a></li><li><a href="/qishao-notes/pages/45877/" class="sidebar-link">GPU TLB</a></li><li><a href="/qishao-notes/pages/45878/" class="sidebar-link">GPU Page Table Walk</a></li><li><a href="/qishao-notes/pages/45879/" class="sidebar-link">GPU Cache's Papers</a></li><li><a href="/qishao-notes/pages/45880/" class="sidebar-link">GPU WARP Mangement Papers</a></li><li><a href="/qishao-notes/pages/45882/" class="sidebar-link">GPU Unified Memory Innovations</a></li><li><a href="/qishao-notes/pages/45883/" class="sidebar-link">GPU MultiTask</a></li><li><a href="/qishao-notes/pages/45884/" class="sidebar-link">GPU Training Notes</a></li><li><a href="/qishao-notes/pages/45885/" class="sidebar-link">GPU Paper with Code</a></li><li><a href="/qishao-notes/pages/45886/" class="sidebar-link">GPU Driver &amp; Runtime &amp; Compliation</a></li><li><a href="/qishao-notes/pages/45887/" class="sidebar-link">Accel-Sim Simulator</a></li><li><a href="/qishao-notes/pages/45889/" class="sidebar-link">Understanding GPGPU-SIM 6 Memory Space</a></li><li><a href="/qishao-notes/pages/45890/" aria-current="page" class="active sidebar-link">GPU Insturctions</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header level2"><a href="/qishao-notes/pages/45890/#_1-20-decoding-cuda-binary" class="sidebar-link">1. [20] Decoding CUDA Binary</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header level3"><a href="/qishao-notes/pages/45890/#compiling-flow" class="sidebar-link">Compiling Flow</a></li><li class="sidebar-sub-header level3"><a href="/qishao-notes/pages/45890/#assemble-code" class="sidebar-link">Assemble Code</a></li><li class="sidebar-sub-header level3"><a href="/qishao-notes/pages/45890/#load-store-instruction-and-control-flow-of-divergence" class="sidebar-link">Load/Store Instruction and Control Flow of Divergence</a></li><li class="sidebar-sub-header level3"><a href="/qishao-notes/pages/45890/#compile-time-scheduling" class="sidebar-link">Compile-Time Scheduling</a></li><li class="sidebar-sub-header level3"><a href="/qishao-notes/pages/45890/#reverse-engineering-tool" class="sidebar-link">Reverse Engineering Tool</a></li><li class="sidebar-sub-header level3"><a href="/qishao-notes/pages/45890/#instruction-format-basics" class="sidebar-link">Instruction Format Basics</a></li><li class="sidebar-sub-header level3"><a href="/qishao-notes/pages/45890/#predicate" class="sidebar-link">Predicate</a></li></ul></li><li class="sidebar-sub-header level2"><a href="/qishao-notes/pages/45890/#_7-2024-a-journey-of-a-1-000-kernels-begins-with-a-single-step-a-restrospective-of-deep-learning-on-gpus" class="sidebar-link">[7 2024] A Journey of a 1,000 Kernels Begins with a Single Step A Restrospective of Deep Learning on GPUs</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header level3"><a href="/qishao-notes/pages/45890/#key-objectives-and-questions-addressed" class="sidebar-link">Key Objectives and Questions Addressed</a></li><li class="sidebar-sub-header level3"><a href="/qishao-notes/pages/45890/#main-insights-and-findings" class="sidebar-link">Main Insights and Findings</a></li><li class="sidebar-sub-header level3"><a href="/qishao-notes/pages/45890/#hardware-performance-analysis" class="sidebar-link">Hardware Performance Analysis</a></li><li class="sidebar-sub-header level3"><a href="/qishao-notes/pages/45890/#insights-into-future-hardware-directions" class="sidebar-link">Insights into Future Hardware Directions</a></li><li class="sidebar-sub-header level3"><a href="/qishao-notes/pages/45890/#contributions-and-resources" class="sidebar-link">Contributions and Resources</a></li><li class="sidebar-sub-header level3"><a href="/qishao-notes/pages/45890/#significance" class="sidebar-link">Significance</a></li><li class="sidebar-sub-header level3"><a href="/qishao-notes/pages/45890/#conclusion-and-impact" class="sidebar-link">Conclusion and Impact</a></li></ul></li></ul></li><li><a href="/qishao-notes/pages/47871e/" class="sidebar-link">TO READ</a></li></ul> </aside> <div><main class="page"><div class="theme-vdoing-wrapper bg-style-6"><div class="articleInfo-wrap" data-v-06225672><div class="articleInfo" data-v-06225672><ul class="breadcrumbs" data-v-06225672><li data-v-06225672><a href="/qishao-notes/" title="首页" class="iconfont icon-home router-link-active" data-v-06225672></a></li> <li data-v-06225672><a href="/qishao-notes/gpu/#gpu" data-v-06225672>gpu</a></li></ul> <div class="info" data-v-06225672><div title="作者" class="author iconfont icon-touxiang" data-v-06225672><a href="https://github.com/hitqshao" target="_blank" title="作者" class="beLink" data-v-06225672>hitqishao</a></div> <div title="创建时间" class="date iconfont icon-riqi" data-v-06225672><a href="javascript:;" data-v-06225672>2025-04-02</a></div> <!----></div></div></div> <!----> <div class="content-wrapper"><div class="right-menu-wrapper"><div class="right-menu-margin"><div class="right-menu-title">目录</div> <div class="right-menu-content"></div></div></div> <h1><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAB4AAAAeCAYAAAA7MK6iAAAAAXNSR0IArs4c6QAABKFJREFUSA3tVl1oFVcQnrMbrak3QUgkya1akpJYcrUtIqW1JvFBE9LiQ5v6JmJpolbMg32rVrhgoYK0QiMY6i9Y6EMaW5D+xFJaTYItIuK2Kr3+BJNwkxBj05sQY3b3nM6cs2dv9t7NT/vQJw/sndk5M/PNzJkzewGerP+pAmy+ON8lLzUJgA8ZYxYIYZmGYRnctDaWvJJAmTtfP1pvXsBCCPP8QFcCaRkZYACgDZFO4stNIcBCajEOlmmC9XpJ9bAGCaPaPmzPl32dvLSVu3BWCTQs0XQQ6g0DYgwLIoAZbBCdW/i+781o1VVlm/410mw4h06Y7bIPHNyWDyL4FHkX03Q8SrzNhZTZriieckWt7cL6MM85YcLpsi/7O9/iXFT6MswI0DmmpkSaJ0qLxFIm3+i1THHB3zmBH3PYx9CcykcLOeQVVa7QtdxTgQgEleX2AjHYfwA+2ddV77ruGoJUbhGDI09YSNXyMpUt5ylOzxgbUmtOp7NmbNt8v3arjTBfYELmLUV+M+nSawNNAUqpT3ClJWg5I3BLT+cGW/DXNGCa6tx1aakCGEigArTn4TDIPdrXXYKCZNrHLMCOEPvHBlLQ99s9eHB7EB6NTki73CVPQ2F5MSx/uRQixfmq7rK0wYD8w8E905bnPDfwoWs/rfv93NWN/ZfvwsLIU7A09gxECyISeGJkHAau98L97tuw7NXnoPyNF8FcYGLGKsOs0mN3OEyec9esGW/ZEl945dTP34wlR2FZVQWU1q0Cw8Tr7p+hgLLNL0FPxx/Q35mA8aEUrH6nCgwEl0tn7wUiZYJnNRh6DK4UH/k0lfyrsBKdPVv/AriGIQcEDQZ65LBAGe2Rzui9Ybjz7XUppz1/uKBbyVPGkN3ZAeC6hr0x7Nr38N5+EqkoOm17xpoqR9ohQF55ERSvr4Dkr3chNfC3DMzGJlNBElW8w9nsGQvhNGIzDkXzCg8cLK951xHsFBlTJspJNi3ZFIMF2AeDV3q8DNOB+YHi6QTrChDIWDBRi5U5f+ZMfJLu3ccrqxtdxk4SKH336LFxSmkqefwU5T8fhdSdQf9IVKD6aNiwI/hnmcAZ91isYMJIaCUCx9W098+LgruikeTqzqqxKPUwqJyCPJiyemVVZBOijDGjD38Os0jOiSPL1z3SPjXNANbiNPXAdzTfukjjuknNBbyz3nwgTd3AVFqUJ5hpHlq9MveLnWwttUfoygBmvVjuikxND3znrhsELnZk7k+OjIGxeNEkomyLVta0xxn+HZhjBc4YZ/AFjHjz9u3xRZl2BN4aq9nFwWh16IrQ1aHHEd3j1+4/dB9OtH4e29A2H1DyHQRmOSfQZ1Fy7MHBTGB6J/Djq6p3OxyO2cB+4Car7v/o3GXgfAkj23+x9ID1Teoamo/SXcbvSf2PX7Vc8DdCmE1vN9di+32P9/5YR3vLnhCVGUWBjEkr3yh4H8v9CzmsbdhzOKzsJKM90iFdaTMjRPhGVsakRvOaRidljo6H6G7j+ctrJpsP+4COhDIl0La2+FS4+5mlocBaXY5QnGZysIBYoeSsl5qQzrSj/cgNrfuEzlWBfwA+EjrZyWUvpAAAAABJRU5ErkJggg==">GPU Insturctions<!----></h1> <!----> <div class="theme-vdoing-content content__default"><ol><li>[20] Decoding CUDA Binary</li> <li>[7 2024 ASPLOS] A Journey of a 1,000 Kernels Begins with a Single Step A Restrospective of Deep Learning on GPUs</li> <li>Dissecting the NVIDIA Volta GPU Architecture via Microbenchmarking</li> <li>Dissecting the NVidia Turing T4 GPU via Microbenchmarking</li> <li>[2025] Analyzing Modern NVIDIA GPU cores 👍 👍 👍 👍 👍</li></ol> <hr> <h2 id="_1-20-decoding-cuda-binary"><a href="#_1-20-decoding-cuda-binary" class="header-anchor">#</a> 1. [20] Decoding CUDA Binary</h2> <h3 id="compiling-flow"><a href="#compiling-flow" class="header-anchor">#</a> Compiling Flow</h3> <p>When every thread in the warp has reached a re-convergence command - either a .S modifier or a SYNC instruction,
depending on the architecture - it will wait until the thread warp reaches the instruction whose address is specified by the
SSY instruction, and then return to running in lock-step.</p> <p><img src="https://github.com/user-attachments/assets/66319026-1b78-410c-a6c5-68d09375da76" alt="image"></p> <h3 id="assemble-code"><a href="#assemble-code" class="header-anchor">#</a> Assemble Code</h3> <p>64 bits or 128 bits
<img src="https://github.com/user-attachments/assets/86e4c66a-1b8f-4b18-8efd-bdb40638b80d" alt="image"></p> <h3 id="load-store-instruction-and-control-flow-of-divergence"><a href="#load-store-instruction-and-control-flow-of-divergence" class="header-anchor">#</a> Load/Store Instruction and Control Flow of Divergence</h3> <p><img src="https://github.com/user-attachments/assets/6c3891a8-c1ee-4eef-9526-febbd597188a" alt="image"></p> <h3 id="compile-time-scheduling"><a href="#compile-time-scheduling" class="header-anchor">#</a> Compile-Time Scheduling</h3> <p>As of Compute Capability 3.0, <em>instruction scheduling is handled by the compiler</em> rather than by the hardware.</p> <p>On this architecture every 8−th instruction, rather than being a real instruction, is a set of scheduling codes inserted by the compiler.</p> <p>These scheduling codes dictate the minimum number of cycles that the thread must wait between every two consecutive instructions in the following seven instructions in order to satisfy dependence constraints.</p> <p>Starting with Compute Capability 5.0, NVIDIA moved even more control logic away from the hardware, saving power and space.</p> <p>Thus instruction-level barrier has been added to the scheduling codes generated by the compiler.</p> <p>The scheduling codes on Compute Capabilities 5.x and 6.x occur in place of every fourth instruction.</p> <p>As of Compute Capability 7.0, <strong>they are embedded into each individual instruction</strong>, rather than controlling larger blocks of instructions.</p> <h4 id="instruction-with-operand"><a href="#instruction-with-operand" class="header-anchor">#</a> Instruction with Operand</h4> <p><img src="https://github.com/user-attachments/assets/c12c2fae-dd53-420a-96f8-e05615ef0035" alt="image"></p> <p>Although instructions are of fixed length, NVIDIA’s instruction sets lack the relative simplicity of a RISC architecture.</p> <p>It includes complicated instructions such as multiplication-and-addition, multi-function operation that performs trigonometric functions including sine and cosine, and so on.</p> <p>Although we can make generalizations about which bits are used for which components of the instruction, there are few consistent rules across different instructions.</p> <p>Check PSETP, it has 3 source operands.
<img src="https://github.com/user-attachments/assets/b38e7590-f494-45a8-a029-643a7cdf7941" alt="image"></p> <p><img src="https://github.com/user-attachments/assets/54cd8f74-c1bc-4496-b175-8214972bef0c" alt="image"></p> <h3 id="reverse-engineering-tool"><a href="#reverse-engineering-tool" class="header-anchor">#</a> Reverse Engineering Tool</h3> <p>nvdisasm and sass2ptx</p> <h3 id="instruction-format-basics"><a href="#instruction-format-basics" class="header-anchor">#</a> Instruction Format Basics</h3> <h4 id="instruction-length"><a href="#instruction-length" class="header-anchor">#</a> Instruction Length:</h4> <p>NVIDIA GPU instructions are typically 8 or 16 bytes in length (i.e., 64 or 128 bits), depending on the generation and specific instruction.</p> <p>Most common instructions are encoded in 8 bytes, but certain instructions may require 16 bytes for additional fields (larger immediate values, special modifiers, etc.).</p> <h4 id="predicate-bits"><a href="#predicate-bits" class="header-anchor">#</a> Predicate Bits:</h4> <p>Each instruction can be conditionally executed based on a predicate register (e.g., @P0 or @!P0).</p> <p>The instruction encoding typically reserves a few bits for specifying which predicate is used, whether it’s negated, and whether the instruction updates that predicate or only tests it.</p> <h4 id="opcode-and-sub-op-fields"><a href="#opcode-and-sub-op-fields" class="header-anchor">#</a> Opcode and Sub-Op Fields:</h4> <p>A chunk of bits is used to identify the primary operation (e.g., FADD for floating-point add, IMUL for integer multiply, LDG for global memory load, etc.).</p> <p>Some instructions have “sub-ops” or “specialization bits” that further refine the operation (e.g., specifying data type, rounding mode, or variant of the operation).</p> <h4 id="source-and-destination-registers"><a href="#source-and-destination-registers" class="header-anchor">#</a> Source and Destination Registers:</h4> <p>SASS instructions typically encode up to four source operands and one or two destinations (though most commonly one destination).</p> <p>The register indices (e.g., R0, R1, R2, etc.) appear in dedicated fields.</p> <p>Depending on the instruction, immediate operands (e.g., a constant offset) may replace a register operand.</p> <h4 id="modifiers-and-flags"><a href="#modifiers-and-flags" class="header-anchor">#</a> Modifiers and Flags:</h4> <p>Many instructions have bits for modifiers (e.g., .CC to set condition codes, .SAT to enable saturation, etc.).</p> <p>Reuse flags (discussed in your previous question) are also stored in a few bits in the encoding.</p> <p>Additional bits might control things like whether a memory operation is cache-specific (.E for eviction policy, .L1 or .L2 usage, etc.), or whether an instruction is uniform across a warp, and so on.</p> <h4 id="scheduling-information"><a href="#scheduling-information" class="header-anchor">#</a> Scheduling Information:</h4> <p>Modern NVIDIA architectures embed scheduling information in the instruction to help the hardware’s instruction scheduler. You might see references to “stall” counts or “read dependency” codes. In short:</p> <p>A few bits can indicate how many cycles to wait before reading certain registers, or how many cycles to wait before issuing the next instruction.</p> <p>This is sometimes referred to as “scheduling” or “scoreboarding” fields.</p> <h4 id="operand-encoding-and-immediate-values"><a href="#operand-encoding-and-immediate-values" class="header-anchor">#</a> Operand Encoding and Immediate Values</h4> <p>Register Operands: Typically specified by a field that directly encodes the register number (e.g., 7 bits for the register index if up to 128 registers).</p> <p>Immediate Operands: Some instructions support small inline immediates.</p> <p>The immediate field is part of the instruction encoding, using a certain number of bits.</p> <p>If the immediate is too large to fit, a 16-byte (128-bit) encoding might be used, or the compiler may materialize the immediate in a register first.</p> <p>Addressing Modes: Memory instructions (LDG, STG, LDS, etc.) often encode an offset or a base+offset form. Some bits specify how to interpret those, e.g., 8-bit or 20-bit offset, sign extension, scaled by data type size, etc.</p> <h4 id="reuse-flags-and-the-2-way-associative-cam"><a href="#reuse-flags-and-the-2-way-associative-cam" class="header-anchor">#</a> Reuse Flags and the 2-Way Associative CAM</h4> <p>Reuse Flags: Each instruction can mark which of its first four source registers should be saved in a small local cache, so that subsequent instructions can reuse them without accessing the main register file.</p> <p>These flags are 4 bits in the SASS encoding (one per operand), typically in the lower part of the 8-byte instruction encoding.</p> <p>This is a micro-architectural feature that helps reduce register file pressure and bank conflicts.</p> <h4 id="predicate-and-condition-code-fields"><a href="#predicate-and-condition-code-fields" class="header-anchor">#</a> Predicate and Condition Code Fields</h4> <p>One or two bits designate whether an instruction is predicated (e.g., @P0, @!P0, etc.).</p> <p>Another small field may specify which predicate register is used (since GPUs can have multiple predicate registers).</p> <p>Some instructions also set condition codes (e.g., for subsequent instructions to test), which the hardware might encode in a “condition code” sub-field.</p> <h4 id="example-layout-hypothetical"><a href="#example-layout-hypothetical" class="header-anchor">#</a> Example Layout (Hypothetical)</h4> <p>Below is a hypothetical 64-bit (8-byte) SASS instruction breakdown (not official, but a conceptual approximation):</p> <p><img src="https://github.com/user-attachments/assets/22bb7fc6-1272-41cd-a662-843609fe2782" alt="image"></p> <ul><li>Opcode (7 bits): Identifies the core instruction (e.g., FADD, IMUL, LDG).</li> <li>Source Registers (5 bits each): Up to three or four sources, each needing enough bits to address the register file.</li> <li>Destination Register (5 bits): Usually one, possibly two in some instructions (like a multiply-add that writes an extra output).</li> <li>Modifiers / Flags: Several bits for controlling instruction behavior (e.g., rounding modes, type specifiers, etc.).</li> <li>Reuse Flags (4 bits): One bit per operand position, marking which registers to cache.</li> <li>Predicate / Condition Code: Often stored in either the high bits or low bits, depending on generation.</li> <li>Scheduling Info: Usually a small field that the compiler sets to help with instruction issuing/stalling.</li></ul> <p>Different architectures shift these fields around or allocate more/less bits, but the principle remains similar.</p> <h3 id="predicate"><a href="#predicate" class="header-anchor">#</a> Predicate</h3> <p>NVIDIA GPUs use predicate registers and explicit branch instructions (e.g., BRA) to handle conditional logic at the SASS (assembly) level.</p> <p>In concert with the hardware’s warp execution model, this mechanism can create control flow divergence when different threads of the same warp take different paths.</p> <p>Below is a more detailed explanation of how predicates, branching, and divergence work together.</p> <h4 id="the-basic-idea-of-predication"><a href="#the-basic-idea-of-predication" class="header-anchor">#</a> The Basic Idea of Predication</h4> <p>A predicate (e.g., P0, P1, etc.) is a 1-bit register that can be set or cleared by a comparison instruction. For example:</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>PSETP.EQ.U32 P0, PT, R4, RZ, PT;
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>This sets predicate P0 to 1 if R4 == 0; otherwise P0 = 0.</p> <p>PT means “always pass” (no predicate on that comparison itself).</p> <p>RZ is the “zero register.”</p> <p>Once a predicate is set, any subsequent instruction can be predicated—i.e., guarded—by referencing that predicate. For example:</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>@P0 IADD R5, R5, R6;
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>Reads as: “Perform IADD R5, R5, R6 only if P0 == 1; otherwise do nothing.”</p> <p>However, you can also have a predicated branch:</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>@P0 BRA 0x210;
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>Means: “If P0 == 1, jump to the instruction at address 0x210; if P0 == 0, continue sequentially.”</p> <h4 id="divergence-and-the-active-mask"><a href="#divergence-and-the-active-mask" class="header-anchor">#</a> Divergence and the Active Mask</h4> <p>A key point about GPU execution is that an entire warp (32 threads on most NVIDIA hardware) executes in lockstep on a single instruction stream. If a branch is taken by some threads but not others, the warp must diverge:</p> <ul><li>The hardware splits the warp’s threads into multiple “subsets,” one subset that takes the branch and another that doesn’t.</li> <li>The warp serially executes each subset’s path, with the other subset of threads masked out (inactive).</li></ul> <p>At the end, the warp reconverges at a known instruction (e.g., the instruction pointed to by SSY).</p> <p>This is how a single warp can handle different control flow paths for its 32 threads.</p> <h4 id="the-role-of-ssy-set-synchronization"><a href="#the-role-of-ssy-set-synchronization" class="header-anchor">#</a> The Role of SSY (Set SYnchronization)</h4> <p>When the compiler emits:</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>SSY 0x238
@P0 BRA 0x210
...
SYNC
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><p>SSY 0x238 instructs the hardware to push a reconvergence point (address 0x238) onto the hardware’s “divergence stack.”</p> <p>The next branch—@P0 BRA 0x210—can cause divergence: some threads branch, others continue.</p> <p>After each subset of threads has finished, the hardware automatically goes to 0x238 (the SSY target) to reconverge the warp, so all threads proceed together again.</p> <h4 id="using-predicates-to-create-conditional-branches"><a href="#using-predicates-to-create-conditional-branches" class="header-anchor">#</a> Using Predicates to Create Conditional Branches</h4> <p>Example Flow
Let’s say your high-level code is:</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>if (tid != 0) {
    sum += 4;
}
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><p>The compiler might produce:</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>// 1) Compare tid != 0, store result in P0
PSETP.NE.U32 P0, PT, R9, RZ, PT;  // if (R9 != 0) P0=1; else P0=0

// 2) Set the reconvergence point after the IF block
SSY targetAddr

// 3) Predicated branch: jump if P0=1
@P0 BRA insideIf

// (fallthrough path: if P0=0, skip the IF block)
BRA endIf   // or a SYNC, depending on code structure

insideIf:
 IADD32I R8, R8, 4;   // sum += 4
 SYNC

endIf:
// warp reconverges here
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br></div></div><p>Here, the hardware uses P0 to decide which threads branch and which do not. The warp may need multiple passes if some threads are P0=1 and others are P0=0.</p> <h4 id="tid-and-tid-4-why-you-don-t-always-see-explicit-instructions"><a href="#tid-and-tid-4-why-you-don-t-always-see-explicit-instructions" class="header-anchor">#</a> (tid) and (tid % 4): Why You Don’t Always See Explicit Instructions</h4> <p>In high-level CUDA (C/C++), you write:</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>int tid = threadIdx.x;
if (tid != 0) ...
if (tid % 4 == 0) ...
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><p>But the final SASS might not show a direct “integer modulo” or “compare to zero” instruction. Instead:</p> <ul><li><p><strong>Thread ID is Already in a Register</strong></p> <ul><li>At the start of the kernel, the compiler loads threadIdx.x into a register (R9 or something).</li> <li>That code might be hoisted well above the snippet you’re looking at.</li></ul></li> <li><p>Modulo 4 = Bitwise Test</p> <ul><li>tid % 4 == 0 is the same as (tid &amp; 3) == 0.</li> <li>The compiler can use a single bitwise AND or LOP3 (logical operation) to check the two least significant bits. Then it sets a predicate based on the result.</li> <li>So you’ll see something like LOP3.LUT P1, R9, RZ, ... 0x... or I2I P1, R9, AND, 3 or some variant that directly sets P1.</li></ul></li> <li><p>Predicate is Checked at Branch</p> <ul><li>Instead of a standalone branch if (tid != 0), the hardware does PSETP.NE.U32 P0, R9, RZ followed by @P0 BRA label.</li> <li>This merges “compare” + “branch” logic with the warp’s active mask concept.</li></ul></li></ul> <p>Hence, you rarely see an explicit “%4” machine instruction or a standalone CMP R9 != 0 or “TID instruction.”</p> <p>The predicate logic folds these checks into specialized SASS instructions that set P0 or P1, and then uses predicated branching or predicated instructions.</p> <h4 id="putting-it-all-together"><a href="#putting-it-all-together" class="header-anchor">#</a> Putting It All Together</h4> <p><strong>Predicate Computation</strong> A special compare (e.g., PSETP) sets P0 based on (tid != 0), (tid &amp; 3) == 0, etc.
<strong>Control Divergence</strong> If some threads in the warp have P0=1 and others have P0=0, the warp diverges when it hits @P0 BRA somewhere.</p> <p>Reconvergence: An SSY target before the branch and a SYNC (or matching BRA) after the branch help the hardware manage warp subsets and eventually bring them back together at the same program counter.</p> <p>In short, predicates let each thread in a warp conditionally execute code. If different threads disagree on the condition, the warp temporarily serializes the different paths but eventually merges (reconverges) again at an SSY target. This is how GPUs handle “if” statements, loops, etc., across thousands of parallel threads.</p> <hr> <p><strong>Summary of the Paper</strong>
The paper investigates the evolution of deep learning (DL) applications on GPUs by examining a diverse range of state-of-the-art applications and hardware across three NVIDIA GPU generations: <strong>P100</strong> , <strong>V100</strong> , and <strong>A100</strong> . It provides a comprehensive analysis at three levels:</p> <ul><li><p><strong>Framework Level</strong>  (TensorFlow/PyTorch)</p></li> <li><p><strong>Device API Level</strong>  (e.g., cuDNN, CUDA kernels)</p></li> <li><p><strong>Hardware and Microarchitecture Level</strong></p></li></ul> <p>The authors develop a benchmarking suite named <strong>CaSiO</strong>  (covering applications from domains like computer vision, physical simulation, language processing, etc.) to capture a wide range of realistic production workloads that are broader and more diverse than conventional benchmarks like MLPerf.</p> <hr> <h2 id="_7-2024-a-journey-of-a-1-000-kernels-begins-with-a-single-step-a-restrospective-of-deep-learning-on-gpus"><a href="#_7-2024-a-journey-of-a-1-000-kernels-begins-with-a-single-step-a-restrospective-of-deep-learning-on-gpus" class="header-anchor">#</a> [7 2024] A Journey of a 1,000 Kernels Begins with a Single Step A Restrospective of Deep Learning on GPUs</h2> <h3 id="key-objectives-and-questions-addressed"><a href="#key-objectives-and-questions-addressed" class="header-anchor">#</a> <strong>Key Objectives and Questions Addressed</strong></h3> <p>The paper aims to answer three major questions:</p> <ul><li><strong>Application Scaling:</strong> <em>How does the behavior of real-world DL applications scale across GPU hardware generations?</em></li> <li><strong>Hardware-Software Interactions:</strong> <em>What are the software-compiler-hardware interactions that either enable or limit generational speedup?</em></li> <li><strong>Future Directions:</strong> <em>What insights can we gain from current trends to inform the development of future GPU architectures?</em></li></ul> <h3 id="main-insights-and-findings"><a href="#main-insights-and-findings" class="header-anchor">#</a> <strong>Main Insights and Findings</strong></h3> <h4 id="application-level-observations"><a href="#application-level-observations" class="header-anchor">#</a> <strong>Application-Level Observations</strong></h4> <ul><li><strong>Operator Diversity:</strong>  Modern DL applications are diverse and require a large set of operators beyond simple matrix multiplications or convolutions.</li></ul> <p><img src="https://github.com/user-attachments/assets/975da5b1-c112-4368-a883-4202ce0da33a" alt="image"></p> <ul><li><strong>GEMM Decline:</strong>  While GEMM-based kernels (e.g., matrix multiplications) have traditionally dominated GPU computations, their relative importance decreases with newer hardware generations.</li> <li><strong>Specialization and Complexity:</strong>  The software ecosystem must support an extensive set of shape-specialized kernels to maximize hardware utilization.</li></ul> <p><img src="https://github.com/user-attachments/assets/a59a404c-bba3-4aaf-b529-fd495e1ead03" alt="image"></p> <h4 id="detailed-gemm-analysis"><a href="#detailed-gemm-analysis" class="header-anchor">#</a> <strong>Detailed GEMM Analysis</strong></h4> <ul><li><strong>Shape Specialization:</strong>  Significant performance improvements (on V100 over P100) were driven by specialized kernels tailored for specific GEMM shapes. However, the further generational speedups (A100 over V100) were modest.</li> <li><strong>Utilization:</strong>  Hardware utilization for GEMM operations peaked on V100 but began declining on the A100 due to challenges in effectively utilizing massively parallel hardware for smaller or irregular shapes.</li></ul> <h4 id="hardware-execution-states"><a href="#hardware-execution-states" class="header-anchor">#</a> <strong>Hardware Execution States</strong></h4> <ul><li>The authors defined a taxonomy based on three key hardware execution characteristics:</li> <li><strong>Thread parallelism</strong>  (low, medium, high)</li> <li><strong>Compute utilization</strong>  (SM utilization)</li> <li><strong>Memory utilization</strong>  (DRAM bandwidth usage)
They found:</li> <li>Substantial under-utilization of resources even for seemingly optimized GEMM-heavy workloads.</li> <li>Frequent switching between execution states, highlighting the dynamic and diverse nature of modern AI applications.</li></ul> <h3 id="hardware-performance-analysis"><a href="#hardware-performance-analysis" class="header-anchor">#</a> <strong>Hardware Performance Analysis</strong></h3> <ul><li><strong>P100 → V100:</strong>  Significant speedups due to the introduction of TensorCores (specialized GEMM units).</li> <li><strong>V100 → A100:</strong>  Modest gains indicating diminishing returns on GEMM acceleration alone.</li></ul> <p><img src="https://github.com/user-attachments/assets/826ea8d5-ea36-4e5c-b335-9c580c7bef52" alt="image"></p> <h3 id="insights-into-future-hardware-directions"><a href="#insights-into-future-hardware-directions" class="header-anchor">#</a> <strong>Insights into Future Hardware Directions</strong></h3> <p>Based on their observations, the authors highlight three major areas for future hardware optimization:</p> <h4 id="compute-orchestration"><a href="#compute-orchestration" class="header-anchor">#</a> <strong>Compute Orchestration:</strong></h4> <p>Optimizing hardware execution units to better handle diverse and irregular shapes of GEMMs, especially smaller and less regular computations.</p> <p><img src="https://github.com/user-attachments/assets/ed5550cf-b903-42b5-a5e6-a9f0ed41c0d6" alt="image"></p> <h4 id="data-orchestration"><a href="#data-orchestration" class="header-anchor">#</a> <strong>Data Orchestration:</strong></h4> <p>Improving data movement operations in memory systems, since many kernels spend significant execution time on memory-bound or data-movement-heavy operations.</p> <h4 id="dependence-orchestration"><a href="#dependence-orchestration" class="header-anchor">#</a> <strong>Dependence Orchestration:</strong></h4> <p>Better leveraging the rapidly changing execution states and complex dependencies in DL algorithms to maximize hardware resource occupancy.</p> <p>The authors present a case study demonstrating that by focusing on these behaviors, future architectures could achieve around <strong>2.3X geometric mean speedup</strong>  over current GPU architectures.</p> <h3 id="contributions-and-resources"><a href="#contributions-and-resources" class="header-anchor">#</a> <strong>Contributions and Resources</strong></h3> <p>The authors provide a curated set of real-world DL applications, their infrastructure (<strong>CaSiO</strong>  suite), and detailed performance data at different levels for public access to aid future research.</p> <ul><li><p>GitHub Repository: <a href="https://github.com/VerticalResearchGroup/casio" target="_blank" rel="noopener noreferrer">CaSiO Suite<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p></li> <li><p>Detailed GEMM analysis data: <a href="https://github.com/VerticalResearchGroup/casio-gemms/blob/main/gemms.csv" target="_blank" rel="noopener noreferrer">GEMM Shape Performance Data<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p> <ul><li>Large M,N,K provide consistent performance</li> <li>At least one of M,N,K is very small
With very small K, the inner loop doesn’t run enough, causing under-utilization of faster compute resources.
With Large M or N but small K, utilization could still be high. but if both M and N are low, the utilization will be low.</li></ul></li></ul> <p><img src="https://github.com/user-attachments/assets/0b06a53a-ecac-4dcf-b8b8-4c8dd88ef36c" alt="image"></p> <h3 id="significance"><a href="#significance" class="header-anchor">#</a> <strong>Significance</strong></h3> <p>This paper is significant because:</p> <ul><li>It systematically addresses the limits and future potentials of GPU-based accelerators for DL workloads.</li> <li>It provides empirical insights into how actual, complex DL workloads interact with evolving hardware, guiding future designs.</li> <li>It challenges the conventional wisdom of GEMM-centric acceleration by demonstrating diminishing returns and highlighting the need for more diverse hardware strategies.</li></ul> <h3 id="conclusion-and-impact"><a href="#conclusion-and-impact" class="header-anchor">#</a> <strong>Conclusion and Impact</strong></h3> <p>The paper underscores a critical transition point in AI hardware development, clearly demonstrating that the era of straightforward GEMM-based acceleration has reached diminishing returns.</p> <p>It makes a strong case for a more nuanced, algorithm-aware hardware architecture that can dynamically adapt to a wide variety of computational patterns and data orchestration needs.</p> <p>By providing both detailed empirical evidence and actionable insights, the paper offers valuable guidance for architects and system designers developing next-generation hardware platforms tailored to real-world DL workloads.</p></div></div> <!----> <div class="page-edit"><div class="edit-link"><a href="https://github.com/hitqshao/qishao-notes/edit/main/docs/03.gpu/31.gpu_inst.md" target="_blank" rel="noopener noreferrer">帮助我们改善此页面</a> <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></div> <!----> <div class="last-updated"><span class="prefix">上次更新:</span> <span class="time">2025/04/04, 03:09:07</span></div></div> <div class="page-nav-wapper"><div class="page-nav-centre-wrap"><a href="/qishao-notes/pages/45889/" class="page-nav-centre page-nav-centre-prev"><div class="tooltip">Understanding GPGPU-SIM 6 Memory Space</div></a> <a href="/qishao-notes/pages/47871e/" class="page-nav-centre page-nav-centre-next"><div class="tooltip">TO READ</div></a></div> <div class="page-nav"><p class="inner"><span class="prev">
        ←
        <a href="/qishao-notes/pages/45889/" class="prev">Understanding GPGPU-SIM 6 Memory Space</a></span> <span class="next"><a href="/qishao-notes/pages/47871e/">TO READ</a>→
      </span></p></div></div></div> <!----></main></div> <div class="footer"><div class="icons"><a href="https://github.com/hitqshao" title="GitHub" target="_blank" class="iconfont icon-github"></a><a href="mailto:hitqshao@163.com" title="发邮件" target="_blank" class="iconfont icon-youjian"></a><a href="https://gitee.com/hitqshao" title="Gitee" target="_blank" class="iconfont icon-gitee"></a></div> 
  Theme by
  <a href="https://github.com/xugaoyi/vuepress-theme-vdoing" target="_blank" title="本站主题">Vdoing</a> 
    | Copyright © 2022-2025
    <span>Eryajf | <a href="https://github.com/hitqshao/qishao-notes/blob/main/LICENSE" target="_blank">MIT License</a></span></div> <div class="buttons"><div title="返回顶部" class="button blur go-to-top iconfont icon-fanhuidingbu" style="display:none;"></div> <div title="去评论" class="button blur go-to-comment iconfont icon-pinglun" style="display:none;"></div> <div title="主题模式" class="button blur theme-mode-but iconfont icon-zhuti"><ul class="select-box" style="display:none;"><li class="iconfont icon-zidong">
          跟随系统
        </li><li class="iconfont icon-rijianmoshi">
          浅色模式
        </li><li class="iconfont icon-yejianmoshi">
          深色模式
        </li><li class="iconfont icon-yuedu">
          阅读模式
        </li></ul></div></div> <!----> <!----> <!----></div><div class="global-ui"><!----></div></div>
    <script src="/qishao-notes/assets/js/app.d6e24f61.js" defer></script><script src="/qishao-notes/assets/js/2.6d8a25ce.js" defer></script><script src="/qishao-notes/assets/js/76.55fb1852.js" defer></script>
  </body>
</html>

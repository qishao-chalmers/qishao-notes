<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>GPU Cache Management | CPU &amp; GPU Microarch. Qi Shao</title>
    <meta name="generator" content="VuePress 1.8.0">
    <link rel="stylesheet" href="custom.css">
    <script language="javascript" type="text/javascript" src="/qishao-notes/js/pgmanor-self.js"></script>
    <meta name="description" content="Computer System">
    <meta name="google-site-verification" content="66w5U9NY5gJWu7iBtHKMbhpXkV94jy31L_RHbvrZZzY">
    <meta name="keywords" content="Hitqishao,golang,vue,go-web,go-admin,go-ldap-admin">
    <meta name="theme-color" content="#11a8cd">
    <meta name="referrer" content="no-referrer-when-downgrade">
    
    <link rel="preload" href="/qishao-notes/assets/css/0.styles.685d6d32.css" as="style"><link rel="preload" href="/qishao-notes/assets/js/app.e7ace6b1.js" as="script"><link rel="preload" href="/qishao-notes/assets/js/2.53666c0e.js" as="script"><link rel="preload" href="/qishao-notes/assets/js/83.2dc65497.js" as="script"><link rel="prefetch" href="/qishao-notes/assets/js/10.7e6f253e.js"><link rel="prefetch" href="/qishao-notes/assets/js/100.e23945ef.js"><link rel="prefetch" href="/qishao-notes/assets/js/101.443df34d.js"><link rel="prefetch" href="/qishao-notes/assets/js/102.e06ee548.js"><link rel="prefetch" href="/qishao-notes/assets/js/103.5914c104.js"><link rel="prefetch" href="/qishao-notes/assets/js/104.e051c7e1.js"><link rel="prefetch" href="/qishao-notes/assets/js/105.993cc1c8.js"><link rel="prefetch" href="/qishao-notes/assets/js/106.417f856b.js"><link rel="prefetch" href="/qishao-notes/assets/js/107.a9b2846e.js"><link rel="prefetch" href="/qishao-notes/assets/js/108.b368a96f.js"><link rel="prefetch" href="/qishao-notes/assets/js/109.2582ea4e.js"><link rel="prefetch" href="/qishao-notes/assets/js/11.2552ffdb.js"><link rel="prefetch" href="/qishao-notes/assets/js/110.35d36118.js"><link rel="prefetch" href="/qishao-notes/assets/js/111.46510f64.js"><link rel="prefetch" href="/qishao-notes/assets/js/112.676d673f.js"><link rel="prefetch" href="/qishao-notes/assets/js/113.67d7dae6.js"><link rel="prefetch" href="/qishao-notes/assets/js/114.e89aec69.js"><link rel="prefetch" href="/qishao-notes/assets/js/115.814e6c0b.js"><link rel="prefetch" href="/qishao-notes/assets/js/116.9104fc67.js"><link rel="prefetch" href="/qishao-notes/assets/js/117.d27bfdb8.js"><link rel="prefetch" href="/qishao-notes/assets/js/118.73d54539.js"><link rel="prefetch" href="/qishao-notes/assets/js/119.8da19415.js"><link rel="prefetch" href="/qishao-notes/assets/js/12.5ce790ca.js"><link rel="prefetch" href="/qishao-notes/assets/js/120.9290b729.js"><link rel="prefetch" href="/qishao-notes/assets/js/121.f66a23b7.js"><link rel="prefetch" href="/qishao-notes/assets/js/122.bfa94c5e.js"><link rel="prefetch" href="/qishao-notes/assets/js/123.3df5c31f.js"><link rel="prefetch" href="/qishao-notes/assets/js/124.b5ae1ec8.js"><link rel="prefetch" href="/qishao-notes/assets/js/125.602cbbd0.js"><link rel="prefetch" href="/qishao-notes/assets/js/126.781a7e44.js"><link rel="prefetch" href="/qishao-notes/assets/js/127.fada19d1.js"><link rel="prefetch" href="/qishao-notes/assets/js/128.e5525f8d.js"><link rel="prefetch" href="/qishao-notes/assets/js/129.6bfedde3.js"><link rel="prefetch" href="/qishao-notes/assets/js/13.bac50165.js"><link rel="prefetch" href="/qishao-notes/assets/js/130.7abe407b.js"><link rel="prefetch" href="/qishao-notes/assets/js/131.fc816bb1.js"><link rel="prefetch" href="/qishao-notes/assets/js/132.0fbb1cb1.js"><link rel="prefetch" href="/qishao-notes/assets/js/133.abdb4253.js"><link rel="prefetch" href="/qishao-notes/assets/js/134.6a170514.js"><link rel="prefetch" href="/qishao-notes/assets/js/135.659149ab.js"><link rel="prefetch" href="/qishao-notes/assets/js/136.08eae3d5.js"><link rel="prefetch" href="/qishao-notes/assets/js/137.2c401123.js"><link rel="prefetch" href="/qishao-notes/assets/js/138.e7bc05a7.js"><link rel="prefetch" href="/qishao-notes/assets/js/139.6988eb93.js"><link rel="prefetch" href="/qishao-notes/assets/js/14.85d7470d.js"><link rel="prefetch" href="/qishao-notes/assets/js/140.55204db8.js"><link rel="prefetch" href="/qishao-notes/assets/js/141.c80ef843.js"><link rel="prefetch" href="/qishao-notes/assets/js/142.131b598c.js"><link rel="prefetch" href="/qishao-notes/assets/js/143.5ce7683f.js"><link rel="prefetch" href="/qishao-notes/assets/js/144.c0db68b8.js"><link rel="prefetch" href="/qishao-notes/assets/js/145.43da4cd0.js"><link rel="prefetch" href="/qishao-notes/assets/js/146.b35b0153.js"><link rel="prefetch" href="/qishao-notes/assets/js/147.f698f299.js"><link rel="prefetch" href="/qishao-notes/assets/js/15.a59c480d.js"><link rel="prefetch" href="/qishao-notes/assets/js/16.b8c76f47.js"><link rel="prefetch" href="/qishao-notes/assets/js/17.9e600c68.js"><link rel="prefetch" href="/qishao-notes/assets/js/18.128c2b0e.js"><link rel="prefetch" href="/qishao-notes/assets/js/19.e439f846.js"><link rel="prefetch" href="/qishao-notes/assets/js/20.c8a92336.js"><link rel="prefetch" href="/qishao-notes/assets/js/21.bc8dc9c7.js"><link rel="prefetch" href="/qishao-notes/assets/js/22.3f92d355.js"><link rel="prefetch" href="/qishao-notes/assets/js/23.b0c9fab9.js"><link rel="prefetch" href="/qishao-notes/assets/js/24.261fe8af.js"><link rel="prefetch" href="/qishao-notes/assets/js/25.18d5d695.js"><link rel="prefetch" href="/qishao-notes/assets/js/26.2f3cc9ee.js"><link rel="prefetch" href="/qishao-notes/assets/js/27.7aedf070.js"><link rel="prefetch" href="/qishao-notes/assets/js/28.9d8ed5e8.js"><link rel="prefetch" href="/qishao-notes/assets/js/29.100135e7.js"><link rel="prefetch" href="/qishao-notes/assets/js/3.0852a784.js"><link rel="prefetch" href="/qishao-notes/assets/js/30.1e129010.js"><link rel="prefetch" href="/qishao-notes/assets/js/31.0913dc23.js"><link rel="prefetch" href="/qishao-notes/assets/js/32.7880ac0e.js"><link rel="prefetch" href="/qishao-notes/assets/js/33.222759c1.js"><link rel="prefetch" href="/qishao-notes/assets/js/34.33841c37.js"><link rel="prefetch" href="/qishao-notes/assets/js/35.3c3204eb.js"><link rel="prefetch" href="/qishao-notes/assets/js/36.9bcf840c.js"><link rel="prefetch" href="/qishao-notes/assets/js/37.e769481a.js"><link rel="prefetch" href="/qishao-notes/assets/js/38.699db830.js"><link rel="prefetch" href="/qishao-notes/assets/js/39.a5809a01.js"><link rel="prefetch" href="/qishao-notes/assets/js/4.b35441f3.js"><link rel="prefetch" href="/qishao-notes/assets/js/40.c9641058.js"><link rel="prefetch" href="/qishao-notes/assets/js/41.e0f6e0a9.js"><link rel="prefetch" href="/qishao-notes/assets/js/42.42517ec5.js"><link rel="prefetch" href="/qishao-notes/assets/js/43.9124aa21.js"><link rel="prefetch" href="/qishao-notes/assets/js/44.f269e52d.js"><link rel="prefetch" href="/qishao-notes/assets/js/45.f36ca625.js"><link rel="prefetch" href="/qishao-notes/assets/js/46.5a589844.js"><link rel="prefetch" href="/qishao-notes/assets/js/47.cbbac7ec.js"><link rel="prefetch" href="/qishao-notes/assets/js/48.aa2bff30.js"><link rel="prefetch" href="/qishao-notes/assets/js/49.d21d110e.js"><link rel="prefetch" href="/qishao-notes/assets/js/5.2b7b0962.js"><link rel="prefetch" href="/qishao-notes/assets/js/50.1677be2e.js"><link rel="prefetch" href="/qishao-notes/assets/js/51.9509318b.js"><link rel="prefetch" href="/qishao-notes/assets/js/52.e6abb808.js"><link rel="prefetch" href="/qishao-notes/assets/js/53.d440a337.js"><link rel="prefetch" href="/qishao-notes/assets/js/54.8a42ca67.js"><link rel="prefetch" href="/qishao-notes/assets/js/55.fdc9350c.js"><link rel="prefetch" href="/qishao-notes/assets/js/56.de665920.js"><link rel="prefetch" href="/qishao-notes/assets/js/57.922a047b.js"><link rel="prefetch" href="/qishao-notes/assets/js/58.81f554f1.js"><link rel="prefetch" href="/qishao-notes/assets/js/59.28b92743.js"><link rel="prefetch" href="/qishao-notes/assets/js/6.b23efced.js"><link rel="prefetch" href="/qishao-notes/assets/js/60.0b2328ba.js"><link rel="prefetch" href="/qishao-notes/assets/js/61.fe6f3c26.js"><link rel="prefetch" href="/qishao-notes/assets/js/62.98875bfe.js"><link rel="prefetch" href="/qishao-notes/assets/js/63.796deb10.js"><link rel="prefetch" href="/qishao-notes/assets/js/64.0faea049.js"><link rel="prefetch" href="/qishao-notes/assets/js/65.4a7ea356.js"><link rel="prefetch" href="/qishao-notes/assets/js/66.ce5c129e.js"><link rel="prefetch" href="/qishao-notes/assets/js/67.8dac9ea9.js"><link rel="prefetch" href="/qishao-notes/assets/js/68.85c6f7d5.js"><link rel="prefetch" href="/qishao-notes/assets/js/69.5bd4a13f.js"><link rel="prefetch" href="/qishao-notes/assets/js/7.47ead47f.js"><link rel="prefetch" href="/qishao-notes/assets/js/70.bcb1c3dc.js"><link rel="prefetch" href="/qishao-notes/assets/js/71.144574dc.js"><link rel="prefetch" href="/qishao-notes/assets/js/72.137167e4.js"><link rel="prefetch" href="/qishao-notes/assets/js/73.6bad7981.js"><link rel="prefetch" href="/qishao-notes/assets/js/74.19e8d26a.js"><link rel="prefetch" href="/qishao-notes/assets/js/75.82c4de60.js"><link rel="prefetch" href="/qishao-notes/assets/js/76.8dcc9670.js"><link rel="prefetch" href="/qishao-notes/assets/js/77.f67291e4.js"><link rel="prefetch" href="/qishao-notes/assets/js/78.c02341ca.js"><link rel="prefetch" href="/qishao-notes/assets/js/79.037b5e81.js"><link rel="prefetch" href="/qishao-notes/assets/js/8.e05f36d5.js"><link rel="prefetch" href="/qishao-notes/assets/js/80.8f5b0650.js"><link rel="prefetch" href="/qishao-notes/assets/js/81.1bc1adc6.js"><link rel="prefetch" href="/qishao-notes/assets/js/82.0c445de3.js"><link rel="prefetch" href="/qishao-notes/assets/js/84.edd27008.js"><link rel="prefetch" href="/qishao-notes/assets/js/85.8ac62810.js"><link rel="prefetch" href="/qishao-notes/assets/js/86.39a5c885.js"><link rel="prefetch" href="/qishao-notes/assets/js/87.634fc945.js"><link rel="prefetch" href="/qishao-notes/assets/js/88.0979f9f9.js"><link rel="prefetch" href="/qishao-notes/assets/js/89.090200eb.js"><link rel="prefetch" href="/qishao-notes/assets/js/9.cf4260fb.js"><link rel="prefetch" href="/qishao-notes/assets/js/90.7d516f0d.js"><link rel="prefetch" href="/qishao-notes/assets/js/91.e6c2da92.js"><link rel="prefetch" href="/qishao-notes/assets/js/92.94621630.js"><link rel="prefetch" href="/qishao-notes/assets/js/93.4b7d190a.js"><link rel="prefetch" href="/qishao-notes/assets/js/94.72b50028.js"><link rel="prefetch" href="/qishao-notes/assets/js/95.47936ae2.js"><link rel="prefetch" href="/qishao-notes/assets/js/96.857bf4c8.js"><link rel="prefetch" href="/qishao-notes/assets/js/97.5d11b62d.js"><link rel="prefetch" href="/qishao-notes/assets/js/98.94179e7e.js"><link rel="prefetch" href="/qishao-notes/assets/js/99.44d67dad.js">
    <link rel="stylesheet" href="/qishao-notes/assets/css/0.styles.685d6d32.css">
  </head>
  <body class="theme-mode-light">
    <div id="app" data-server-rendered="true"><div class="theme-container sidebar-open have-rightmenu"><header class="navbar blur"><div title="ÁõÆÂΩï" class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/qishao-notes/" class="home-link router-link-active"><!----> <span class="site-name">CPU &amp; GPU Microarch. Qi Shao</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/qishao-notes/" class="nav-link">Home</a></div><div class="nav-item"><a href="/qishao-notes/gpu/" class="nav-link">gpu</a></div><div class="nav-item"><a href="/qishao-notes/cpu/" class="nav-link">cpu</a></div><div class="nav-item"><a href="/qishao-notes/llm/" class="nav-link">ml&amp;llm</a></div><div class="nav-item"><a href="/qishao-notes/compiler/" class="nav-link">compiler</a></div><div class="nav-item"><a href="/qishao-notes/hbm/" class="nav-link">hbm</a></div><div class="nav-item"><a href="/qishao-notes/mix/" class="nav-link">program</a></div><div class="nav-item"><a href="/qishao-notes/unix/" class="nav-link">unix</a></div><div class="nav-item"><a href="https://blog.csdn.net/hit_shaoqi" target="_blank" rel="noopener noreferrer" class="nav-link external">
  CSDN
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></div> <a href="https://github.com/hitqshao/qishao-notes" target="_blank" rel="noopener noreferrer" class="repo-link">
    GitHub
    <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></nav></div></header> <div class="sidebar-mask"></div> <div class="sidebar-hover-trigger"></div> <aside class="sidebar" style="display:none;"><!----> <nav class="nav-links"><div class="nav-item"><a href="/qishao-notes/" class="nav-link">Home</a></div><div class="nav-item"><a href="/qishao-notes/gpu/" class="nav-link">gpu</a></div><div class="nav-item"><a href="/qishao-notes/cpu/" class="nav-link">cpu</a></div><div class="nav-item"><a href="/qishao-notes/llm/" class="nav-link">ml&amp;llm</a></div><div class="nav-item"><a href="/qishao-notes/compiler/" class="nav-link">compiler</a></div><div class="nav-item"><a href="/qishao-notes/hbm/" class="nav-link">hbm</a></div><div class="nav-item"><a href="/qishao-notes/mix/" class="nav-link">program</a></div><div class="nav-item"><a href="/qishao-notes/unix/" class="nav-link">unix</a></div><div class="nav-item"><a href="https://blog.csdn.net/hit_shaoqi" target="_blank" rel="noopener noreferrer" class="nav-link external">
  CSDN
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></div> <a href="https://github.com/hitqshao/qishao-notes" target="_blank" rel="noopener noreferrer" class="repo-link">
    GitHub
    <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></nav>  <ul class="sidebar-links"><li><a href="/qishao-notes/pages/cc7034/" class="sidebar-link">Operand Collector</a></li><li><a href="/qishao-notes/pages/2476ae/" class="sidebar-link">GPU WARP Scheduler</a></li><li><a href="/qishao-notes/pages/14769f/" class="sidebar-link">Precision Exception</a></li><li><a href="/qishao-notes/pages/44771e/" class="sidebar-link">Unified Memory Paper List</a></li><li><a href="/qishao-notes/pages/44871e/" class="sidebar-link">TensorCore Paper List</a></li><li><a href="/qishao-notes/pages/45871e/" class="sidebar-link">Memory Behaviour Paper List</a></li><li><a href="/qishao-notes/pages/45871f/" class="sidebar-link">GPU Virtualization Paper List</a></li><li><a href="/qishao-notes/pages/458720/" class="sidebar-link">Large Language Model Paper List</a></li><li><a href="/qishao-notes/pages/458721/" class="sidebar-link">GPU Simulator</a></li><li><a href="/qishao-notes/pages/458722/" class="sidebar-link">Architectural Survey</a></li><li><a href="/qishao-notes/pages/458724/" class="sidebar-link">Harnessing Integrated CPU-GPU System Memory for HPC a first look into Grace Hopper</a></li><li><a href="/qishao-notes/pages/458725/" class="sidebar-link">Understanding GPGPU-SIM 1 How to get Instruction</a></li><li><a href="/qishao-notes/pages/458726/" class="sidebar-link">Understanding GPGPU-SIM 2 Instruction Execution</a></li><li><a href="/qishao-notes/pages/458727/" class="sidebar-link">Understanding GPGPU-SIM 3 How is the simulation started</a></li><li><a href="/qishao-notes/pages/45872/" class="sidebar-link">Understanding GPGPU-SIM 4 Microarchitecture</a></li><li><a href="/qishao-notes/pages/45874/" class="sidebar-link">Understanding GPGPU-SIM 5  Memory Interface</a></li><li><a href="/qishao-notes/pages/45873/" class="sidebar-link">Warp Related Memory Optimization</a></li><li><a href="/qishao-notes/pages/45875/" class="sidebar-link">GPU Cache Coherency</a></li><li><a href="/qishao-notes/pages/45876/" class="sidebar-link">GPU Cache &amp; Memory Hirerarchy</a></li><li><a href="/qishao-notes/pages/45877/" class="sidebar-link">GPU TLB</a></li><li><a href="/qishao-notes/pages/45878/" class="sidebar-link">GPU Page Table Walk</a></li><li><a href="/qishao-notes/pages/45879/" class="sidebar-link">GPU Cache's Papers</a></li><li><a href="/qishao-notes/pages/45880/" class="sidebar-link">GPU WARP Mangement Papers</a></li><li><a href="/qishao-notes/pages/45882/" class="sidebar-link">GPU Unified Memory Innovations</a></li><li><a href="/qishao-notes/pages/45883/" class="sidebar-link">GPU MultiTask</a></li><li><a href="/qishao-notes/pages/45884/" class="sidebar-link">GPU Training Notes</a></li><li><a href="/qishao-notes/pages/45885/" class="sidebar-link">GPU Paper with Code</a></li><li><a href="/qishao-notes/pages/45886/" class="sidebar-link">GPU Driver &amp; Runtime &amp; Compliation</a></li><li><a href="/qishao-notes/pages/45887/" class="sidebar-link">Accel-Sim Simulator</a></li><li><a href="/qishao-notes/pages/45889/" class="sidebar-link">Understanding GPGPU-SIM 6 Memory Space</a></li><li><a href="/qishao-notes/pages/45890/" class="sidebar-link">GPU Insturctions</a></li><li><a href="/qishao-notes/pages/45892/" class="sidebar-link">GPU GEMM</a></li><li><a href="/qishao-notes/pages/45893/" class="sidebar-link">GPU Compiler Optimization Pass</a></li><li><a href="/qishao-notes/pages/45894/" class="sidebar-link">GPU GEMM</a></li><li><a href="/qishao-notes/pages/45895/" class="sidebar-link">GPU Workload Scheduling</a></li><li><a href="/qishao-notes/pages/45896/" class="sidebar-link">GPU Workload Scheduling</a></li><li><a href="/qishao-notes/pages/45897/" aria-current="page" class="active sidebar-link">GPU Cache Management</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header level2"><a href="/qishao-notes/pages/45897/#_1-22-adaptive-memory-side-last-level-gpu-caching" class="sidebar-link">1. [22] Adaptive Memory-Side Last-Level GPU Caching</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header level3"><a href="/qishao-notes/pages/45897/#dynamic-reconfiguration-rules" class="sidebar-link">Dynamic Reconfiguration Rules</a></li></ul></li><li class="sidebar-sub-header level2"><a href="/qishao-notes/pages/45897/#_2-83-2015-locality-driven-dynamic-gpu-cache-bypassing" class="sidebar-link">2. [83 2015] Locality-Driven Dynamic GPU Cache Bypassing</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header level3"><a href="/qishao-notes/pages/45897/#categories-of-applications" class="sidebar-link">Categories of Applications</a></li><li class="sidebar-sub-header level3"><a href="/qishao-notes/pages/45897/#bypassing-logic" class="sidebar-link">Bypassing logic</a></li><li class="sidebar-sub-header level3"><a href="/qishao-notes/pages/45897/#üìä-summary-table" class="sidebar-link">üìä Summary Table</a></li><li class="sidebar-sub-header level3"><a href="/qishao-notes/pages/45897/#üß†-design-implications" class="sidebar-link">üß† Design Implications</a></li><li class="sidebar-sub-header level3"><a href="/qishao-notes/pages/45897/#_3-9-2021-analyzing-and-leveraging-decoupled-l1-caches-in-gpus" class="sidebar-link">3. [9 2021] Analyzing and Leveraging Decoupled L1 Caches in GPUs</a></li><li class="sidebar-sub-header level3"><a href="/qishao-notes/pages/45897/#ideas" class="sidebar-link">Ideas</a></li></ul></li></ul></li><li><a href="/qishao-notes/pages/45898/" class="sidebar-link">GPU Multiworkload scheduling</a></li><li><a href="/qishao-notes/pages/47871e/" class="sidebar-link">TO READ</a></li></ul> </aside> <div><main class="page"><div class="theme-vdoing-wrapper bg-style-6"><div class="articleInfo-wrap" data-v-06225672><div class="articleInfo" data-v-06225672><ul class="breadcrumbs" data-v-06225672><li data-v-06225672><a href="/qishao-notes/" title="È¶ñÈ°µ" class="iconfont icon-home router-link-active" data-v-06225672></a></li> <li data-v-06225672><a href="/qishao-notes/gpu/#gpu" data-v-06225672>gpu</a></li></ul> <div class="info" data-v-06225672><div title="‰ΩúËÄÖ" class="author iconfont icon-touxiang" data-v-06225672><a href="https://github.com/hitqshao" target="_blank" title="‰ΩúËÄÖ" class="beLink" data-v-06225672>hitqishao</a></div> <div title="ÂàõÂª∫Êó∂Èó¥" class="date iconfont icon-riqi" data-v-06225672><a href="javascript:;" data-v-06225672>2025-06-28</a></div> <!----></div></div></div> <!----> <div class="content-wrapper"><div class="right-menu-wrapper"><div class="right-menu-margin"><div class="right-menu-title">ÁõÆÂΩï</div> <div class="right-menu-content"></div></div></div> <h1><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAB4AAAAeCAYAAAA7MK6iAAAAAXNSR0IArs4c6QAABGpJREFUSA3tVVtoXFUU3fvOI53UlmCaKIFmwEhsE7QK0ipFEdHEKpXaZGrp15SINsXUWvBDpBgQRKi0+KKoFeJHfZA+ED9KKoIU2gYD9UejTW4rVIzm0VSTziPzuNu1z507dibTTjL4U/DAzLn3nL3X2o91ziX6f9wMFdh6Jvbm9nNSV0msViVO6tN1Rm7NMu2OpeJ9lWBUTDxrJbYTS0hInuwciu9eLHlFxCLCZEk3MegsJmZ5K/JD6t7FkFdEvGUo1g7qJoG3MHImqRIn8/nzY1K9UPKKiJmtnUqHVE3Gbuay6vJE/N2FEmuxFjW2nUuE0yQXRRxLiTUAzs36zhZvOXJPdX850EVnnLZkB8prodQoM5JGj7Xk2mvC7JB8tG04Ef5PiXtG0UtxupRQSfTnBoCy554x18yJHI6I+G5Eru4LHmPJZEQsrvPUbMiA8G/WgMK7w7I+ez7++o2ANfbrjvaOl1tFMs+htG3IrZH9/hDX1Pr8Tc0UvH8tcX29KzAgIGcEkINyW5BF9x891hw6VYqgJHEk0huccS7vh3C6gTiODL+26huuBtbct8eZnqLML8PkxGYpuPZBqtqwkSjgc4mB5gbgig5i+y0UDK35LMxXisn9xQtK+nd26gTIHsHe/oblK/b29fUmN/8Y+9jAQrnBp56m1LcDlDp9irKTExSKduXJVWSqdBMA08pEJnEIOB3FPPMybu/oeV8zFeYN3xx576Q6RH+VmplE4ncQV5v+5rzSoyOU7PuEAg8g803PwBJ0CExno/jcMbN8tONYeOmHiuUNryvm3fRUy4tMPVLdAGkUhNWuggGrJcXPv+ouCjz0MKUHz1J2/E8IC9nqTabcxgaBYM0hPhD5Y65FsbxRQKxCQrDjDctW7PUM3HuZunFyifSAqEfuzCp48Il24luWUWZoyJCaPR82jE0+kFA643wRFVni4RYSq3ohJO2pZ7B5dO4xkDWbEpossJPLSrPjYID8rS2UHTlvyNxqIGsg674XJJ7vnh5L7PNwC4hh2sjCI96mzszOTpxLF0T7l88Yz7lAuK6OnL8gXLOnTvpzSb22YG8W7us3jSebFHeeqnXRG1vt+MoUM84LQIBmMsCTAcOauTh0T0l0neQK7m2bLMt2mGxU3HYssS0J2cdv5wljlPsrIuZLAG/2DOZIXgCYT8uMGZN+e2kSirfxZOPCsC0f24nTZzspnVn9VePS1Z5vubmAGGXG8ZFno9Hel0yfA5ZPhF7Dh972BQJ2qCpgH67lmWtBYbvk6sz02wjky2vXyz0XErP/kFB619js1BtwfOV4OPRqOQBjy3Qbk18vigUPPSD5ceHnwck7W9bhAqZdd7SuG7w4/P2F/GaJh8c7e9qgow+Q7cGBo+98WsLkuktFqiZabtXuQTu/Y5ETbR0v7tNSFnvrmu6pjdoan2KjMu8q/Hmj1EfCO2ZGfEIbIXKUlw8qaX9/b2oeSJmFksSeT/Fn0V3nSypChh4Gjh74ybO9aeZ/AN2dwciu2/MhAAAAAElFTkSuQmCC">GPU Cache Management<!----></h1> <!----> <div class="theme-vdoing-content content__default"><ol><li>[22] Adaptive Memory-Side Last-Level GPU Caching</li> <li>[83 2015] Locality-Driven Dynamic GPU Cache Bypassing</li> <li>[9 2021 HPCA] Analyzing and Leveraging Decoupled L1 Caches in GPUs</li></ol> <hr> <h2 id="_1-22-adaptive-memory-side-last-level-gpu-caching"><a href="#_1-22-adaptive-memory-side-last-level-gpu-caching" class="header-anchor">#</a> 1. [22] Adaptive Memory-Side Last-Level GPU Caching</h2> <ul><li>Private LLCs, which replicate shared data across multiple slices, provide higher bandwidth but suffer from higher miss rates.</li> <li>Shared LLCs avoid redundancy, reducing miss rates, but suffer bandwidth contention under high sharing.</li></ul> <p><img src="https://github.com/user-attachments/assets/fe7ab2e6-f43a-4881-b154-0782bb84bafc" alt="image"></p> <p>In the shared LLC organization, an LLC slice is shared by all SMs.</p> <p>The LLC slice for a given cache line is determined by a few address bits.</p> <p>Collectively, all LLC slices associated with a given memory controller cache the entire memory address space served by the memory controller.</p> <p>In the private LLC organization, an LLC slice is private to a cluster of SMs.</p> <p>An LLC slice caches the entire memory partition served by the respective memory controller for only a single cluster of SMs.</p> <p>The LLC slice for a cache line is thus determined by the cluster ID.</p> <p><img src="https://github.com/user-attachments/assets/86193f2f-2ad3-45c3-a78d-4b4c79db370d" alt="image"></p> <h3 id="dynamic-reconfiguration-rules"><a href="#dynamic-reconfiguration-rules" class="header-anchor">#</a> Dynamic Reconfiguration Rules</h3> <ul><li>Switch to private if:
<ul><li>Miss rate remains comparable (within 2%)</li> <li>Bandwidth gain outweighs miss rate penalty</li></ul></li> <li>Revert to shared:
<ul><li>At new kernel or time epoch</li></ul></li></ul> <p>How to profile/</p> <p>Set Dueling</p> <hr> <h2 id="_2-83-2015-locality-driven-dynamic-gpu-cache-bypassing"><a href="#_2-83-2015-locality-driven-dynamic-gpu-cache-bypassing" class="header-anchor">#</a> 2. [83 2015] Locality-Driven Dynamic GPU Cache Bypassing</h2> <h3 id="categories-of-applications"><a href="#categories-of-applications" class="header-anchor">#</a> Categories of Applications</h3> <p>The paper classifies GPU applications into three categories based on how they benefit (or suffer) from the L1 D-cache:</p> <h4 id="_1-cache-unfriendly-cnf"><a href="#_1-cache-unfriendly-cnf" class="header-anchor">#</a> 1. Cache-Unfriendly (CNF)</h4> <p>Definition: Applications that perform better when L1 D-cache is bypassed.</p> <p>Cause:</p> <ul><li>Low data reuse.</li> <li>Long reuse distances.</li></ul> <p>Leads to cache pollution and resource contention.</p> <p>Impact:</p> <ul><li>Memory pipeline stalls.</li> <li>Unnecessary eviction of useful lines.</li></ul> <p>Examples:</p> <ul><li>NW, SD2, LUD, HS, PTF, BH, SSSP</li></ul> <p>Performance gain: Up to 36% IPC improvement by bypassing L1.</p> <h4 id="_2-cache-insensitive-ci"><a href="#_2-cache-insensitive-ci" class="header-anchor">#</a> 2. Cache-Insensitive (CI)</h4> <p>Definition: Applications for which enabling/disabling L1 D-cache has little to no effect.</p> <p>Cause:</p> <ul><li>Heavy use of shared memory.</li> <li>Minimal or no global memory accesses.</li></ul> <p>Low memory intensity or high control divergence.</p> <p>Impact:</p> <ul><li>Cache behavior does not affect IPC.</li></ul> <p>Examples:</p> <ul><li>CFD, MYC, FFT, GS, PF, LFK</li></ul> <h4 id="_3-cache-friendly-cf"><a href="#_3-cache-friendly-cf" class="header-anchor">#</a> 3. Cache-Friendly (CF)</h4> <p>Definition: Applications that benefit from L1 D-cache.</p> <p>Cause:</p> <ul><li>High data reuse.</li> <li>Short reuse distances.</li></ul> <p>Impact:</p> <ul><li>Disabling L1 severely degrades performance.</li></ul> <p>Examples:</p> <ul><li><strong>MM, HT, SD1, BT, BP</strong></li></ul> <p>Performance loss: Up to 77% IPC drop when bypassed.</p> <ul><li>üîÅ Reuse Behavior Analysis</li> <li>üî¢ Reuse Count</li></ul> <p>What it shows: Number of times a memory address is reused.</p> <p><img src="https://github.com/user-attachments/assets/fcc652e0-5464-423b-af2b-e7dcf4b4c21b" alt="image"></p> <p>Observation:</p> <ul><li>CNF apps have few high-reuse accesses.</li> <li>Example: &gt;60% of accesses in NW, LUD are reused fewer than 3 times.</li></ul> <h4 id="üìè-reuse-distance-figure-4"><a href="#üìè-reuse-distance-figure-4" class="header-anchor">#</a> üìè Reuse Distance (Figure 4)</h4> <p>Definition: The number of unique memory accesses between two accesses to the same address.</p> <p>Example: Pattern A‚ÄìB‚ÄìC‚ÄìA ‚Üí reuse distance = 2.</p> <p>Observation:</p> <ul><li>CNF apps have long reuse distances: often 512‚Äì2048.</li></ul> <p><strong>These accesses cannot fit in L1 (e.g., 128B lines √ó 512 = 64KB).</strong></p> <p>üß† L1 vs. L2 Cache Bottlenecks
Experimental Setup (Figure 2)</p> <ul><li>The authors increase associativity and capacity of both L1 and L2 caches.</li></ul> <p>Findings:</p> <p><img src="https://github.com/user-attachments/assets/4dc6d668-e824-43ee-b0fd-ca229beb6ced" alt="image"></p> <p>Cache Level	Observation for CNF Apps</p> <ul><li><strong>L2	Performance is insensitive to L2 size and associativity. L2 is not a bottleneck.</strong></li> <li><strong>L1	Performance improves with larger/more associative L1. But needs impractically large L1 (e.g., 128-way, 16MB) to be effective. Still insufficient for some apps</strong>.</li></ul> <p>Conclusion: <strong>The L1 D-cache is the performance bottleneck for CNF workloads, not L2.</strong></p> <h3 id="bypassing-logic"><a href="#bypassing-logic" class="header-anchor">#</a> Bypassing logic</h3> <ul><li>On a tag store miss ‚Üí insert into tag store with RC = 1 ‚Üí bypass data store.</li> <li>On subsequent hits:
<ul><li>RC incremented.</li> <li>If RC &gt; threshold (e.g., 2), allocate data in the data store.</li></ul></li> <li>Replacement:
<ul><li>Tag store uses LFU with aging (decays RC to evict stale entries).</li></ul></li> <li>Data store uses existing GPU policies like LRU, RRIP.</li></ul> <p><img src="https://github.com/user-attachments/assets/01bb388a-a287-4514-b5b6-a628fc2453c2" alt="image"></p> <h3 id="üìä-summary-table"><a href="#üìä-summary-table" class="header-anchor">#</a> üìä Summary Table</h3> <p>Category	Behavior	Reuse Count	Reuse Distance	L1 Role	L2 Role</p> <ul><li>CNF	Cache hurts	Mostly low (1‚Äì2)	Long (512‚Äì2048)	Bottleneck, polluted	Not bottleneck</li> <li>CI	Cache irrelevant	N/A	N/A	Irrelevant	Irrelevant</li> <li>CF	Cache helps	High	Short	Critical	Less relevant</li></ul> <h3 id="üß†-design-implications"><a href="#üß†-design-implications" class="header-anchor">#</a> üß† Design Implications</h3> <ul><li>L1 D-cache should selectively cache data.</li> <li>A naive insert-everything policy causes: Thrashing in CNF apps.</li> <li>Performance degradation in CF apps if cache is bypassed.</li></ul> <p>The paper proposes a reuse-aware dynamic bypass mechanism that:</p> <ul><li>Tracks Reference Count (RC).</li> <li>Filters accesses based on reuse patterns.</li></ul> <p>Add extra information in the tag. But not the data.</p> <p><img src="https://github.com/user-attachments/assets/192f1f93-4aa2-4957-a8b8-fe96ffacc85f" alt="image"></p> <hr> <h3 id="_3-9-2021-analyzing-and-leveraging-decoupled-l1-caches-in-gpus"><a href="#_3-9-2021-analyzing-and-leveraging-decoupled-l1-caches-in-gpus" class="header-anchor">#</a> 3. [9 2021] Analyzing and Leveraging Decoupled L1 Caches in GPUs</h3> <h4 id="üìå-motivation"><a href="#üìå-motivation" class="header-anchor">#</a> üìå Motivation</h4> <p>Modern GPUs use private, tightly-coupled L1 caches per core. While this cache hierarchy helps address the memory wall by providing on-chip bandwidth, it introduces two key inefficiencies:</p> <p>Data Replication: Multiple cores may cache the same data, wasting total L1 capacity.</p> <p>Underutilized L1 Bandwidth: Many-to-few traffic from many L1s to fewer L2s causes poor L1 bandwidth utilization.</p> <h4 id="üöÄ-proposed-solution-dc-l1-decoupled-l1-cache-architecture"><a href="#üöÄ-proposed-solution-dc-l1-decoupled-l1-cache-architecture" class="header-anchor">#</a> üöÄ Proposed Solution: DC-L1 (DeCoupled L1) Cache Architecture</h4> <p><img src="https://github.com/user-attachments/assets/9e418409-59b4-4b91-8157-527bdf49be7c" alt="image"></p> <p>Core Idea:</p> <p><strong>Physically decouple L1 caches from the cores and aggregate them into a flexible organization called DC-L1, enabling:</strong></p> <ul><li>Reduced data replication.</li> <li>Improved bandwidth utilization.</li> <li>Tunable design between latency and capacity benefits.</li></ul> <p><img src="https://github.com/user-attachments/assets/6d38f1d0-873b-440e-88ed-90b7f166f151" alt="image"></p> <h4 id="üìê-architectural-designs-explored"><a href="#üìê-architectural-designs-explored" class="header-anchor">#</a> üìê Architectural Designs Explored</h4> <ol><li><strong>Private DC-L1 (PrY):</strong></li></ol> <p>Each DC-L1 is shared by a group of cores.</p> <p>Configurable aggregation granularity: e.g., Pr80 (1 core per DC-L1), Pr40 (2 cores/DC-L1), ‚Ä¶ Pr10 (8 cores/DC-L1).</p> <p>Benefit: reduces replication as cores share cache lines.</p> <p>üß† Tradeoff: Larger group size ‚Üí better replication reduction but worse bandwidth (more contention, fewer ports).</p> <p><img src="https://github.com/user-attachments/assets/d0cfb8b3-43c1-406f-824f-dd599d34952f" alt="image"></p> <ol start="2"><li><strong>Fully-Shared DC-L1 (Sh40):</strong></li></ol> <p><img src="https://github.com/user-attachments/assets/ff16cb91-c07a-4e60-8649-14067003b670" alt="image"></p> <p>All DC-L1 caches are part of a single logically shared cache space.</p> <p>Each DC-L1 owns a distinct part of the address space (similar to L2 bank slicing).</p> <p>Eliminates replication completely.</p> <p>üî¥ Problem: Requires a large 80√ó40 NoC crossbar ‚Üí high area and power overheads.</p> <ol start="3"><li><strong>Clustered Shared DC-L1 (ShY+CZ):</strong></li></ol> <p>Divide GPU cores and DC-L1s into clusters (e.g., 10 clusters of 8 cores and 4 DC-L1s each).</p> <p>Enable intra-cluster sharing, but allow inter-cluster replication.</p> <p>Tradeoff: reduced replication and reduced NoC cost.</p> <p><img src="https://github.com/user-attachments/assets/3b3352e5-4cf3-4407-8b84-d28c647191cc" alt="image"></p> <p>‚úÖ Chosen configuration: Sh40+C10 (40 DC-L1s, 10 clusters) ‚Üí balanced performance and cost.</p> <ol start="4"><li><strong>Sh40+C10+Boost:</strong></li></ol> <p>Same as above, but doubles the frequency of small crossbars in NoC#1.</p> <p>Leverages the small crossbar size to overcome latency/bandwidth loss from decoupling.</p> <h4 id="simulation-set-up"><a href="#simulation-set-up" class="header-anchor">#</a> Simulation Set up</h4> <p>We estimated such latency under the evaluated applications with Sh40+C10+Boost, and observed an overhead of <strong>54 cycles</strong>, on average.</p> <p>Another source of latency overhead is the aggregation of the DC-L1s.</p> <p>Specifically, with Sh40+C10+Boost, each DC-L1 cache is double the size of the baseline L1 cache, which adds a 7% increase in the DC-L1 access latency.</p> <p>Specifically, the DC-L1s with Sh40+C10+Boost have an access latency of 30 cycles, compared to <strong>28 cycles</strong> L1 access latency in the baseline.</p> <h4 id="insights-analysis"><a href="#insights-analysis" class="header-anchor">#</a> Insights &amp; Analysis</h4> <ul><li>Replication Sensitivity Classification</li> <li>Applications were deemed replication-sensitive if:</li> <li>Replication ratio &gt; 25%</li> <li>L1 miss rate &gt; 50%</li> <li>5% IPC gain with 16√ó L1 size</li></ul> <p>12 such applications (e.g., T-AlexNet, C-BFS) showed substantial gains from reducing L1 replication.</p> <h3 id="ideas"><a href="#ideas" class="header-anchor">#</a> Ideas</h3> <h4 id="_1-workload-aware-dc-l1-partitioning-for-multi-programmed-gpus"><a href="#_1-workload-aware-dc-l1-partitioning-for-multi-programmed-gpus" class="header-anchor">#</a> 1. Workload-aware DC-L1 Partitioning for Multi-programmed GPUs</h4> <p><strong>Problem</strong>: The paper evaluates replication and bandwidth under single workloads. In multi-tenant settings, different applications compete for DC-L1 capacity and bandwidth.</p> <p><strong>Research Idea</strong>: Dynamically partition DC-L1 clusters based on workload characteristics (e.g., memory intensity, data reuse, prefetch aggressiveness).</p> <p>Use runtime metrics (e.g., replication rate, MPKI) to drive partition reconfiguration.</p> <p><strong>Contribution</strong>: Design a low-overhead runtime or compiler hint system for adaptive DC-L1 clustering and mapping under multi-workload scenarios.</p> <h4 id="_2-replication-aware-compressed-dc-l1-caches"><a href="#_2-replication-aware-compressed-dc-l1-caches" class="header-anchor">#</a> 2. Replication-aware Compressed DC-L1 Caches</h4> <p><strong>Problem</strong>: Even clustered DC-L1s have limited capacity and still experience intra-cluster replication.</p> <p><strong>Research Idea</strong>: Implement base-delta or frequent-value compression in DC-L1 caches.</p> <ul><li>Exploit inter-core redundancy for cross-core dictionary compression or address-delta reuse.</li></ul> <p><strong>Twist</strong>: Co-design compression with replication-tracking to avoid storing multiple compressed versions of the same line.</p> <p><strong>Accel-Sim Angle</strong>: Add lightweight modeling of decompression latency and tag expansion overheads in the L1 cache pipeline.</p> <h4 id="_3-prefetch-filtering-and-scheduling-in-dc-l1s-for-irregular-workloads"><a href="#_3-prefetch-filtering-and-scheduling-in-dc-l1s-for-irregular-workloads" class="header-anchor">#</a> 3. Prefetch Filtering and Scheduling in DC-L1s for Irregular Workloads</h4> <p><strong>Problem:</strong> DC-L1 nodes create new prefetch timing and routing bottlenecks.</p> <p><strong>Research Idea:</strong> Introduce a prefetch scheduler in DC-L1 nodes that:</p> <ul><li>Differentiates between &quot;core-locality&quot; and &quot;remote-sharing&quot; prefetches.</li> <li>Uses reuse-distance or MSHR saturation tracking to decide eviction or forwarding.</li></ul> <p><strong>New Angle</strong>: Combine prefetch confidence with replication sensitivity to filter harmful prefetches that pollute shared DC-L1s.</p> <h4 id="_4-topology-aware-workload-to-dc-l1-mapping-in-multi-gpu-systems"><a href="#_4-topology-aware-workload-to-dc-l1-mapping-in-multi-gpu-systems" class="header-anchor">#</a> 4. Topology-aware Workload-to-DC-L1 Mapping in Multi-GPU Systems</h4> <p><strong>Problem:</strong> DC-L1s require networked routing; current cluster mapping is static.</p> <p><strong>Research Idea:</strong> In a multi-GPU setup (Accel-Sim or MCM-GPU-style), design dynamic workload mapping policies that:</p> <ul><li>Cluster memory-sharing CTAs to minimize DC-L1 hop distance.</li> <li>Balance NoC load across shared DC-L1s.</li></ul> <p><strong>Extension:</strong> Apply machine learning (e.g., reinforcement learning) to learn optimal DC-L1 routing and core affinity over time.</p></div></div> <!----> <div class="page-edit"><div class="edit-link"><a href="https://github.com/hitqshao/qishao-notes/edit/main/docs/03.gpu/37.gpu_cache.md" target="_blank" rel="noopener noreferrer">Â∏ÆÂä©Êàë‰ª¨ÊîπÂñÑÊ≠§È°µÈù¢</a> <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></div> <!----> <div class="last-updated"><span class="prefix">‰∏äÊ¨°Êõ¥Êñ∞:</span> <span class="time">2025/12/11, 16:14:20</span></div></div> <div class="page-nav-wapper"><div class="page-nav-centre-wrap"><a href="/qishao-notes/pages/45896/" class="page-nav-centre page-nav-centre-prev"><div class="tooltip">GPU Workload Scheduling</div></a> <a href="/qishao-notes/pages/45898/" class="page-nav-centre page-nav-centre-next"><div class="tooltip">GPU Multiworkload scheduling</div></a></div> <div class="page-nav"><p class="inner"><span class="prev">
        ‚Üê
        <a href="/qishao-notes/pages/45896/" class="prev">GPU Workload Scheduling</a></span> <span class="next"><a href="/qishao-notes/pages/45898/">GPU Multiworkload scheduling</a>‚Üí
      </span></p></div></div></div> <!----></main></div> <div class="footer"><div class="icons"><a href="https://github.com/hitqshao" title="GitHub" target="_blank" class="iconfont icon-github"></a><a href="mailto:hitqshao@163.com" title="ÂèëÈÇÆ‰ª∂" target="_blank" class="iconfont icon-youjian"></a><a href="https://gitee.com/hitqshao" title="Gitee" target="_blank" class="iconfont icon-gitee"></a></div> 
  Theme by
  <a href="https://github.com/xugaoyi/vuepress-theme-vdoing" target="_blank" title="Êú¨Á´ô‰∏ªÈ¢ò">Vdoing</a> 
    | Copyright ¬© 2022-2025
    <span>Eryajf | <a href="https://github.com/hitqshao/qishao-notes/blob/main/LICENSE" target="_blank">MIT License</a></span></div> <div class="buttons"><div title="ËøîÂõûÈ°∂ÈÉ®" class="button blur go-to-top iconfont icon-fanhuidingbu" style="display:none;"></div> <div title="ÂéªËØÑËÆ∫" class="button blur go-to-comment iconfont icon-pinglun" style="display:none;"></div> <div title="‰∏ªÈ¢òÊ®°Âºè" class="button blur theme-mode-but iconfont icon-zhuti"><ul class="select-box" style="display:none;"><li class="iconfont icon-zidong">
          Ë∑üÈöèÁ≥ªÁªü
        </li><li class="iconfont icon-rijianmoshi">
          ÊµÖËâ≤Ê®°Âºè
        </li><li class="iconfont icon-yejianmoshi">
          Ê∑±Ëâ≤Ê®°Âºè
        </li><li class="iconfont icon-yuedu">
          ÈòÖËØªÊ®°Âºè
        </li></ul></div></div> <!----> <!----> <!----></div><div class="global-ui"><!----></div></div>
    <script src="/qishao-notes/assets/js/app.e7ace6b1.js" defer></script><script src="/qishao-notes/assets/js/2.53666c0e.js" defer></script><script src="/qishao-notes/assets/js/83.2dc65497.js" defer></script>
  </body>
</html>

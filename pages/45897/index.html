<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>GPU Cache Management | CPU &amp; GPU Microarch. Qi Shao</title>
    <meta name="generator" content="VuePress 1.8.0">
    <link rel="stylesheet" href="custom.css">
    <script language="javascript" type="text/javascript" src="/qishao-notes/js/pgmanor-self.js"></script>
    <meta name="description" content="Computer System">
    <meta name="google-site-verification" content="66w5U9NY5gJWu7iBtHKMbhpXkV94jy31L_RHbvrZZzY">
    <meta name="keywords" content="Hitqishao,golang,vue,go-web,go-admin,go-ldap-admin">
    <meta name="theme-color" content="#11a8cd">
    <meta name="referrer" content="no-referrer-when-downgrade">
    
    <link rel="preload" href="/qishao-notes/assets/css/0.styles.685d6d32.css" as="style"><link rel="preload" href="/qishao-notes/assets/js/app.5850ffb4.js" as="script"><link rel="preload" href="/qishao-notes/assets/js/2.4d9050ab.js" as="script"><link rel="preload" href="/qishao-notes/assets/js/83.e639f5e2.js" as="script"><link rel="prefetch" href="/qishao-notes/assets/js/10.023fac80.js"><link rel="prefetch" href="/qishao-notes/assets/js/100.85be7dca.js"><link rel="prefetch" href="/qishao-notes/assets/js/101.dc419179.js"><link rel="prefetch" href="/qishao-notes/assets/js/102.6706c6d4.js"><link rel="prefetch" href="/qishao-notes/assets/js/103.86619558.js"><link rel="prefetch" href="/qishao-notes/assets/js/104.2ad0cee3.js"><link rel="prefetch" href="/qishao-notes/assets/js/105.09f92abe.js"><link rel="prefetch" href="/qishao-notes/assets/js/106.b83e9324.js"><link rel="prefetch" href="/qishao-notes/assets/js/107.725aa4ba.js"><link rel="prefetch" href="/qishao-notes/assets/js/108.cf18dc67.js"><link rel="prefetch" href="/qishao-notes/assets/js/109.be07d04a.js"><link rel="prefetch" href="/qishao-notes/assets/js/11.b001321c.js"><link rel="prefetch" href="/qishao-notes/assets/js/110.b23b3733.js"><link rel="prefetch" href="/qishao-notes/assets/js/111.1c9a25c8.js"><link rel="prefetch" href="/qishao-notes/assets/js/112.d0acb48e.js"><link rel="prefetch" href="/qishao-notes/assets/js/113.b2af57da.js"><link rel="prefetch" href="/qishao-notes/assets/js/114.c08eb4b9.js"><link rel="prefetch" href="/qishao-notes/assets/js/115.0b8f1e2b.js"><link rel="prefetch" href="/qishao-notes/assets/js/116.59a3b0df.js"><link rel="prefetch" href="/qishao-notes/assets/js/117.8964f796.js"><link rel="prefetch" href="/qishao-notes/assets/js/118.f0b19878.js"><link rel="prefetch" href="/qishao-notes/assets/js/119.67a6db8f.js"><link rel="prefetch" href="/qishao-notes/assets/js/12.dfe024be.js"><link rel="prefetch" href="/qishao-notes/assets/js/120.a5aa08d1.js"><link rel="prefetch" href="/qishao-notes/assets/js/121.6da13e9b.js"><link rel="prefetch" href="/qishao-notes/assets/js/122.adf8e4b2.js"><link rel="prefetch" href="/qishao-notes/assets/js/123.b0270000.js"><link rel="prefetch" href="/qishao-notes/assets/js/124.148eed01.js"><link rel="prefetch" href="/qishao-notes/assets/js/125.dee88642.js"><link rel="prefetch" href="/qishao-notes/assets/js/126.4bda76e1.js"><link rel="prefetch" href="/qishao-notes/assets/js/127.70d75f56.js"><link rel="prefetch" href="/qishao-notes/assets/js/128.0d908cea.js"><link rel="prefetch" href="/qishao-notes/assets/js/129.a0afd888.js"><link rel="prefetch" href="/qishao-notes/assets/js/13.5efab44e.js"><link rel="prefetch" href="/qishao-notes/assets/js/130.8409a0ee.js"><link rel="prefetch" href="/qishao-notes/assets/js/131.54f42aec.js"><link rel="prefetch" href="/qishao-notes/assets/js/132.10fd416e.js"><link rel="prefetch" href="/qishao-notes/assets/js/133.3a4234ba.js"><link rel="prefetch" href="/qishao-notes/assets/js/134.c759d591.js"><link rel="prefetch" href="/qishao-notes/assets/js/135.1563f59a.js"><link rel="prefetch" href="/qishao-notes/assets/js/136.a526c852.js"><link rel="prefetch" href="/qishao-notes/assets/js/137.349fccbc.js"><link rel="prefetch" href="/qishao-notes/assets/js/138.e568e87e.js"><link rel="prefetch" href="/qishao-notes/assets/js/139.80fb04c4.js"><link rel="prefetch" href="/qishao-notes/assets/js/14.c969a0b3.js"><link rel="prefetch" href="/qishao-notes/assets/js/140.271f177f.js"><link rel="prefetch" href="/qishao-notes/assets/js/141.870b5fb2.js"><link rel="prefetch" href="/qishao-notes/assets/js/142.f95dab0f.js"><link rel="prefetch" href="/qishao-notes/assets/js/143.17886040.js"><link rel="prefetch" href="/qishao-notes/assets/js/144.c581af60.js"><link rel="prefetch" href="/qishao-notes/assets/js/15.df53a168.js"><link rel="prefetch" href="/qishao-notes/assets/js/16.a1bb9d23.js"><link rel="prefetch" href="/qishao-notes/assets/js/17.71442f47.js"><link rel="prefetch" href="/qishao-notes/assets/js/18.a1cec71e.js"><link rel="prefetch" href="/qishao-notes/assets/js/19.6c64a4be.js"><link rel="prefetch" href="/qishao-notes/assets/js/20.0d206441.js"><link rel="prefetch" href="/qishao-notes/assets/js/21.58619e3b.js"><link rel="prefetch" href="/qishao-notes/assets/js/22.773b472b.js"><link rel="prefetch" href="/qishao-notes/assets/js/23.acc5896d.js"><link rel="prefetch" href="/qishao-notes/assets/js/24.8b39ef40.js"><link rel="prefetch" href="/qishao-notes/assets/js/25.ff2ed822.js"><link rel="prefetch" href="/qishao-notes/assets/js/26.331f17d4.js"><link rel="prefetch" href="/qishao-notes/assets/js/27.914a6398.js"><link rel="prefetch" href="/qishao-notes/assets/js/28.b0085c20.js"><link rel="prefetch" href="/qishao-notes/assets/js/29.22d52e9a.js"><link rel="prefetch" href="/qishao-notes/assets/js/3.99819a65.js"><link rel="prefetch" href="/qishao-notes/assets/js/30.a0eefaec.js"><link rel="prefetch" href="/qishao-notes/assets/js/31.b1ae7f6b.js"><link rel="prefetch" href="/qishao-notes/assets/js/32.feb23e67.js"><link rel="prefetch" href="/qishao-notes/assets/js/33.8ffc297f.js"><link rel="prefetch" href="/qishao-notes/assets/js/34.3e885138.js"><link rel="prefetch" href="/qishao-notes/assets/js/35.a6b5adef.js"><link rel="prefetch" href="/qishao-notes/assets/js/36.093d9d1a.js"><link rel="prefetch" href="/qishao-notes/assets/js/37.fe8a50b6.js"><link rel="prefetch" href="/qishao-notes/assets/js/38.577877cc.js"><link rel="prefetch" href="/qishao-notes/assets/js/39.68da95f4.js"><link rel="prefetch" href="/qishao-notes/assets/js/4.c90ef165.js"><link rel="prefetch" href="/qishao-notes/assets/js/40.21270a40.js"><link rel="prefetch" href="/qishao-notes/assets/js/41.bee13bcd.js"><link rel="prefetch" href="/qishao-notes/assets/js/42.e1e6eeac.js"><link rel="prefetch" href="/qishao-notes/assets/js/43.20d7ac8f.js"><link rel="prefetch" href="/qishao-notes/assets/js/44.9139dac1.js"><link rel="prefetch" href="/qishao-notes/assets/js/45.8b6602f3.js"><link rel="prefetch" href="/qishao-notes/assets/js/46.79799614.js"><link rel="prefetch" href="/qishao-notes/assets/js/47.ad15993e.js"><link rel="prefetch" href="/qishao-notes/assets/js/48.73187f25.js"><link rel="prefetch" href="/qishao-notes/assets/js/49.79517f64.js"><link rel="prefetch" href="/qishao-notes/assets/js/5.e4bdf3ee.js"><link rel="prefetch" href="/qishao-notes/assets/js/50.383cf514.js"><link rel="prefetch" href="/qishao-notes/assets/js/51.267ac7b3.js"><link rel="prefetch" href="/qishao-notes/assets/js/52.1bb5adf4.js"><link rel="prefetch" href="/qishao-notes/assets/js/53.6c4ab0d4.js"><link rel="prefetch" href="/qishao-notes/assets/js/54.2777a73c.js"><link rel="prefetch" href="/qishao-notes/assets/js/55.faf9c3ce.js"><link rel="prefetch" href="/qishao-notes/assets/js/56.5c37e921.js"><link rel="prefetch" href="/qishao-notes/assets/js/57.c956efdb.js"><link rel="prefetch" href="/qishao-notes/assets/js/58.acb30547.js"><link rel="prefetch" href="/qishao-notes/assets/js/59.474e2517.js"><link rel="prefetch" href="/qishao-notes/assets/js/6.4f0f340b.js"><link rel="prefetch" href="/qishao-notes/assets/js/60.257e363f.js"><link rel="prefetch" href="/qishao-notes/assets/js/61.f19094e5.js"><link rel="prefetch" href="/qishao-notes/assets/js/62.5459930a.js"><link rel="prefetch" href="/qishao-notes/assets/js/63.60339392.js"><link rel="prefetch" href="/qishao-notes/assets/js/64.84a4e203.js"><link rel="prefetch" href="/qishao-notes/assets/js/65.8aff9616.js"><link rel="prefetch" href="/qishao-notes/assets/js/66.82293b3c.js"><link rel="prefetch" href="/qishao-notes/assets/js/67.141cb180.js"><link rel="prefetch" href="/qishao-notes/assets/js/68.76a443ae.js"><link rel="prefetch" href="/qishao-notes/assets/js/69.3ca9a961.js"><link rel="prefetch" href="/qishao-notes/assets/js/7.d5bd83ad.js"><link rel="prefetch" href="/qishao-notes/assets/js/70.cef4957c.js"><link rel="prefetch" href="/qishao-notes/assets/js/71.a4f4e7d5.js"><link rel="prefetch" href="/qishao-notes/assets/js/72.070db250.js"><link rel="prefetch" href="/qishao-notes/assets/js/73.30ad9c0b.js"><link rel="prefetch" href="/qishao-notes/assets/js/74.88825c83.js"><link rel="prefetch" href="/qishao-notes/assets/js/75.b3660535.js"><link rel="prefetch" href="/qishao-notes/assets/js/76.11230362.js"><link rel="prefetch" href="/qishao-notes/assets/js/77.0fcdf383.js"><link rel="prefetch" href="/qishao-notes/assets/js/78.0075faa9.js"><link rel="prefetch" href="/qishao-notes/assets/js/79.010789b5.js"><link rel="prefetch" href="/qishao-notes/assets/js/8.10049696.js"><link rel="prefetch" href="/qishao-notes/assets/js/80.26bda327.js"><link rel="prefetch" href="/qishao-notes/assets/js/81.4125c387.js"><link rel="prefetch" href="/qishao-notes/assets/js/82.65299337.js"><link rel="prefetch" href="/qishao-notes/assets/js/84.6ceb15a3.js"><link rel="prefetch" href="/qishao-notes/assets/js/85.1fd6a95d.js"><link rel="prefetch" href="/qishao-notes/assets/js/86.ec5f7f0b.js"><link rel="prefetch" href="/qishao-notes/assets/js/87.a3141d95.js"><link rel="prefetch" href="/qishao-notes/assets/js/88.48b663af.js"><link rel="prefetch" href="/qishao-notes/assets/js/89.a79fe340.js"><link rel="prefetch" href="/qishao-notes/assets/js/9.9ff8f5de.js"><link rel="prefetch" href="/qishao-notes/assets/js/90.dd525248.js"><link rel="prefetch" href="/qishao-notes/assets/js/91.0bbcf4ff.js"><link rel="prefetch" href="/qishao-notes/assets/js/92.843b8146.js"><link rel="prefetch" href="/qishao-notes/assets/js/93.5ae969aa.js"><link rel="prefetch" href="/qishao-notes/assets/js/94.7f1a14f3.js"><link rel="prefetch" href="/qishao-notes/assets/js/95.d8b7f2b3.js"><link rel="prefetch" href="/qishao-notes/assets/js/96.bc25b0f0.js"><link rel="prefetch" href="/qishao-notes/assets/js/97.5e7777c0.js"><link rel="prefetch" href="/qishao-notes/assets/js/98.5788defc.js"><link rel="prefetch" href="/qishao-notes/assets/js/99.5375a66d.js">
    <link rel="stylesheet" href="/qishao-notes/assets/css/0.styles.685d6d32.css">
  </head>
  <body class="theme-mode-light">
    <div id="app" data-server-rendered="true"><div class="theme-container sidebar-open have-rightmenu"><header class="navbar blur"><div title="目录" class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/qishao-notes/" class="home-link router-link-active"><!----> <span class="site-name">CPU &amp; GPU Microarch. Qi Shao</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/qishao-notes/" class="nav-link">Home</a></div><div class="nav-item"><a href="/qishao-notes/gpu/" class="nav-link">gpu</a></div><div class="nav-item"><a href="/qishao-notes/cpu/" class="nav-link">cpu</a></div><div class="nav-item"><a href="/qishao-notes/llm/" class="nav-link">ml&amp;llm</a></div><div class="nav-item"><a href="/qishao-notes/compiler/" class="nav-link">compiler</a></div><div class="nav-item"><a href="/qishao-notes/hbm/" class="nav-link">hbm</a></div><div class="nav-item"><a href="/qishao-notes/mix/" class="nav-link">program</a></div><div class="nav-item"><a href="/qishao-notes/unix/" class="nav-link">unix</a></div><div class="nav-item"><a href="https://blog.csdn.net/hit_shaoqi" target="_blank" rel="noopener noreferrer" class="nav-link external">
  CSDN
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></div> <a href="https://github.com/hitqshao/qishao-notes" target="_blank" rel="noopener noreferrer" class="repo-link">
    GitHub
    <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></nav></div></header> <div class="sidebar-mask"></div> <div class="sidebar-hover-trigger"></div> <aside class="sidebar" style="display:none;"><!----> <nav class="nav-links"><div class="nav-item"><a href="/qishao-notes/" class="nav-link">Home</a></div><div class="nav-item"><a href="/qishao-notes/gpu/" class="nav-link">gpu</a></div><div class="nav-item"><a href="/qishao-notes/cpu/" class="nav-link">cpu</a></div><div class="nav-item"><a href="/qishao-notes/llm/" class="nav-link">ml&amp;llm</a></div><div class="nav-item"><a href="/qishao-notes/compiler/" class="nav-link">compiler</a></div><div class="nav-item"><a href="/qishao-notes/hbm/" class="nav-link">hbm</a></div><div class="nav-item"><a href="/qishao-notes/mix/" class="nav-link">program</a></div><div class="nav-item"><a href="/qishao-notes/unix/" class="nav-link">unix</a></div><div class="nav-item"><a href="https://blog.csdn.net/hit_shaoqi" target="_blank" rel="noopener noreferrer" class="nav-link external">
  CSDN
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></div> <a href="https://github.com/hitqshao/qishao-notes" target="_blank" rel="noopener noreferrer" class="repo-link">
    GitHub
    <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></nav>  <ul class="sidebar-links"><li><a href="/qishao-notes/pages/cc7034/" class="sidebar-link">Operand Collector</a></li><li><a href="/qishao-notes/pages/2476ae/" class="sidebar-link">GPU WARP Scheduler</a></li><li><a href="/qishao-notes/pages/14769f/" class="sidebar-link">Precision Exception</a></li><li><a href="/qishao-notes/pages/44771e/" class="sidebar-link">Unified Memory Paper List</a></li><li><a href="/qishao-notes/pages/44871e/" class="sidebar-link">TensorCore Paper List</a></li><li><a href="/qishao-notes/pages/45871e/" class="sidebar-link">Memory Behaviour Paper List</a></li><li><a href="/qishao-notes/pages/45871f/" class="sidebar-link">GPU Virtualization Paper List</a></li><li><a href="/qishao-notes/pages/458720/" class="sidebar-link">Large Language Model Paper List</a></li><li><a href="/qishao-notes/pages/458721/" class="sidebar-link">GPU Simulator</a></li><li><a href="/qishao-notes/pages/458722/" class="sidebar-link">Architectural Survey</a></li><li><a href="/qishao-notes/pages/458724/" class="sidebar-link">Harnessing Integrated CPU-GPU System Memory for HPC a first look into Grace Hopper</a></li><li><a href="/qishao-notes/pages/458725/" class="sidebar-link">Understanding GPGPU-SIM 1 How to get Instruction</a></li><li><a href="/qishao-notes/pages/458726/" class="sidebar-link">Understanding GPGPU-SIM 2 Instruction Execution</a></li><li><a href="/qishao-notes/pages/458727/" class="sidebar-link">Understanding GPGPU-SIM 3 How is the simulation started</a></li><li><a href="/qishao-notes/pages/45872/" class="sidebar-link">Understanding GPGPU-SIM 4 Microarchitecture</a></li><li><a href="/qishao-notes/pages/45874/" class="sidebar-link">Understanding GPGPU-SIM 5  Memory Interface</a></li><li><a href="/qishao-notes/pages/45873/" class="sidebar-link">Warp Related Memory Optimization</a></li><li><a href="/qishao-notes/pages/45875/" class="sidebar-link">GPU Cache Coherency</a></li><li><a href="/qishao-notes/pages/45876/" class="sidebar-link">GPU Cache &amp; Memory Hirerarchy</a></li><li><a href="/qishao-notes/pages/45877/" class="sidebar-link">GPU TLB</a></li><li><a href="/qishao-notes/pages/45878/" class="sidebar-link">GPU Page Table Walk</a></li><li><a href="/qishao-notes/pages/45879/" class="sidebar-link">GPU Cache's Papers</a></li><li><a href="/qishao-notes/pages/45880/" class="sidebar-link">GPU WARP Mangement Papers</a></li><li><a href="/qishao-notes/pages/45882/" class="sidebar-link">GPU Unified Memory Innovations</a></li><li><a href="/qishao-notes/pages/45883/" class="sidebar-link">GPU MultiTask</a></li><li><a href="/qishao-notes/pages/45884/" class="sidebar-link">GPU Training Notes</a></li><li><a href="/qishao-notes/pages/45885/" class="sidebar-link">GPU Paper with Code</a></li><li><a href="/qishao-notes/pages/45886/" class="sidebar-link">GPU Driver &amp; Runtime &amp; Compliation</a></li><li><a href="/qishao-notes/pages/45887/" class="sidebar-link">Accel-Sim Simulator</a></li><li><a href="/qishao-notes/pages/45889/" class="sidebar-link">Understanding GPGPU-SIM 6 Memory Space</a></li><li><a href="/qishao-notes/pages/45890/" class="sidebar-link">GPU Insturctions</a></li><li><a href="/qishao-notes/pages/45892/" class="sidebar-link">GPU GEMM</a></li><li><a href="/qishao-notes/pages/45893/" class="sidebar-link">GPU Compiler Optimization Pass</a></li><li><a href="/qishao-notes/pages/45894/" class="sidebar-link">GPU GEMM</a></li><li><a href="/qishao-notes/pages/45895/" class="sidebar-link">GPU Workload Scheduling</a></li><li><a href="/qishao-notes/pages/45896/" class="sidebar-link">GPU Workload Scheduling</a></li><li><a href="/qishao-notes/pages/45897/" aria-current="page" class="active sidebar-link">GPU Cache Management</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header level2"><a href="/qishao-notes/pages/45897/#_1-22-adaptive-memory-side-last-level-gpu-caching" class="sidebar-link">1. [22] Adaptive Memory-Side Last-Level GPU Caching</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header level3"><a href="/qishao-notes/pages/45897/#dynamic-reconfiguration-rules" class="sidebar-link">Dynamic Reconfiguration Rules</a></li></ul></li><li class="sidebar-sub-header level2"><a href="/qishao-notes/pages/45897/#_2-83-2015-locality-driven-dynamic-gpu-cache-bypassing" class="sidebar-link">2. [83 2015] Locality-Driven Dynamic GPU Cache Bypassing</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header level3"><a href="/qishao-notes/pages/45897/#categories-of-applications" class="sidebar-link">Categories of Applications</a></li><li class="sidebar-sub-header level3"><a href="/qishao-notes/pages/45897/#bypassing-logic" class="sidebar-link">Bypassing logic</a></li><li class="sidebar-sub-header level3"><a href="/qishao-notes/pages/45897/#📊-summary-table" class="sidebar-link">📊 Summary Table</a></li><li class="sidebar-sub-header level3"><a href="/qishao-notes/pages/45897/#🧠-design-implications" class="sidebar-link">🧠 Design Implications</a></li><li class="sidebar-sub-header level3"><a href="/qishao-notes/pages/45897/#_3-9-2021-analyzing-and-leveraging-decoupled-l1-caches-in-gpus" class="sidebar-link">3. [9 2021] Analyzing and Leveraging Decoupled L1 Caches in GPUs</a></li><li class="sidebar-sub-header level3"><a href="/qishao-notes/pages/45897/#ideas" class="sidebar-link">Ideas</a></li></ul></li></ul></li><li><a href="/qishao-notes/pages/45898/" class="sidebar-link">GPU Multiworkload scheduling</a></li><li><a href="/qishao-notes/pages/47871e/" class="sidebar-link">TO READ</a></li></ul> </aside> <div><main class="page"><div class="theme-vdoing-wrapper bg-style-6"><div class="articleInfo-wrap" data-v-06225672><div class="articleInfo" data-v-06225672><ul class="breadcrumbs" data-v-06225672><li data-v-06225672><a href="/qishao-notes/" title="首页" class="iconfont icon-home router-link-active" data-v-06225672></a></li> <li data-v-06225672><a href="/qishao-notes/gpu/#gpu" data-v-06225672>gpu</a></li></ul> <div class="info" data-v-06225672><div title="作者" class="author iconfont icon-touxiang" data-v-06225672><a href="https://github.com/hitqshao" target="_blank" title="作者" class="beLink" data-v-06225672>hitqishao</a></div> <div title="创建时间" class="date iconfont icon-riqi" data-v-06225672><a href="javascript:;" data-v-06225672>2025-06-28</a></div> <!----></div></div></div> <!----> <div class="content-wrapper"><div class="right-menu-wrapper"><div class="right-menu-margin"><div class="right-menu-title">目录</div> <div class="right-menu-content"></div></div></div> <h1><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAB4AAAAeCAYAAAA7MK6iAAAAAXNSR0IArs4c6QAABGpJREFUSA3tVVtoXFUU3fvOI53UlmCaKIFmwEhsE7QK0ipFEdHEKpXaZGrp15SINsXUWvBDpBgQRKi0+KKoFeJHfZA+ED9KKoIU2gYD9UejTW4rVIzm0VSTziPzuNu1z507dibTTjL4U/DAzLn3nL3X2o91ziX6f9wMFdh6Jvbm9nNSV0msViVO6tN1Rm7NMu2OpeJ9lWBUTDxrJbYTS0hInuwciu9eLHlFxCLCZEk3MegsJmZ5K/JD6t7FkFdEvGUo1g7qJoG3MHImqRIn8/nzY1K9UPKKiJmtnUqHVE3Gbuay6vJE/N2FEmuxFjW2nUuE0yQXRRxLiTUAzs36zhZvOXJPdX850EVnnLZkB8prodQoM5JGj7Xk2mvC7JB8tG04Ef5PiXtG0UtxupRQSfTnBoCy554x18yJHI6I+G5Eru4LHmPJZEQsrvPUbMiA8G/WgMK7w7I+ez7++o2ANfbrjvaOl1tFMs+htG3IrZH9/hDX1Pr8Tc0UvH8tcX29KzAgIGcEkINyW5BF9x891hw6VYqgJHEk0huccS7vh3C6gTiODL+26huuBtbct8eZnqLML8PkxGYpuPZBqtqwkSjgc4mB5gbgig5i+y0UDK35LMxXisn9xQtK+nd26gTIHsHe/oblK/b29fUmN/8Y+9jAQrnBp56m1LcDlDp9irKTExSKduXJVWSqdBMA08pEJnEIOB3FPPMybu/oeV8zFeYN3xx576Q6RH+VmplE4ncQV5v+5rzSoyOU7PuEAg8g803PwBJ0CExno/jcMbN8tONYeOmHiuUNryvm3fRUy4tMPVLdAGkUhNWuggGrJcXPv+ouCjz0MKUHz1J2/E8IC9nqTabcxgaBYM0hPhD5Y65FsbxRQKxCQrDjDctW7PUM3HuZunFyifSAqEfuzCp48Il24luWUWZoyJCaPR82jE0+kFA643wRFVni4RYSq3ohJO2pZ7B5dO4xkDWbEpossJPLSrPjYID8rS2UHTlvyNxqIGsg674XJJ7vnh5L7PNwC4hh2sjCI96mzszOTpxLF0T7l88Yz7lAuK6OnL8gXLOnTvpzSb22YG8W7us3jSebFHeeqnXRG1vt+MoUM84LQIBmMsCTAcOauTh0T0l0neQK7m2bLMt2mGxU3HYssS0J2cdv5wljlPsrIuZLAG/2DOZIXgCYT8uMGZN+e2kSirfxZOPCsC0f24nTZzspnVn9VePS1Z5vubmAGGXG8ZFno9Hel0yfA5ZPhF7Dh972BQJ2qCpgH67lmWtBYbvk6sz02wjky2vXyz0XErP/kFB619js1BtwfOV4OPRqOQBjy3Qbk18vigUPPSD5ceHnwck7W9bhAqZdd7SuG7w4/P2F/GaJh8c7e9qgow+Q7cGBo+98WsLkuktFqiZabtXuQTu/Y5ETbR0v7tNSFnvrmu6pjdoan2KjMu8q/Hmj1EfCO2ZGfEIbIXKUlw8qaX9/b2oeSJmFksSeT/Fn0V3nSypChh4Gjh74ybO9aeZ/AN2dwciu2/MhAAAAAElFTkSuQmCC">GPU Cache Management<!----></h1> <!----> <div class="theme-vdoing-content content__default"><ol><li>[22] Adaptive Memory-Side Last-Level GPU Caching</li> <li>[83 2015] Locality-Driven Dynamic GPU Cache Bypassing</li> <li>[9 2021 HPCA] Analyzing and Leveraging Decoupled L1 Caches in GPUs</li></ol> <hr> <h2 id="_1-22-adaptive-memory-side-last-level-gpu-caching"><a href="#_1-22-adaptive-memory-side-last-level-gpu-caching" class="header-anchor">#</a> 1. [22] Adaptive Memory-Side Last-Level GPU Caching</h2> <ul><li>Private LLCs, which replicate shared data across multiple slices, provide higher bandwidth but suffer from higher miss rates.</li> <li>Shared LLCs avoid redundancy, reducing miss rates, but suffer bandwidth contention under high sharing.</li></ul> <p><img src="https://github.com/user-attachments/assets/fe7ab2e6-f43a-4881-b154-0782bb84bafc" alt="image"></p> <p>In the shared LLC organization, an LLC slice is shared by all SMs.</p> <p>The LLC slice for a given cache line is determined by a few address bits.</p> <p>Collectively, all LLC slices associated with a given memory controller cache the entire memory address space served by the memory controller.</p> <p>In the private LLC organization, an LLC slice is private to a cluster of SMs.</p> <p>An LLC slice caches the entire memory partition served by the respective memory controller for only a single cluster of SMs.</p> <p>The LLC slice for a cache line is thus determined by the cluster ID.</p> <p><img src="https://github.com/user-attachments/assets/86193f2f-2ad3-45c3-a78d-4b4c79db370d" alt="image"></p> <h3 id="dynamic-reconfiguration-rules"><a href="#dynamic-reconfiguration-rules" class="header-anchor">#</a> Dynamic Reconfiguration Rules</h3> <ul><li>Switch to private if:
<ul><li>Miss rate remains comparable (within 2%)</li> <li>Bandwidth gain outweighs miss rate penalty</li></ul></li> <li>Revert to shared:
<ul><li>At new kernel or time epoch</li></ul></li></ul> <p>How to profile/</p> <p>Set Dueling</p> <hr> <h2 id="_2-83-2015-locality-driven-dynamic-gpu-cache-bypassing"><a href="#_2-83-2015-locality-driven-dynamic-gpu-cache-bypassing" class="header-anchor">#</a> 2. [83 2015] Locality-Driven Dynamic GPU Cache Bypassing</h2> <h3 id="categories-of-applications"><a href="#categories-of-applications" class="header-anchor">#</a> Categories of Applications</h3> <p>The paper classifies GPU applications into three categories based on how they benefit (or suffer) from the L1 D-cache:</p> <h4 id="_1-cache-unfriendly-cnf"><a href="#_1-cache-unfriendly-cnf" class="header-anchor">#</a> 1. Cache-Unfriendly (CNF)</h4> <p>Definition: Applications that perform better when L1 D-cache is bypassed.</p> <p>Cause:</p> <ul><li>Low data reuse.</li> <li>Long reuse distances.</li></ul> <p>Leads to cache pollution and resource contention.</p> <p>Impact:</p> <ul><li>Memory pipeline stalls.</li> <li>Unnecessary eviction of useful lines.</li></ul> <p>Examples:</p> <ul><li>NW, SD2, LUD, HS, PTF, BH, SSSP</li></ul> <p>Performance gain: Up to 36% IPC improvement by bypassing L1.</p> <h4 id="_2-cache-insensitive-ci"><a href="#_2-cache-insensitive-ci" class="header-anchor">#</a> 2. Cache-Insensitive (CI)</h4> <p>Definition: Applications for which enabling/disabling L1 D-cache has little to no effect.</p> <p>Cause:</p> <ul><li>Heavy use of shared memory.</li> <li>Minimal or no global memory accesses.</li></ul> <p>Low memory intensity or high control divergence.</p> <p>Impact:</p> <ul><li>Cache behavior does not affect IPC.</li></ul> <p>Examples:</p> <ul><li>CFD, MYC, FFT, GS, PF, LFK</li></ul> <h4 id="_3-cache-friendly-cf"><a href="#_3-cache-friendly-cf" class="header-anchor">#</a> 3. Cache-Friendly (CF)</h4> <p>Definition: Applications that benefit from L1 D-cache.</p> <p>Cause:</p> <ul><li>High data reuse.</li> <li>Short reuse distances.</li></ul> <p>Impact:</p> <ul><li>Disabling L1 severely degrades performance.</li></ul> <p>Examples:</p> <ul><li><strong>MM, HT, SD1, BT, BP</strong></li></ul> <p>Performance loss: Up to 77% IPC drop when bypassed.</p> <ul><li>🔁 Reuse Behavior Analysis</li> <li>🔢 Reuse Count</li></ul> <p>What it shows: Number of times a memory address is reused.</p> <p><img src="https://github.com/user-attachments/assets/fcc652e0-5464-423b-af2b-e7dcf4b4c21b" alt="image"></p> <p>Observation:</p> <ul><li>CNF apps have few high-reuse accesses.</li> <li>Example: &gt;60% of accesses in NW, LUD are reused fewer than 3 times.</li></ul> <h4 id="📏-reuse-distance-figure-4"><a href="#📏-reuse-distance-figure-4" class="header-anchor">#</a> 📏 Reuse Distance (Figure 4)</h4> <p>Definition: The number of unique memory accesses between two accesses to the same address.</p> <p>Example: Pattern A–B–C–A → reuse distance = 2.</p> <p>Observation:</p> <ul><li>CNF apps have long reuse distances: often 512–2048.</li></ul> <p><strong>These accesses cannot fit in L1 (e.g., 128B lines × 512 = 64KB).</strong></p> <p>🧠 L1 vs. L2 Cache Bottlenecks
Experimental Setup (Figure 2)</p> <ul><li>The authors increase associativity and capacity of both L1 and L2 caches.</li></ul> <p>Findings:</p> <p><img src="https://github.com/user-attachments/assets/4dc6d668-e824-43ee-b0fd-ca229beb6ced" alt="image"></p> <p>Cache Level	Observation for CNF Apps</p> <ul><li><strong>L2	Performance is insensitive to L2 size and associativity. L2 is not a bottleneck.</strong></li> <li><strong>L1	Performance improves with larger/more associative L1. But needs impractically large L1 (e.g., 128-way, 16MB) to be effective. Still insufficient for some apps</strong>.</li></ul> <p>Conclusion: <strong>The L1 D-cache is the performance bottleneck for CNF workloads, not L2.</strong></p> <h3 id="bypassing-logic"><a href="#bypassing-logic" class="header-anchor">#</a> Bypassing logic</h3> <ul><li>On a tag store miss → insert into tag store with RC = 1 → bypass data store.</li> <li>On subsequent hits:
<ul><li>RC incremented.</li> <li>If RC &gt; threshold (e.g., 2), allocate data in the data store.</li></ul></li> <li>Replacement:
<ul><li>Tag store uses LFU with aging (decays RC to evict stale entries).</li></ul></li> <li>Data store uses existing GPU policies like LRU, RRIP.</li></ul> <p><img src="https://github.com/user-attachments/assets/01bb388a-a287-4514-b5b6-a628fc2453c2" alt="image"></p> <h3 id="📊-summary-table"><a href="#📊-summary-table" class="header-anchor">#</a> 📊 Summary Table</h3> <p>Category	Behavior	Reuse Count	Reuse Distance	L1 Role	L2 Role</p> <ul><li>CNF	Cache hurts	Mostly low (1–2)	Long (512–2048)	Bottleneck, polluted	Not bottleneck</li> <li>CI	Cache irrelevant	N/A	N/A	Irrelevant	Irrelevant</li> <li>CF	Cache helps	High	Short	Critical	Less relevant</li></ul> <h3 id="🧠-design-implications"><a href="#🧠-design-implications" class="header-anchor">#</a> 🧠 Design Implications</h3> <ul><li>L1 D-cache should selectively cache data.</li> <li>A naive insert-everything policy causes: Thrashing in CNF apps.</li> <li>Performance degradation in CF apps if cache is bypassed.</li></ul> <p>The paper proposes a reuse-aware dynamic bypass mechanism that:</p> <ul><li>Tracks Reference Count (RC).</li> <li>Filters accesses based on reuse patterns.</li></ul> <p>Add extra information in the tag. But not the data.</p> <p><img src="https://github.com/user-attachments/assets/192f1f93-4aa2-4957-a8b8-fe96ffacc85f" alt="image"></p> <hr> <h3 id="_3-9-2021-analyzing-and-leveraging-decoupled-l1-caches-in-gpus"><a href="#_3-9-2021-analyzing-and-leveraging-decoupled-l1-caches-in-gpus" class="header-anchor">#</a> 3. [9 2021] Analyzing and Leveraging Decoupled L1 Caches in GPUs</h3> <h4 id="📌-motivation"><a href="#📌-motivation" class="header-anchor">#</a> 📌 Motivation</h4> <p>Modern GPUs use private, tightly-coupled L1 caches per core. While this cache hierarchy helps address the memory wall by providing on-chip bandwidth, it introduces two key inefficiencies:</p> <p>Data Replication: Multiple cores may cache the same data, wasting total L1 capacity.</p> <p>Underutilized L1 Bandwidth: Many-to-few traffic from many L1s to fewer L2s causes poor L1 bandwidth utilization.</p> <h4 id="🚀-proposed-solution-dc-l1-decoupled-l1-cache-architecture"><a href="#🚀-proposed-solution-dc-l1-decoupled-l1-cache-architecture" class="header-anchor">#</a> 🚀 Proposed Solution: DC-L1 (DeCoupled L1) Cache Architecture</h4> <p><img src="https://github.com/user-attachments/assets/9e418409-59b4-4b91-8157-527bdf49be7c" alt="image"></p> <p>Core Idea:</p> <p><strong>Physically decouple L1 caches from the cores and aggregate them into a flexible organization called DC-L1, enabling:</strong></p> <ul><li>Reduced data replication.</li> <li>Improved bandwidth utilization.</li> <li>Tunable design between latency and capacity benefits.</li></ul> <p><img src="https://github.com/user-attachments/assets/6d38f1d0-873b-440e-88ed-90b7f166f151" alt="image"></p> <h4 id="📐-architectural-designs-explored"><a href="#📐-architectural-designs-explored" class="header-anchor">#</a> 📐 Architectural Designs Explored</h4> <ol><li><strong>Private DC-L1 (PrY):</strong></li></ol> <p>Each DC-L1 is shared by a group of cores.</p> <p>Configurable aggregation granularity: e.g., Pr80 (1 core per DC-L1), Pr40 (2 cores/DC-L1), … Pr10 (8 cores/DC-L1).</p> <p>Benefit: reduces replication as cores share cache lines.</p> <p>🧠 Tradeoff: Larger group size → better replication reduction but worse bandwidth (more contention, fewer ports).</p> <p><img src="https://github.com/user-attachments/assets/d0cfb8b3-43c1-406f-824f-dd599d34952f" alt="image"></p> <ol start="2"><li><strong>Fully-Shared DC-L1 (Sh40):</strong></li></ol> <p><img src="https://github.com/user-attachments/assets/ff16cb91-c07a-4e60-8649-14067003b670" alt="image"></p> <p>All DC-L1 caches are part of a single logically shared cache space.</p> <p>Each DC-L1 owns a distinct part of the address space (similar to L2 bank slicing).</p> <p>Eliminates replication completely.</p> <p>🔴 Problem: Requires a large 80×40 NoC crossbar → high area and power overheads.</p> <ol start="3"><li><strong>Clustered Shared DC-L1 (ShY+CZ):</strong></li></ol> <p>Divide GPU cores and DC-L1s into clusters (e.g., 10 clusters of 8 cores and 4 DC-L1s each).</p> <p>Enable intra-cluster sharing, but allow inter-cluster replication.</p> <p>Tradeoff: reduced replication and reduced NoC cost.</p> <p><img src="https://github.com/user-attachments/assets/3b3352e5-4cf3-4407-8b84-d28c647191cc" alt="image"></p> <p>✅ Chosen configuration: Sh40+C10 (40 DC-L1s, 10 clusters) → balanced performance and cost.</p> <ol start="4"><li><strong>Sh40+C10+Boost:</strong></li></ol> <p>Same as above, but doubles the frequency of small crossbars in NoC#1.</p> <p>Leverages the small crossbar size to overcome latency/bandwidth loss from decoupling.</p> <h4 id="simulation-set-up"><a href="#simulation-set-up" class="header-anchor">#</a> Simulation Set up</h4> <p>We estimated such latency under the evaluated applications with Sh40+C10+Boost, and observed an overhead of <strong>54 cycles</strong>, on average.</p> <p>Another source of latency overhead is the aggregation of the DC-L1s.</p> <p>Specifically, with Sh40+C10+Boost, each DC-L1 cache is double the size of the baseline L1 cache, which adds a 7% increase in the DC-L1 access latency.</p> <p>Specifically, the DC-L1s with Sh40+C10+Boost have an access latency of 30 cycles, compared to <strong>28 cycles</strong> L1 access latency in the baseline.</p> <h4 id="insights-analysis"><a href="#insights-analysis" class="header-anchor">#</a> Insights &amp; Analysis</h4> <ul><li>Replication Sensitivity Classification</li> <li>Applications were deemed replication-sensitive if:</li> <li>Replication ratio &gt; 25%</li> <li>L1 miss rate &gt; 50%</li> <li>5% IPC gain with 16× L1 size</li></ul> <p>12 such applications (e.g., T-AlexNet, C-BFS) showed substantial gains from reducing L1 replication.</p> <h3 id="ideas"><a href="#ideas" class="header-anchor">#</a> Ideas</h3> <h4 id="_1-workload-aware-dc-l1-partitioning-for-multi-programmed-gpus"><a href="#_1-workload-aware-dc-l1-partitioning-for-multi-programmed-gpus" class="header-anchor">#</a> 1. Workload-aware DC-L1 Partitioning for Multi-programmed GPUs</h4> <p><strong>Problem</strong>: The paper evaluates replication and bandwidth under single workloads. In multi-tenant settings, different applications compete for DC-L1 capacity and bandwidth.</p> <p><strong>Research Idea</strong>: Dynamically partition DC-L1 clusters based on workload characteristics (e.g., memory intensity, data reuse, prefetch aggressiveness).</p> <p>Use runtime metrics (e.g., replication rate, MPKI) to drive partition reconfiguration.</p> <p><strong>Contribution</strong>: Design a low-overhead runtime or compiler hint system for adaptive DC-L1 clustering and mapping under multi-workload scenarios.</p> <h4 id="_2-replication-aware-compressed-dc-l1-caches"><a href="#_2-replication-aware-compressed-dc-l1-caches" class="header-anchor">#</a> 2. Replication-aware Compressed DC-L1 Caches</h4> <p><strong>Problem</strong>: Even clustered DC-L1s have limited capacity and still experience intra-cluster replication.</p> <p><strong>Research Idea</strong>: Implement base-delta or frequent-value compression in DC-L1 caches.</p> <ul><li>Exploit inter-core redundancy for cross-core dictionary compression or address-delta reuse.</li></ul> <p><strong>Twist</strong>: Co-design compression with replication-tracking to avoid storing multiple compressed versions of the same line.</p> <p><strong>Accel-Sim Angle</strong>: Add lightweight modeling of decompression latency and tag expansion overheads in the L1 cache pipeline.</p> <h4 id="_3-prefetch-filtering-and-scheduling-in-dc-l1s-for-irregular-workloads"><a href="#_3-prefetch-filtering-and-scheduling-in-dc-l1s-for-irregular-workloads" class="header-anchor">#</a> 3. Prefetch Filtering and Scheduling in DC-L1s for Irregular Workloads</h4> <p><strong>Problem:</strong> DC-L1 nodes create new prefetch timing and routing bottlenecks.</p> <p><strong>Research Idea:</strong> Introduce a prefetch scheduler in DC-L1 nodes that:</p> <ul><li>Differentiates between &quot;core-locality&quot; and &quot;remote-sharing&quot; prefetches.</li> <li>Uses reuse-distance or MSHR saturation tracking to decide eviction or forwarding.</li></ul> <p><strong>New Angle</strong>: Combine prefetch confidence with replication sensitivity to filter harmful prefetches that pollute shared DC-L1s.</p> <h4 id="_4-topology-aware-workload-to-dc-l1-mapping-in-multi-gpu-systems"><a href="#_4-topology-aware-workload-to-dc-l1-mapping-in-multi-gpu-systems" class="header-anchor">#</a> 4. Topology-aware Workload-to-DC-L1 Mapping in Multi-GPU Systems</h4> <p><strong>Problem:</strong> DC-L1s require networked routing; current cluster mapping is static.</p> <p><strong>Research Idea:</strong> In a multi-GPU setup (Accel-Sim or MCM-GPU-style), design dynamic workload mapping policies that:</p> <ul><li>Cluster memory-sharing CTAs to minimize DC-L1 hop distance.</li> <li>Balance NoC load across shared DC-L1s.</li></ul> <p><strong>Extension:</strong> Apply machine learning (e.g., reinforcement learning) to learn optimal DC-L1 routing and core affinity over time.</p></div></div> <!----> <div class="page-edit"><div class="edit-link"><a href="https://github.com/hitqshao/qishao-notes/edit/main/docs/03.gpu/37.gpu_cache.md" target="_blank" rel="noopener noreferrer">帮助我们改善此页面</a> <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></div> <!----> <div class="last-updated"><span class="prefix">上次更新:</span> <span class="time">2025/09/16, 21:55:41</span></div></div> <div class="page-nav-wapper"><div class="page-nav-centre-wrap"><a href="/qishao-notes/pages/45896/" class="page-nav-centre page-nav-centre-prev"><div class="tooltip">GPU Workload Scheduling</div></a> <a href="/qishao-notes/pages/45898/" class="page-nav-centre page-nav-centre-next"><div class="tooltip">GPU Multiworkload scheduling</div></a></div> <div class="page-nav"><p class="inner"><span class="prev">
        ←
        <a href="/qishao-notes/pages/45896/" class="prev">GPU Workload Scheduling</a></span> <span class="next"><a href="/qishao-notes/pages/45898/">GPU Multiworkload scheduling</a>→
      </span></p></div></div></div> <!----></main></div> <div class="footer"><div class="icons"><a href="https://github.com/hitqshao" title="GitHub" target="_blank" class="iconfont icon-github"></a><a href="mailto:hitqshao@163.com" title="发邮件" target="_blank" class="iconfont icon-youjian"></a><a href="https://gitee.com/hitqshao" title="Gitee" target="_blank" class="iconfont icon-gitee"></a></div> 
  Theme by
  <a href="https://github.com/xugaoyi/vuepress-theme-vdoing" target="_blank" title="本站主题">Vdoing</a> 
    | Copyright © 2022-2025
    <span>Eryajf | <a href="https://github.com/hitqshao/qishao-notes/blob/main/LICENSE" target="_blank">MIT License</a></span></div> <div class="buttons"><div title="返回顶部" class="button blur go-to-top iconfont icon-fanhuidingbu" style="display:none;"></div> <div title="去评论" class="button blur go-to-comment iconfont icon-pinglun" style="display:none;"></div> <div title="主题模式" class="button blur theme-mode-but iconfont icon-zhuti"><ul class="select-box" style="display:none;"><li class="iconfont icon-zidong">
          跟随系统
        </li><li class="iconfont icon-rijianmoshi">
          浅色模式
        </li><li class="iconfont icon-yejianmoshi">
          深色模式
        </li><li class="iconfont icon-yuedu">
          阅读模式
        </li></ul></div></div> <!----> <!----> <!----></div><div class="global-ui"><!----></div></div>
    <script src="/qishao-notes/assets/js/app.5850ffb4.js" defer></script><script src="/qishao-notes/assets/js/2.4d9050ab.js" defer></script><script src="/qishao-notes/assets/js/83.e639f5e2.js" defer></script>
  </body>
</html>

<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>GPU WARP Mangement Papers | CPU &amp; GPU Microarch. Qi Shao</title>
    <meta name="generator" content="VuePress 1.8.0">
    <link rel="stylesheet" href="custom.css">
    <script language="javascript" type="text/javascript" src="/qishao-notes/js/pgmanor-self.js"></script>
    <meta name="description" content="Computer System">
    <meta name="google-site-verification" content="66w5U9NY5gJWu7iBtHKMbhpXkV94jy31L_RHbvrZZzY">
    <meta name="keywords" content="Hitqishao,golang,vue,go-web,go-admin,go-ldap-admin">
    <meta name="theme-color" content="#11a8cd">
    <meta name="referrer" content="no-referrer-when-downgrade">
    
    <link rel="preload" href="/qishao-notes/assets/css/0.styles.922e50b3.css" as="style"><link rel="preload" href="/qishao-notes/assets/js/app.4ea71f9a.js" as="script"><link rel="preload" href="/qishao-notes/assets/js/2.9488d546.js" as="script"><link rel="preload" href="/qishao-notes/assets/js/58.ebe669f3.js" as="script"><link rel="prefetch" href="/qishao-notes/assets/js/10.c86ef341.js"><link rel="prefetch" href="/qishao-notes/assets/js/100.cc547ac3.js"><link rel="prefetch" href="/qishao-notes/assets/js/11.475a6daa.js"><link rel="prefetch" href="/qishao-notes/assets/js/12.395da613.js"><link rel="prefetch" href="/qishao-notes/assets/js/13.ec4e4351.js"><link rel="prefetch" href="/qishao-notes/assets/js/14.398474f0.js"><link rel="prefetch" href="/qishao-notes/assets/js/15.08e9a735.js"><link rel="prefetch" href="/qishao-notes/assets/js/16.3922e5ea.js"><link rel="prefetch" href="/qishao-notes/assets/js/17.549c09b6.js"><link rel="prefetch" href="/qishao-notes/assets/js/18.9f16959c.js"><link rel="prefetch" href="/qishao-notes/assets/js/19.7e55c536.js"><link rel="prefetch" href="/qishao-notes/assets/js/20.71be2b02.js"><link rel="prefetch" href="/qishao-notes/assets/js/21.79f3ceff.js"><link rel="prefetch" href="/qishao-notes/assets/js/22.5653cd65.js"><link rel="prefetch" href="/qishao-notes/assets/js/23.7d82567b.js"><link rel="prefetch" href="/qishao-notes/assets/js/24.2f210439.js"><link rel="prefetch" href="/qishao-notes/assets/js/25.f1d3d1bd.js"><link rel="prefetch" href="/qishao-notes/assets/js/26.ea51e514.js"><link rel="prefetch" href="/qishao-notes/assets/js/27.ac0f6a8b.js"><link rel="prefetch" href="/qishao-notes/assets/js/28.c36d3ee8.js"><link rel="prefetch" href="/qishao-notes/assets/js/29.2894c23c.js"><link rel="prefetch" href="/qishao-notes/assets/js/3.c6cba72d.js"><link rel="prefetch" href="/qishao-notes/assets/js/30.845402ca.js"><link rel="prefetch" href="/qishao-notes/assets/js/31.2a536d4f.js"><link rel="prefetch" href="/qishao-notes/assets/js/32.06343959.js"><link rel="prefetch" href="/qishao-notes/assets/js/33.b49e195c.js"><link rel="prefetch" href="/qishao-notes/assets/js/34.187ea3b0.js"><link rel="prefetch" href="/qishao-notes/assets/js/35.82d60c42.js"><link rel="prefetch" href="/qishao-notes/assets/js/36.9ba0ca67.js"><link rel="prefetch" href="/qishao-notes/assets/js/37.0cc8968e.js"><link rel="prefetch" href="/qishao-notes/assets/js/38.e170c40e.js"><link rel="prefetch" href="/qishao-notes/assets/js/39.2f0158f0.js"><link rel="prefetch" href="/qishao-notes/assets/js/4.43d9d83d.js"><link rel="prefetch" href="/qishao-notes/assets/js/40.485804d3.js"><link rel="prefetch" href="/qishao-notes/assets/js/41.bbe65f24.js"><link rel="prefetch" href="/qishao-notes/assets/js/42.9a84b4fe.js"><link rel="prefetch" href="/qishao-notes/assets/js/43.dd61f910.js"><link rel="prefetch" href="/qishao-notes/assets/js/44.9f340b2f.js"><link rel="prefetch" href="/qishao-notes/assets/js/45.34e8323d.js"><link rel="prefetch" href="/qishao-notes/assets/js/46.7657e973.js"><link rel="prefetch" href="/qishao-notes/assets/js/47.33df5712.js"><link rel="prefetch" href="/qishao-notes/assets/js/48.ed2999ed.js"><link rel="prefetch" href="/qishao-notes/assets/js/49.59a2f1da.js"><link rel="prefetch" href="/qishao-notes/assets/js/5.e730adaa.js"><link rel="prefetch" href="/qishao-notes/assets/js/50.1e9623d9.js"><link rel="prefetch" href="/qishao-notes/assets/js/51.8c78866f.js"><link rel="prefetch" href="/qishao-notes/assets/js/52.93caeab2.js"><link rel="prefetch" href="/qishao-notes/assets/js/53.87e3caca.js"><link rel="prefetch" href="/qishao-notes/assets/js/54.2934a37c.js"><link rel="prefetch" href="/qishao-notes/assets/js/55.dceb53a2.js"><link rel="prefetch" href="/qishao-notes/assets/js/56.58914c2d.js"><link rel="prefetch" href="/qishao-notes/assets/js/57.e17d8083.js"><link rel="prefetch" href="/qishao-notes/assets/js/59.e3c782e9.js"><link rel="prefetch" href="/qishao-notes/assets/js/6.c5a71d89.js"><link rel="prefetch" href="/qishao-notes/assets/js/60.bfc85820.js"><link rel="prefetch" href="/qishao-notes/assets/js/61.4d8772e9.js"><link rel="prefetch" href="/qishao-notes/assets/js/62.5428035f.js"><link rel="prefetch" href="/qishao-notes/assets/js/63.b7b6a76d.js"><link rel="prefetch" href="/qishao-notes/assets/js/64.38b49078.js"><link rel="prefetch" href="/qishao-notes/assets/js/65.4316ab04.js"><link rel="prefetch" href="/qishao-notes/assets/js/66.d84776f9.js"><link rel="prefetch" href="/qishao-notes/assets/js/67.eaf66463.js"><link rel="prefetch" href="/qishao-notes/assets/js/68.70e07188.js"><link rel="prefetch" href="/qishao-notes/assets/js/69.1dbfb147.js"><link rel="prefetch" href="/qishao-notes/assets/js/7.1cb9872e.js"><link rel="prefetch" href="/qishao-notes/assets/js/70.8ee80196.js"><link rel="prefetch" href="/qishao-notes/assets/js/71.29068aa5.js"><link rel="prefetch" href="/qishao-notes/assets/js/72.7a75537c.js"><link rel="prefetch" href="/qishao-notes/assets/js/73.1bdf9824.js"><link rel="prefetch" href="/qishao-notes/assets/js/74.ade5b2af.js"><link rel="prefetch" href="/qishao-notes/assets/js/75.a9212cbe.js"><link rel="prefetch" href="/qishao-notes/assets/js/76.c8d54deb.js"><link rel="prefetch" href="/qishao-notes/assets/js/77.d759c239.js"><link rel="prefetch" href="/qishao-notes/assets/js/78.ecd6ffd7.js"><link rel="prefetch" href="/qishao-notes/assets/js/79.b131f236.js"><link rel="prefetch" href="/qishao-notes/assets/js/8.b77ca1ef.js"><link rel="prefetch" href="/qishao-notes/assets/js/80.2cb14f3d.js"><link rel="prefetch" href="/qishao-notes/assets/js/81.34ad79b1.js"><link rel="prefetch" href="/qishao-notes/assets/js/82.0b754642.js"><link rel="prefetch" href="/qishao-notes/assets/js/83.b2c1fd87.js"><link rel="prefetch" href="/qishao-notes/assets/js/84.390971d8.js"><link rel="prefetch" href="/qishao-notes/assets/js/85.c71dde83.js"><link rel="prefetch" href="/qishao-notes/assets/js/86.65f6f816.js"><link rel="prefetch" href="/qishao-notes/assets/js/87.b0729009.js"><link rel="prefetch" href="/qishao-notes/assets/js/88.930ec243.js"><link rel="prefetch" href="/qishao-notes/assets/js/89.f777933d.js"><link rel="prefetch" href="/qishao-notes/assets/js/9.ce3d6321.js"><link rel="prefetch" href="/qishao-notes/assets/js/90.d25884e4.js"><link rel="prefetch" href="/qishao-notes/assets/js/91.81f6ece8.js"><link rel="prefetch" href="/qishao-notes/assets/js/92.9bbb8a3c.js"><link rel="prefetch" href="/qishao-notes/assets/js/93.1e1dbc96.js"><link rel="prefetch" href="/qishao-notes/assets/js/94.4bf2a4b2.js"><link rel="prefetch" href="/qishao-notes/assets/js/95.d372f54b.js"><link rel="prefetch" href="/qishao-notes/assets/js/96.2e408834.js"><link rel="prefetch" href="/qishao-notes/assets/js/97.6bc12b88.js"><link rel="prefetch" href="/qishao-notes/assets/js/98.4ad60bf2.js"><link rel="prefetch" href="/qishao-notes/assets/js/99.1c38a6fc.js">
    <link rel="stylesheet" href="/qishao-notes/assets/css/0.styles.922e50b3.css">
  </head>
  <body class="theme-mode-light">
    <div id="app" data-server-rendered="true"><div class="theme-container sidebar-open have-rightmenu"><header class="navbar blur"><div title="目录" class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/qishao-notes/" class="home-link router-link-active"><!----> <span class="site-name">CPU &amp; GPU Microarch. Qi Shao</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/qishao-notes/" class="nav-link">Home</a></div><div class="nav-item"><a href="/qishao-notes/gpu/" class="nav-link">gpu</a></div><div class="nav-item"><a href="/qishao-notes/cpu/" class="nav-link">cpu</a></div><div class="nav-item"><a href="/qishao-notes/llm/" class="nav-link">ml&amp;llm</a></div><div class="nav-item"><a href="/qishao-notes/compiler/" class="nav-link">compiler</a></div><div class="nav-item"><a href="/qishao-notes/hbm/" class="nav-link">hbm</a></div><div class="nav-item"><a href="/qishao-notes/mix/" class="nav-link">program</a></div><div class="nav-item"><a href="/qishao-notes/unix/" class="nav-link">unix</a></div><div class="nav-item"><a href="https://blog.csdn.net/hit_shaoqi" target="_blank" rel="noopener noreferrer" class="nav-link external">
  CSDN
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></div> <a href="https://github.com/hitqshao/qishao-notes" target="_blank" rel="noopener noreferrer" class="repo-link">
    GitHub
    <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></nav></div></header> <div class="sidebar-mask"></div> <div class="sidebar-hover-trigger"></div> <aside class="sidebar" style="display:none;"><!----> <nav class="nav-links"><div class="nav-item"><a href="/qishao-notes/" class="nav-link">Home</a></div><div class="nav-item"><a href="/qishao-notes/gpu/" class="nav-link">gpu</a></div><div class="nav-item"><a href="/qishao-notes/cpu/" class="nav-link">cpu</a></div><div class="nav-item"><a href="/qishao-notes/llm/" class="nav-link">ml&amp;llm</a></div><div class="nav-item"><a href="/qishao-notes/compiler/" class="nav-link">compiler</a></div><div class="nav-item"><a href="/qishao-notes/hbm/" class="nav-link">hbm</a></div><div class="nav-item"><a href="/qishao-notes/mix/" class="nav-link">program</a></div><div class="nav-item"><a href="/qishao-notes/unix/" class="nav-link">unix</a></div><div class="nav-item"><a href="https://blog.csdn.net/hit_shaoqi" target="_blank" rel="noopener noreferrer" class="nav-link external">
  CSDN
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></div> <a href="https://github.com/hitqshao/qishao-notes" target="_blank" rel="noopener noreferrer" class="repo-link">
    GitHub
    <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></nav>  <ul class="sidebar-links"><li><a href="/qishao-notes/pages/cc7034/" class="sidebar-link">Operand Collector</a></li><li><a href="/qishao-notes/pages/2476ae/" class="sidebar-link">GPU WARP Scheduler</a></li><li><a href="/qishao-notes/pages/14769f/" class="sidebar-link">Precision Exception</a></li><li><a href="/qishao-notes/pages/44771e/" class="sidebar-link">Unified Memory Paper List</a></li><li><a href="/qishao-notes/pages/44871e/" class="sidebar-link">TensorCore Paper List</a></li><li><a href="/qishao-notes/pages/45871e/" class="sidebar-link">Memory Behaviour Paper List</a></li><li><a href="/qishao-notes/pages/45871f/" class="sidebar-link">GPU Virtualization Paper List</a></li><li><a href="/qishao-notes/pages/458720/" class="sidebar-link">Large Language Model Paper List</a></li><li><a href="/qishao-notes/pages/458721/" class="sidebar-link">GPU Simulator</a></li><li><a href="/qishao-notes/pages/458722/" class="sidebar-link">Architectural Survey</a></li><li><a href="/qishao-notes/pages/458724/" class="sidebar-link">Harnessing Integrated CPU-GPU System Memory for HPC a first look into Grace Hopper</a></li><li><a href="/qishao-notes/pages/458725/" class="sidebar-link">Understanding GPGPU-SIM 1 How to get Instruction</a></li><li><a href="/qishao-notes/pages/458726/" class="sidebar-link">Understanding GPGPU-SIM 2 Instruction Execution</a></li><li><a href="/qishao-notes/pages/458727/" class="sidebar-link">Understanding GPGPU-SIM 3 How is the simulation started</a></li><li><a href="/qishao-notes/pages/45872/" class="sidebar-link">Understanding GPGPU-SIM 4 Microarchitecture</a></li><li><a href="/qishao-notes/pages/45874/" class="sidebar-link">Understanding GPGPU-SIM 5  Memory Interface</a></li><li><a href="/qishao-notes/pages/45873/" class="sidebar-link">Warp Related Memory Optimization</a></li><li><a href="/qishao-notes/pages/45875/" class="sidebar-link">GPU Cache Coherency</a></li><li><a href="/qishao-notes/pages/45876/" class="sidebar-link">GPU Cache &amp; Memory Hirerarchy</a></li><li><a href="/qishao-notes/pages/45877/" class="sidebar-link">GPU TLB</a></li><li><a href="/qishao-notes/pages/45878/" class="sidebar-link">GPU Page Table Walk</a></li><li><a href="/qishao-notes/pages/45879/" class="sidebar-link">GPU Cache's Papers</a></li><li><a href="/qishao-notes/pages/45880/" aria-current="page" class="active sidebar-link">GPU WARP Mangement Papers</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header level2"><a href="/qishao-notes/pages/45880/#_1-improving-gpu-perfromance-via-large-warps-and-two-level-warp-scheduling" class="sidebar-link">1. Improving GPU Perfromance via Large Warps and Two-Level Warp Scheduling</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header level3"><a href="/qishao-notes/pages/45880/#main-idea-in-short" class="sidebar-link">Main Idea in Short</a></li><li class="sidebar-sub-header level3"><a href="/qishao-notes/pages/45880/#framework" class="sidebar-link">Framework</a></li><li class="sidebar-sub-header level3"><a href="/qishao-notes/pages/45880/#misc" class="sidebar-link">MISC</a></li><li class="sidebar-sub-header level3"><a href="/qishao-notes/pages/45880/#core-pipeline" class="sidebar-link">Core Pipeline</a></li></ul></li><li class="sidebar-sub-header level2"><a href="/qishao-notes/pages/45880/#_2-improving-gpgpu-resource-utilization-through-alternative-thread-blocking-scheduling" class="sidebar-link">2. Improving GPGPU Resource Utilization Through Alternative Thread Blocking Scheduling</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header level3"><a href="/qishao-notes/pages/45880/#main-idea-in-short-2" class="sidebar-link">Main Idea in Short</a></li><li class="sidebar-sub-header level3"><a href="/qishao-notes/pages/45880/#introduction" class="sidebar-link">Introduction</a></li><li class="sidebar-sub-header level3"><a href="/qishao-notes/pages/45880/#two-different-scheduling-cta-policy-for-different-workloads" class="sidebar-link">Two Different scheduling CTA policy for different workloads</a></li><li class="sidebar-sub-header level3"><a href="/qishao-notes/pages/45880/#observation" class="sidebar-link">Observation</a></li><li class="sidebar-sub-header level3"><a href="/qishao-notes/pages/45880/#method" class="sidebar-link">Method</a></li><li class="sidebar-sub-header level3"><a href="/qishao-notes/pages/45880/#framework-2" class="sidebar-link">Framework</a></li></ul></li><li class="sidebar-sub-header level2"><a href="/qishao-notes/pages/45880/#_3-exploiting-inter-warp-heterogeneity-to-improve-gpgpu-performance" class="sidebar-link">3. Exploiting Inter-Warp Heterogeneity to Improve GPGPU Performance</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header level3"><a href="/qishao-notes/pages/45880/#main-idea-in-short-3" class="sidebar-link">Main Idea in Short</a></li><li class="sidebar-sub-header level3"><a href="/qishao-notes/pages/45880/#observation-2" class="sidebar-link">Observation</a></li><li class="sidebar-sub-header level3"><a href="/qishao-notes/pages/45880/#components" class="sidebar-link">Components</a></li></ul></li></ul></li><li><a href="/qishao-notes/pages/45882/" class="sidebar-link">GPU Unified Memory Innovations</a></li><li><a href="/qishao-notes/pages/45883/" class="sidebar-link">GPU MultiTask</a></li><li><a href="/qishao-notes/pages/45884/" class="sidebar-link">GPU Training Notes</a></li><li><a href="/qishao-notes/pages/45885/" class="sidebar-link">GPU Paper with Code</a></li><li><a href="/qishao-notes/pages/45886/" class="sidebar-link">GPU Workload Characteristics</a></li><li><a href="/qishao-notes/pages/45887/" class="sidebar-link">Accel-Sim Simulator</a></li><li><a href="/qishao-notes/pages/45889/" class="sidebar-link">Understanding GPGPU-SIM 6 Memory Space</a></li><li><a href="/qishao-notes/pages/47871e/" class="sidebar-link">TO READ</a></li></ul> </aside> <div><main class="page"><div class="theme-vdoing-wrapper bg-style-6"><div class="articleInfo-wrap" data-v-06225672><div class="articleInfo" data-v-06225672><ul class="breadcrumbs" data-v-06225672><li data-v-06225672><a href="/qishao-notes/" title="首页" class="iconfont icon-home router-link-active" data-v-06225672></a></li> <li data-v-06225672><a href="/qishao-notes/gpu/#gpu" data-v-06225672>gpu</a></li></ul> <div class="info" data-v-06225672><div title="作者" class="author iconfont icon-touxiang" data-v-06225672><a href="https://github.com/hitqshao" target="_blank" title="作者" class="beLink" data-v-06225672>hitqishao</a></div> <div title="创建时间" class="date iconfont icon-riqi" data-v-06225672><a href="javascript:;" data-v-06225672>2024-09-06</a></div> <!----></div></div></div> <!----> <div class="content-wrapper"><div class="right-menu-wrapper"><div class="right-menu-margin"><div class="right-menu-title">目录</div> <div class="right-menu-content"></div></div></div> <h1><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAB4AAAAeCAYAAAA7MK6iAAAAAXNSR0IArs4c6QAABKFJREFUSA3tVl1oFVcQnrMbrak3QUgkya1akpJYcrUtIqW1JvFBE9LiQ5v6JmJpolbMg32rVrhgoYK0QiMY6i9Y6EMaW5D+xFJaTYItIuK2Kr3+BJNwkxBj05sQY3b3nM6cs2dv9t7NT/vQJw/sndk5M/PNzJkzewGerP+pAmy+ON8lLzUJgA8ZYxYIYZmGYRnctDaWvJJAmTtfP1pvXsBCCPP8QFcCaRkZYACgDZFO4stNIcBCajEOlmmC9XpJ9bAGCaPaPmzPl32dvLSVu3BWCTQs0XQQ6g0DYgwLIoAZbBCdW/i+781o1VVlm/410mw4h06Y7bIPHNyWDyL4FHkX03Q8SrzNhZTZriieckWt7cL6MM85YcLpsi/7O9/iXFT6MswI0DmmpkSaJ0qLxFIm3+i1THHB3zmBH3PYx9CcykcLOeQVVa7QtdxTgQgEleX2AjHYfwA+2ddV77ruGoJUbhGDI09YSNXyMpUt5ylOzxgbUmtOp7NmbNt8v3arjTBfYELmLUV+M+nSawNNAUqpT3ClJWg5I3BLT+cGW/DXNGCa6tx1aakCGEigArTn4TDIPdrXXYKCZNrHLMCOEPvHBlLQ99s9eHB7EB6NTki73CVPQ2F5MSx/uRQixfmq7rK0wYD8w8E905bnPDfwoWs/rfv93NWN/ZfvwsLIU7A09gxECyISeGJkHAau98L97tuw7NXnoPyNF8FcYGLGKsOs0mN3OEyec9esGW/ZEl945dTP34wlR2FZVQWU1q0Cw8Tr7p+hgLLNL0FPxx/Q35mA8aEUrH6nCgwEl0tn7wUiZYJnNRh6DK4UH/k0lfyrsBKdPVv/AriGIQcEDQZ65LBAGe2Rzui9Ybjz7XUppz1/uKBbyVPGkN3ZAeC6hr0x7Nr38N5+EqkoOm17xpoqR9ohQF55ERSvr4Dkr3chNfC3DMzGJlNBElW8w9nsGQvhNGIzDkXzCg8cLK951xHsFBlTJspJNi3ZFIMF2AeDV3q8DNOB+YHi6QTrChDIWDBRi5U5f+ZMfJLu3ccrqxtdxk4SKH336LFxSmkqefwU5T8fhdSdQf9IVKD6aNiwI/hnmcAZ91isYMJIaCUCx9W098+LgruikeTqzqqxKPUwqJyCPJiyemVVZBOijDGjD38Os0jOiSPL1z3SPjXNANbiNPXAdzTfukjjuknNBbyz3nwgTd3AVFqUJ5hpHlq9MveLnWwttUfoygBmvVjuikxND3znrhsELnZk7k+OjIGxeNEkomyLVta0xxn+HZhjBc4YZ/AFjHjz9u3xRZl2BN4aq9nFwWh16IrQ1aHHEd3j1+4/dB9OtH4e29A2H1DyHQRmOSfQZ1Fy7MHBTGB6J/Djq6p3OxyO2cB+4Car7v/o3GXgfAkj23+x9ID1Teoamo/SXcbvSf2PX7Vc8DdCmE1vN9di+32P9/5YR3vLnhCVGUWBjEkr3yh4H8v9CzmsbdhzOKzsJKM90iFdaTMjRPhGVsakRvOaRidljo6H6G7j+ctrJpsP+4COhDIl0La2+FS4+5mlocBaXY5QnGZysIBYoeSsl5qQzrSj/cgNrfuEzlWBfwA+EjrZyWUvpAAAAABJRU5ErkJggg==">GPU WARP Mangement Papers<!----></h1> <!----> <div class="theme-vdoing-content content__default"><ol><li>[530 MICRO] Improving GPU Perfromance via Large Warps and Two-Level Warp Scheduling</li> <li>[219] Improving GPGPU Resource Utilization Through Alternative Thread Blocking Scheduling</li> <li>[94] Exploiting Inter-Warp Heterogeneity to Improve GPGPU Performance</li></ol> <hr> <h2 id="_1-improving-gpu-perfromance-via-large-warps-and-two-level-warp-scheduling"><a href="#_1-improving-gpu-perfromance-via-large-warps-and-two-level-warp-scheduling" class="header-anchor">#</a> 1. Improving GPU Perfromance via Large Warps and Two-Level Warp Scheduling</h2> <h3 id="main-idea-in-short"><a href="#main-idea-in-short" class="header-anchor">#</a> Main Idea in Short</h3> <ol><li>Solve issue of branch divergence by managing large wrap and create diverged sub-warp from large warp</li> <li>Two-level warp scheduling. If all warps are scheduled together, they might get stuck by memory access request at the same time.<br>
Thus they group 32 warps into 4 fetch groups. Group0 is prioritized first and then following warps.</li></ol> <h3 id="framework"><a href="#framework" class="header-anchor">#</a> Framework</h3> <p><img src="https://github.com/user-attachments/assets/f926ad58-a0fe-4c56-b529-4292b5ccc0ce" alt="image"> <img src="https://github.com/user-attachments/assets/b0ccc14d-60e6-4cf8-9d55-a5f05693d351" alt="image"></p> <h3 id="misc"><a href="#misc" class="header-anchor">#</a> MISC</h3> <h4 id="branch-divergence"><a href="#branch-divergence" class="header-anchor">#</a> Branch Divergence</h4> <p>Maintainance of branch divergence is well illustrated in the paper.</p> <p><img src="https://github.com/user-attachments/assets/6cf92e7b-a3db-464f-a151-864a35541b51" alt="image"></p> <ul><li>Since a warp can only have a single active PC at any given time, when branch divergence occurs, one path must be chosen first and the other is pushed on a divergence
stack associated with the warp so that it can be executed later.</li> <li>The divergence stack is also used to bring the warp back together once the divergent paths have been executed and all threads have reached a control flow merge (CFM)
point.</li> <li>A divergence stack entry consists of three fields: a re-convergence PC, an active mask, and an execute PC.</li></ul> <h3 id="core-pipeline"><a href="#core-pipeline" class="header-anchor">#</a> Core Pipeline</h3> <p><img src="https://github.com/user-attachments/assets/065f1360-ea1f-46b8-b5e2-bdb9e24f8e09" alt="image"></p> <hr> <h2 id="_2-improving-gpgpu-resource-utilization-through-alternative-thread-blocking-scheduling"><a href="#_2-improving-gpgpu-resource-utilization-through-alternative-thread-blocking-scheduling" class="header-anchor">#</a> 2. Improving GPGPU Resource Utilization Through Alternative Thread Blocking Scheduling</h2> <h3 id="main-idea-in-short-2"><a href="#main-idea-in-short-2" class="header-anchor">#</a> Main Idea in Short</h3> <p>Interaction between thread block scheduler and wrap scheduler for different characteristics of workloads</p> <ul><li>resource contention</li> <li>inter-CTA locality</li></ul> <h3 id="introduction"><a href="#introduction" class="header-anchor">#</a> Introduction</h3> <p>Two level of schedulers within a GPGPU:</p> <ul><li>a warp (or a wavefront) scheduler to determine which warp is executed</li> <li>a thread block or CTA scheduler to assign CTAs to cores</li></ul> <p>By default, the current CTA scheduler in hardware assigns the maximum number of CTAs to each core.<br>
The maximum number of CTAs depends on the resources used by each thread and the upper limit is determined the architecture (e.g., 8 CTAs in the Tesla architecture that we evaluate).</p> <p>Assigning the maximum number of CTAs does not necessarily result in maximum performance as additional CTAs degrade performance by likely creating resource contention.</p> <blockquote><p><em>Other's work</em>
Cache Conscious Wavefront Scheduling (CCWS) [29] proposes a warp scheduler that tracks L1 cache accesses to throttle the number of warps scheduled.
Dynamic CTA scheduling (DYNCTA) [16] attempts to allocate the optimal number of CTAs to each core based on the application characteristics.</p></blockquote> <h3 id="two-different-scheduling-cta-policy-for-different-workloads"><a href="#two-different-scheduling-cta-policy-for-different-workloads" class="header-anchor">#</a> Two Different scheduling CTA policy for different workloads</h3> <p>For workloads where the maximum number of CTAs does not maximize performance, we leverage a greedy warp scheduler [29] to propose a lazy CTA scheduling (LCS) where the maximum number of CTAs allocated to each core is reduced to avoid resource contention and performance degradation.</p> <p>In addition, to exploit inter-CTA locality, we propose block CTA scheduling (in conjunction with an appropriate block-aware warp scheduling) to improve performance and efficiency.</p> <h3 id="observation"><a href="#observation" class="header-anchor">#</a> Observation</h3> <ul><li>Type I : Increased Performance</li> <li>Type II : Increased Performance and Saturate</li></ul> <p>Contention of L1 and increasing L2 miss rate can leads to degrade performance</p> <ul><li>Type III : Decreased Performance</li> <li>Type IV : Increase then Decrease</li></ul> <p><strong>Core Activity</strong></p> <ul><li><em>IDLE</em><br>
There are no available warps that can be issued. This can occur when there are not sufficient warps (and CTAs) assigned to the core.</li> <li><em>MEM_STALL</em> <br>
Most of the warps in the core are stalled waiting for data reply from memory while other warps have no valid instruction to issue.</li> <li><em>CORE_STALL</em> <br>
The core pipeline is stalled and no warp can be issued.<br>
While some of the warps in the core might be stalled waiting for data from memory, other warps are stalled because of core/pipeline resource contention (e.g., lack of MSHR entries).</li></ul> <p><img src="https://github.com/user-attachments/assets/a39e1839-f055-49df-baf9-f0bbf1ae2a2c" alt="image"></p> <h3 id="method"><a href="#method" class="header-anchor">#</a> Method</h3> <p>We analyzed the behavior of the CTA scheduler through instrumentation.<br>
In the source code of the workloads, we used the PTX register %smid to determine which SM each CTA was assigned to.
<img src="https://github.com/user-attachments/assets/516c6ff8-0618-44c3-aa01-928af6a746ec" alt="image"></p> <h3 id="framework-2"><a href="#framework-2" class="header-anchor">#</a> Framework</h3> <h4 id=""><a href="#" class="header-anchor">#</a></h4> <p>Lazy CTA scheduling (LCS) that reduces the maximum number of CTAs that can be assigned to each core to improve performance and energy efficiency.<br>
Block CTA scheduling (BCS) where sequential CTA blocks are assigned to the same core to improve inter-CTA cache locality and an appropriate warp scheduler that exploits such locality.
<img src="https://github.com/user-attachments/assets/25f19366-20a8-4f5f-8f31-b78323cdf3a9" alt="image"></p> <h4 id="lcs"><a href="#lcs" class="header-anchor">#</a> LCS</h4> <p>In comparison, LCS only requires a single measurement during the execution of the first thread block and based on the data collected, the number of thread blocks allocated to the core is adjusted.</p> <p><img src="https://github.com/user-attachments/assets/ddc71e56-eb23-40d9-9357-06d24f48852a" alt="image"></p> <p>It is simple. <br>
During the monitor phase, the number of instructions issued (inst) for each thread block x is measured. The monitor phase continues until the first thread block finishes execution.</p> <p><img src="https://github.com/user-attachments/assets/bf3786f0-f606-4cb6-aafc-b4c8a5677370" alt="image"></p> <p>In Figure7 (b), Tnew = floor(10/4) = 3</p> <h4 id="bcs"><a href="#bcs" class="header-anchor">#</a> BCS</h4> <p>we focus on a block of size 2 CTAs. BCS is not applicable to workloads with one-dimensional CTAs as there is little inter-CTA L1 locality.
<img src="https://github.com/user-attachments/assets/7c813299-4f24-4cdb-a6d5-2162bfb0366a" alt="image"></p> <h4 id="increasing-efficiency-of-gpgpus-mixed-concurrent-kernel-execution-mcke"><a href="#increasing-efficiency-of-gpgpus-mixed-concurrent-kernel-execution-mcke" class="header-anchor">#</a> Increasing Efficiency of GPGPUs: mixed Concurrent Kernel Execution (mCKE)</h4> <p>Similar to prior work [2], the unused resource (e.g., register file, shared memory) can be powergated to improve energy-efficiency with the reduced number of thread blocks allocated to each core with LCS.<br>
In addition, the underutilized resources within a core provide opportunity for concurrent execution of different kernels on the same core, which we refer to as mixed concurrent kernel execution (mCKE).</p> <p><strong>The main goal of CKE is to efficiently utilize the GPU by overlapping kernel execution.</strong></p> <p>In the baseline CKE, each core can be stalled at different point in time while waiting for the response from the memory and result in the core being idle for significant amount of time.<br>
However, by interleaving the kernels on the same core with mCKE, the memory latency can be hidden (or overlapped) with other kernel execution
and effectively improve overall performance.<br>
This is similar to the benefits of two-level warp scheduling [20] where the memory accesses from the warps within a thread block are not necessarily schedule together but partitioned into different fetch groups.</p> <blockquote><p>[20] V. Narasiman et al. Improving GPU Performance via Large Warps and Two-Level Warp Scheduling. In International Symposium on Microarchitecture (MICRO), pages 308–317, Porto Alegre, Brazil, 2011.</p></blockquote> <hr> <h2 id="_3-exploiting-inter-warp-heterogeneity-to-improve-gpgpu-performance"><a href="#_3-exploiting-inter-warp-heterogeneity-to-improve-gpgpu-performance" class="header-anchor">#</a> 3. Exploiting Inter-Warp Heterogeneity to Improve GPGPU Performance</h2> <h3 id="main-idea-in-short-3"><a href="#main-idea-in-short-3" class="header-anchor">#</a> Main Idea in Short</h3> <p>For almost-all-miss warp, bypass their request to reduce memory &amp; cache contention.</p> <h3 id="observation-2"><a href="#observation-2" class="header-anchor">#</a> Observation</h3> <p>three new observations:</p> <ul><li>GPGPU warps exhibit heterogeneous memory divergence behavior at the shared cache: some warps have most of their requests hit in the cache (high cache utility), while other warps see most of their request miss (low cache utility).</li> <li>a warp retains the same divergence behavior for long periods of execution</li> <li>due to high memory level parallelism, requests going to the shared cache can incur queuing delays as large as hundreds of cycles,  exacerbating the effects of memory divergence.</li></ul> <h3 id="components"><a href="#components" class="header-anchor">#</a> Components</h3> <ul><li>a cache bypassing mechanism that exploits the latency tolerance of low cache utility warps to both alleviate queuing delay and
increase the hit rate for high cache utility warps</li> <li>a cache insertion policy that prevents data from high cache utility warps from being prematurely evicted</li> <li>a memory controller that prioritizes the few requests received from high cache utility warps to minimize stall time.</li></ul> <p><img src="https://github.com/user-attachments/assets/8ee29c66-5a15-40eb-90a8-15552730bd4d" alt="image"></p> <p><img src="https://github.com/user-attachments/assets/dbcc3d98-01c9-4ac4-a1ab-89ca9095bba7" alt="image"></p></div></div> <!----> <div class="page-edit"><div class="edit-link"><a href="https://github.com/hitqshao/qishao-notes/edit/main/docs/03.gpu/23.gpu_warp_paper.md" target="_blank" rel="noopener noreferrer">帮助我们改善此页面</a> <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></div> <!----> <div class="last-updated"><span class="prefix">上次更新:</span> <span class="time">2025/01/16, 03:55:52</span></div></div> <div class="page-nav-wapper"><div class="page-nav-centre-wrap"><a href="/qishao-notes/pages/45879/" class="page-nav-centre page-nav-centre-prev"><div class="tooltip">GPU Cache's Papers</div></a> <a href="/qishao-notes/pages/45882/" class="page-nav-centre page-nav-centre-next"><div class="tooltip">GPU Unified Memory Innovations</div></a></div> <div class="page-nav"><p class="inner"><span class="prev">
        ←
        <a href="/qishao-notes/pages/45879/" class="prev">GPU Cache's Papers</a></span> <span class="next"><a href="/qishao-notes/pages/45882/">GPU Unified Memory Innovations</a>→
      </span></p></div></div></div> <!----></main></div> <div class="footer"><div class="icons"><a href="https://github.com/hitqshao" title="GitHub" target="_blank" class="iconfont icon-github"></a><a href="mailto:hitqshao@163.com" title="发邮件" target="_blank" class="iconfont icon-youjian"></a><a href="https://gitee.com/hitqshao" title="Gitee" target="_blank" class="iconfont icon-gitee"></a></div> 
  Theme by
  <a href="https://github.com/xugaoyi/vuepress-theme-vdoing" target="_blank" title="本站主题">Vdoing</a> 
    | Copyright © 2022-2025
    <span>Eryajf | <a href="https://github.com/hitqshao/qishao-notes/blob/main/LICENSE" target="_blank">MIT License</a></span></div> <div class="buttons"><div title="返回顶部" class="button blur go-to-top iconfont icon-fanhuidingbu" style="display:none;"></div> <div title="去评论" class="button blur go-to-comment iconfont icon-pinglun" style="display:none;"></div> <div title="主题模式" class="button blur theme-mode-but iconfont icon-zhuti"><ul class="select-box" style="display:none;"><li class="iconfont icon-zidong">
          跟随系统
        </li><li class="iconfont icon-rijianmoshi">
          浅色模式
        </li><li class="iconfont icon-yejianmoshi">
          深色模式
        </li><li class="iconfont icon-yuedu">
          阅读模式
        </li></ul></div></div> <!----> <!----> <!----></div><div class="global-ui"><!----></div></div>
    <script src="/qishao-notes/assets/js/app.4ea71f9a.js" defer></script><script src="/qishao-notes/assets/js/2.9488d546.js" defer></script><script src="/qishao-notes/assets/js/58.ebe669f3.js" defer></script>
  </body>
</html>

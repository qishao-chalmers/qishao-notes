<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>HBM Dead Block Predictor | Qi Shao</title>
    <meta name="generator" content="VuePress 1.8.0">
    <link rel="icon" href="https://cdn.staticaly.com/gh/eryajf/tu/main/img/image_20220720_132133.ico">
    <script language="javascript" type="text/javascript" src="/qishao-notes/js/pgmanor-self.js"></script>
    <meta name="description" content="Computer System">
    <meta name="keywords" content="Hitqishao,golang,vue,go-web,go-admin,go-ldap-admin">
    <meta name="theme-color" content="#11a8cd">
    <meta name="referrer" content="no-referrer-when-downgrade">
    
    <link rel="preload" href="/qishao-notes/assets/css/0.styles.ef74cbd5.css" as="style"><link rel="preload" href="/qishao-notes/assets/js/app.4cc8c1cf.js" as="script"><link rel="preload" href="/qishao-notes/assets/js/2.72ae8968.js" as="script"><link rel="preload" href="/qishao-notes/assets/js/11.4ef910c2.js" as="script"><link rel="prefetch" href="/qishao-notes/assets/js/10.91cca9a8.js"><link rel="prefetch" href="/qishao-notes/assets/js/12.fa33dee2.js"><link rel="prefetch" href="/qishao-notes/assets/js/13.f6b20e3c.js"><link rel="prefetch" href="/qishao-notes/assets/js/14.deb02341.js"><link rel="prefetch" href="/qishao-notes/assets/js/15.f76fee91.js"><link rel="prefetch" href="/qishao-notes/assets/js/16.48b3399d.js"><link rel="prefetch" href="/qishao-notes/assets/js/17.75d4244f.js"><link rel="prefetch" href="/qishao-notes/assets/js/18.ba51b318.js"><link rel="prefetch" href="/qishao-notes/assets/js/19.72b8c078.js"><link rel="prefetch" href="/qishao-notes/assets/js/20.b40180fd.js"><link rel="prefetch" href="/qishao-notes/assets/js/21.e5b86efa.js"><link rel="prefetch" href="/qishao-notes/assets/js/22.6f4c76fd.js"><link rel="prefetch" href="/qishao-notes/assets/js/23.be368314.js"><link rel="prefetch" href="/qishao-notes/assets/js/24.3944c975.js"><link rel="prefetch" href="/qishao-notes/assets/js/25.e6517037.js"><link rel="prefetch" href="/qishao-notes/assets/js/26.5e899f83.js"><link rel="prefetch" href="/qishao-notes/assets/js/27.44fd56bd.js"><link rel="prefetch" href="/qishao-notes/assets/js/3.1b7f7ba2.js"><link rel="prefetch" href="/qishao-notes/assets/js/4.e05a2450.js"><link rel="prefetch" href="/qishao-notes/assets/js/5.df5d21e3.js"><link rel="prefetch" href="/qishao-notes/assets/js/6.53e0ea77.js"><link rel="prefetch" href="/qishao-notes/assets/js/7.ae1994f9.js"><link rel="prefetch" href="/qishao-notes/assets/js/8.b00617ec.js"><link rel="prefetch" href="/qishao-notes/assets/js/9.47d4f19f.js">
    <link rel="stylesheet" href="/qishao-notes/assets/css/0.styles.ef74cbd5.css">
  </head>
  <body class="theme-mode-light">
    <div id="app" data-server-rendered="true"><div class="theme-container sidebar-open have-rightmenu"><header class="navbar blur"><div title="目录" class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/qishao-notes/" class="home-link router-link-active"><!----> <span class="site-name">Qi Shao</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/qishao-notes/" class="nav-link">Home</a></div><div class="nav-item"><a href="/qishao-notes/hbm/" class="nav-link">hbm</a></div><div class="nav-item"><a href="/qishao-notes/two/" class="nav-link">two</a></div><div class="nav-item"><a href="/qishao-notes/gpu/" class="nav-link">gpu</a></div><div class="nav-item"><a href="/qishao-notes/cpu/" class="nav-link">cpu</a></div><div class="nav-item"><a href="/qishao-notes/message-board/" class="nav-link">BBS</a></div><div class="nav-item"><a href="https://blog.csdn.net/hit_shaoqi" target="_blank" rel="noopener noreferrer" class="nav-link external">
  CSDN
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></div> <a href="https://github.com/hitqshao/qishao-notes" target="_blank" rel="noopener noreferrer" class="repo-link">
    GitHub
    <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></nav></div></header> <div class="sidebar-mask"></div> <div class="sidebar-hover-trigger"></div> <aside class="sidebar" style="display:none;"><!----> <nav class="nav-links"><div class="nav-item"><a href="/qishao-notes/" class="nav-link">Home</a></div><div class="nav-item"><a href="/qishao-notes/hbm/" class="nav-link">hbm</a></div><div class="nav-item"><a href="/qishao-notes/two/" class="nav-link">two</a></div><div class="nav-item"><a href="/qishao-notes/gpu/" class="nav-link">gpu</a></div><div class="nav-item"><a href="/qishao-notes/cpu/" class="nav-link">cpu</a></div><div class="nav-item"><a href="/qishao-notes/message-board/" class="nav-link">BBS</a></div><div class="nav-item"><a href="https://blog.csdn.net/hit_shaoqi" target="_blank" rel="noopener noreferrer" class="nav-link external">
  CSDN
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></div> <a href="https://github.com/hitqshao/qishao-notes" target="_blank" rel="noopener noreferrer" class="repo-link">
    GitHub
    <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></nav>  <ul class="sidebar-links"><li><a href="/qishao-notes/pages/24769e/" class="sidebar-link">HBM Paper List</a></li><li><a href="/qishao-notes/pages/2476af/" aria-current="page" class="active sidebar-link">HBM Dead Block Predictor</a><ul class="sidebar-sub-headers"></ul></li><li><a href="/qishao-notes/pages/24769f/" class="sidebar-link">Dynamically Adapting  Page Migration Policies Based on Applications Memory Access Behaviors</a></li><li><a href="/qishao-notes/pages/24760e/" class="sidebar-link">DRAM PCM NVM Cache</a></li><li><a href="/qishao-notes/pages/2476bf/" class="sidebar-link">Cache Memory Compression</a></li><li><a href="/qishao-notes/pages/f07695/" class="sidebar-link">memory-ecc</a></li><li><a href="/qishao-notes/pages/f07696/" class="sidebar-link">hbm-latency</a></li></ul> </aside> <div><main class="page"><div class="theme-vdoing-wrapper "><div class="articleInfo-wrap" data-v-06225672><div class="articleInfo" data-v-06225672><ul class="breadcrumbs" data-v-06225672><li data-v-06225672><a href="/qishao-notes/" title="首页" class="iconfont icon-home router-link-active" data-v-06225672></a></li> <li data-v-06225672><a href="/qishao-notes/hbm/#hbm" data-v-06225672>hbm</a></li></ul> <div class="info" data-v-06225672><div title="作者" class="author iconfont icon-touxiang" data-v-06225672><a href="https://github.com/hitqshao" target="_blank" title="作者" class="beLink" data-v-06225672>hitqishao</a></div> <div title="创建时间" class="date iconfont icon-riqi" data-v-06225672><a href="javascript:;" data-v-06225672>2023-05-15</a></div> <!----></div></div></div> <!----> <div class="content-wrapper"><div class="right-menu-wrapper"><div class="right-menu-margin"><div class="right-menu-title">目录</div> <div class="right-menu-content"></div></div></div> <h1><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAB4AAAAeCAYAAAA7MK6iAAAAAXNSR0IArs4c6QAABGpJREFUSA3tVVtoXFUU3fvOI53UlmCaKIFmwEhsE7QK0ipFEdHEKpXaZGrp15SINsXUWvBDpBgQRKi0+KKoFeJHfZA+ED9KKoIU2gYD9UejTW4rVIzm0VSTziPzuNu1z507dibTTjL4U/DAzLn3nL3X2o91ziX6f9wMFdh6Jvbm9nNSV0msViVO6tN1Rm7NMu2OpeJ9lWBUTDxrJbYTS0hInuwciu9eLHlFxCLCZEk3MegsJmZ5K/JD6t7FkFdEvGUo1g7qJoG3MHImqRIn8/nzY1K9UPKKiJmtnUqHVE3Gbuay6vJE/N2FEmuxFjW2nUuE0yQXRRxLiTUAzs36zhZvOXJPdX850EVnnLZkB8prodQoM5JGj7Xk2mvC7JB8tG04Ef5PiXtG0UtxupRQSfTnBoCy554x18yJHI6I+G5Eru4LHmPJZEQsrvPUbMiA8G/WgMK7w7I+ez7++o2ANfbrjvaOl1tFMs+htG3IrZH9/hDX1Pr8Tc0UvH8tcX29KzAgIGcEkINyW5BF9x891hw6VYqgJHEk0huccS7vh3C6gTiODL+26huuBtbct8eZnqLML8PkxGYpuPZBqtqwkSjgc4mB5gbgig5i+y0UDK35LMxXisn9xQtK+nd26gTIHsHe/oblK/b29fUmN/8Y+9jAQrnBp56m1LcDlDp9irKTExSKduXJVWSqdBMA08pEJnEIOB3FPPMybu/oeV8zFeYN3xx576Q6RH+VmplE4ncQV5v+5rzSoyOU7PuEAg8g803PwBJ0CExno/jcMbN8tONYeOmHiuUNryvm3fRUy4tMPVLdAGkUhNWuggGrJcXPv+ouCjz0MKUHz1J2/E8IC9nqTabcxgaBYM0hPhD5Y65FsbxRQKxCQrDjDctW7PUM3HuZunFyifSAqEfuzCp48Il24luWUWZoyJCaPR82jE0+kFA643wRFVni4RYSq3ohJO2pZ7B5dO4xkDWbEpossJPLSrPjYID8rS2UHTlvyNxqIGsg674XJJ7vnh5L7PNwC4hh2sjCI96mzszOTpxLF0T7l88Yz7lAuK6OnL8gXLOnTvpzSb22YG8W7us3jSebFHeeqnXRG1vt+MoUM84LQIBmMsCTAcOauTh0T0l0neQK7m2bLMt2mGxU3HYssS0J2cdv5wljlPsrIuZLAG/2DOZIXgCYT8uMGZN+e2kSirfxZOPCsC0f24nTZzspnVn9VePS1Z5vubmAGGXG8ZFno9Hel0yfA5ZPhF7Dh972BQJ2qCpgH67lmWtBYbvk6sz02wjky2vXyz0XErP/kFB619js1BtwfOV4OPRqOQBjy3Qbk18vigUPPSD5ceHnwck7W9bhAqZdd7SuG7w4/P2F/GaJh8c7e9qgow+Q7cGBo+98WsLkuktFqiZabtXuQTu/Y5ETbR0v7tNSFnvrmu6pjdoan2KjMu8q/Hmj1EfCO2ZGfEIbIXKUlw8qaX9/b2oeSJmFksSeT/Fn0V3nSypChh4Gjh74ybO9aeZ/AN2dwciu2/MhAAAAAElFTkSuQmCC">HBM Dead Block Predictor<!----></h1> <!----> <div class="theme-vdoing-content content__default"><ol><li>Data Placement in HPC Architectures with Heterogeneous Off-chip Memory</li> <li>Die-Stacked DRAM: Memory, Cache, or MemCache?</li> <li>A Survey Of Techniques for Architecting DRAM Caches</li> <li>Bumblebee: A MemCache Design for Die-stacked and Off-chip Heterogeneous Memory Systems (2023)</li> <li>BATMAN: Techniques for Maximizing System Bandwidth of Memory Systems with Stacked-DRAM</li> <li>BEAR: Techniques for Mitigating Bandwidth Bloat in Gigascale DRAM Caches</li> <li>To Update or Not To Update?: Bandwidth-Efficient Intelligent Replacement Policies for DRAM Caches</li> <li>ACCORD: Enabling Associativity for Gigascale DRAM Caches by Coordinating Way-Install and Way-Prediction</li></ol> <hr> <ol start="9"><li>A Survey of Cache Bypassing Techniques</li> <li>The Evicted-Address Filter: A Unified Mechanism to Address Both Cache Pollution and Thrashing - Not Read Yet Intel</li> <li>Bypass and Insertion Algorithms for Exclusive Last-level Caches</li> <li>Counter-Based Cache Replacement and Bypassing Algorithms</li> <li>Techniques for Bandwidth-Efficient Prefetching of Linked Data Structures in Hybrid Prefetching Systems (LDS Prefetch)</li></ol> <hr> <h3 id="_1-data-placement-in-hpc-architectures-with-heterogeneous-off-chip-memory"><a href="#_1-data-placement-in-hpc-architectures-with-heterogeneous-off-chip-memory" class="header-anchor">#</a> 1. Data Placement in HPC Architectures with Heterogeneous Off-chip Memory</h3> <ul><li>Software manage DRAM and NVM</li></ul> <ol><li><p>First touch policy<br>
Alloc all pages in DRAM</p></li> <li><p>Static profile-based policy</p></li> <li><p>Spill Migration<br>
LRU spill policy keeps track of last access time for each page in DRAM, and in case of eviction selects one that is least recently used.
Spill migration policy first allocates a page in fast memory (in our case DRAM), and later evicts it to PCM.
Spill profile-based policy can either spare a page from eviction if its future traffic is high, or victimize it if it is low, regardless of its previous access count.</p></li> <li><p>Dynamic page migration</p> <p><img src="https://github.com/hitqshao/qishao-notes/assets/23403286/f32475d8-b0ce-4066-a416-d36d1f44c86f" alt="image"></p> <p>When a page is first brought to the PCM we reset its access counter, regardless of how many times it was accessed in the DRAM. At the same time we keep track of   the number of accesses for every page in the DRAM, as well as the average for all the pages (nDRAMavg). When a page in PCM is accessed, we compare its access counter
(naccesses) with the average number of accesses to pages in DRAM.
Back migration threshold (BMT) is a value that controls the aggressiveness of migration triggering.
If it is set to zero, a page is migrated as soon as it is touched in PCM, so the DRAM acts as a typical cache. In this case we expect good performance as the system tends to always move active pages to DRAM, but due to a large number of migrations, number of writes to PCM may go high.
On the other hand, if BMT is set to infinity the page never gets migrated back, and then the policy is equivalent to LRU spill. In between those extremes we would like to search for values that give good performace and low number of PCM writes.</p></li></ol> <hr> <h3 id="_2-die-stacked-dram-memory-cache-or-memcache"><a href="#_2-die-stacked-dram-memory-cache-or-memcache" class="header-anchor">#</a> 2. Die-Stacked DRAM: Memory, Cache, or MemCache?</h3> <ul><li>Part as Memory ans Part as Cache</li> <li>Discuss and compared with Alloy Cache, Unison Cache, Banshee Cache, HMA</li> <li>Hot Data Sets pages in memory HBM and transient pages in cache HBM</li></ul> <p>Cited from org paper:
In this proposal, a software procedure pre-processes the application and determines hot pages,then asks the OS to map them to the memory portion of the die-stacked DRAM. The cache portion of the die-stacked DRAM is managed by hardware, caching data allocated in the off-chip memory.</p> <p>To identify hot pages, we use a static profile-based approach before the execution of an application. A software procedure, incorporated into the compiler, pre-processes the application and sorts the pages based on their access frequency. Then it picks the top pages and asks the OS to map them to the memory portion of the die-stacked DRAM.</p> <p>After detection of hot pages, their details are coded into the program binary. Whenever the program gets executed, the Loader passes the required information of hot pages to the OS. Then, the OS tries to map such hot pages to physical locations that belong to the memory portion of the die-stacked DRAM. For the OS, allocating pages in the die-stacked and off-chip memory is similar to the same operations in Non-Uniform Memory Architecture (NUMA) [50] systems.</p> <p>In this paper, <strong>they raised the issue</strong> that when process switches, previous hbm space allocated to a process might left inadequate space for the following process. Other orthogonal research  &quot; Various proposals (e.g., [13, 47, 54, 62, 78]) have suggested to optimize memory management in such situations typically by gradually or periodically migrating application pages between different types of memories based on factors like programming model, application’s criticality, sharing degree, and so on&quot;.</p> <p>They identify the portion of hbm memory(the hot pages that need to be allocated to HBM) for hot pages by trying to allocate the maximum number of pages into hbm memory without worsening the cacheAHF.</p> <p><img src="https://github.com/hitqshao/qishao-notes/assets/23403286/b6fac2f3-c4df-4747-8588-d96b22f317fd" alt="image"></p> <hr> <h3 id="_4-bumblebee-a-memcache-design-for-die-stacked-and-off-chip-heterogeneous-memory-systems-2023"><a href="#_4-bumblebee-a-memcache-design-for-die-stacked-and-off-chip-heterogeneous-memory-systems-2023" class="header-anchor">#</a> 4. Bumblebee: A MemCache Design for Die-stacked and Off-chip Heterogeneous Memory Systems (2023)</h3> <h4 id="me"><a href="#me" class="header-anchor">#</a> Me</h4> <ul><li>Hybrid Memory</li> <li>Blk/Page Size 2KB/64KB<br>
64KB page size is due to the fact that it maps all memory in dram and hbm.<br>
Every request will cam PRT and BLE. <br>
In multi core simulation env,it have to support multi core read and write the SRAM.<br></li> <li>Distinguish Spacial Locality and Temporal Locality.<br>
cacheHBM (cHBM) for temporal locality<br>
memoryHBM (mHBM) for spacial locality<br></li> <li>Page Allocation.<br>
Different from previous design that allocate all memory in HBM or DRAM. It allocate page according to its neighbour pages.
But it does not mention how it interact with page table. If page is deallocate or written back to disk, the PRT should also be updated.</li> <li>The ratio between cHBM and mHBM is flexible.</li></ul> <p><img src="https://github.com/hitqshao/qishao-notes/assets/23403286/6a4417fe-70f7-4620-bcb9-014503a7b6d1" alt="image"></p> <ul><li>If memory footprint is high, all used by OS, all the HBM will be served as flat memory.</li></ul> <p>Cited from org paper:
Program Statistics</p> <p><img src="https://github.com/hitqshao/qishao-notes/assets/23403286/5937f36c-c347-4be5-be5c-fbf446cde4c4" alt="image"></p> <p>In each remapping set, the hotness tracker includes a hot table and five parameters: the HBM occupied ratio (Rh), a hotness threshold (T) to decide if an off-chip DRAM page should be brought in HBM for high Rh condition, the number of cHBM pages (Nc), and the number of mHBM pages in which most blocks have/have not been accessed (Na/Nn).</p> <p><img src="https://github.com/hitqshao/qishao-notes/assets/23403286/a3206fc5-49f2-412e-8001-9694c4d78047" alt="image"></p> <p>For SL&gt;0 (strong spatial locality), more hot data should be brought in mHBM to better exploit the spatial locality and utilize the memory bandwidth. For SL ≤ 0 (weak spatial locality), hot data should be cached in cHBM to reduce over-fetching.</p> <p>The threshold T in the hotness tracker can alleviate this issue. If Rh is high, for SL&gt;0, only pages whose hotness value is larger than T are permitted to be migrated to mHBM and for SL ≤ 0, only blocks in a page whose hotness value is larger than T are permitted to be cached in
cHBM.
<strong>Me</strong>
From this aspect, SL means that number of mHBM pages that most blocks have been accessed is far larger than not been accessed. This means strong spatial locality.</p> <hr> <h3 id="_5-batman-techniques-for-maximizing-system-bandwidth-of-memory-systems-with-stacked-dram"><a href="#_5-batman-techniques-for-maximizing-system-bandwidth-of-memory-systems-with-stacked-dram" class="header-anchor">#</a> 5.BATMAN: Techniques for Maximizing System Bandwidth of Memory Systems with Stacked-DRAM</h3> <p><strong>Insights</strong></p> <ul><li>bandwidth distribution</li> <li>dram and hbm similar latency</li></ul> <p>As the NM simply offers higher bandwidth, not lower latency,the performance of tiered-memory systems is determined by the utilization of system bandwidth. We observe that both system bandwidth and performance are maximized when memory accesses are distributed proportional to the bandwidth of each memory.</p> <p>We leverage our key insight on controlling data movement and propose Bandwidth-Aware Tiered-Memory Management (BATMAN), which is a runtime mechanism that monitors memory access distribution and explicitly controls the data movement between the NM and the FM.
We define the desired access rate of the NM as the target access rate (TAR). TAR is the fraction of memory accesses serviced by the NM when memory accesses to both memories are proportional to the respective bandwidth.</p> <p><img src="https://github.com/hitqshao/qishao-notes/assets/23403286/a307ab63-9871-4e66-bf4c-792a391022ae" alt="image"></p> <p>2X 2/3
4X 4/5
8X 8/9</p> <p><strong>Me</strong>
Bandwidth-Aware Tired-Memory Management tries to distritube memory according to HBM and DRAM bandwidth ratio. And also treat it as a threshold to refuse page migration.</p> <p>This bandwidth division is also adopted in &quot;Design and Implementation of Bandwidth-Aware Memory Placement and Migration Policies for Heterogeneous Memory&quot;.</p> <p><img src="https://github.com/hitqshao/qishao-notes/assets/23403286/854a81e1-9ade-453f-93fe-be5255fea0cc" alt="image"></p> <hr> <h3 id="_6-bear-techniques-for-mitigating-bandwidth-bloat-in-gigascale-dram-caches"><a href="#_6-bear-techniques-for-mitigating-bandwidth-bloat-in-gigascale-dram-caches" class="header-anchor">#</a> 6. BEAR: Techniques for Mitigating Bandwidth Bloat in Gigascale DRAM Caches</h3> <p>Year:2015</p> <p>Ideally, we want the bandwidth consumed for such secondary operations to be negligible, and have almost all the bandwidth be available for transfer of useful data from the DRAM cache to the processor.
BEAR integrates three components, one each for reducing the bandwidth consumed by miss detection, miss fill, and writeback probes.</p> <ol><li>Miss Probe (to detect a miss, we need to look up the tag store in the DRAM cache)</li> <li>Miss Fill (on a cache miss the missed line is obtained from memory and filled in the cache)</li> <li>Write back Probe (on a dirty eviction from the on-chip LLC identifying if that line is present in the DRAM cache)</li> <li>Writeback Update (if writeback probe gives a hit, updating the content of the line in DRAM cache)</li> <li>Writeback Fill (filling the writeback data in the cache, if a writeback probe gives a miss)</li></ol> <p>They define BloatFactor, the ratio of the total bandwidth consumed by the DRAM cache to the bandwidth required for transferring only the data lines to the processor chip.</p> <ol><li><p>Bandwidth Efficient Cache Fills
We propose Bandwidth Aware <strong>Bypass</strong> (BAB) to reduce the bandwidth consumed by fill operations while limiting the loss in cache hit rate to a desired level.</p> <p><img src="https://github.com/hitqshao/qishao-notes/assets/23403286/f0f82689-5971-49c9-b816-6dd29895d217" alt="image"></p></li> <li><p>Bandwidth Efficient Writeback Probe
DRAM Cache Presence (DCP), reduces Writeback Probe by introducing state information in the on-chip Last Level Cache (LLC) to track if the line exists in the DRAM cache.
<strong>Inclusive Cache</strong></p> <p><img src="https://github.com/hitqshao/qishao-notes/assets/23403286/8c440d58-845f-45ef-b464-7bed63f2d72c" alt="image"></p></li> <li><p>Bandwidth Efficient Miss Probe
We reduce the bandwidth consumed by Miss Probe by leveraging the property of DRAM caches to streams multiple tags on each access. We buffer the tags of recently accessed adjacent cache line's tags in the Neighboring Tag Cache (NTC).
<strong>Neighboring Tag Cache</strong></p> <p><img src="https://github.com/hitqshao/qishao-notes/assets/23403286/b985c20d-3da0-4e6c-9370-f02f0ab363db" alt="image"></p></li></ol> <p><strong>Comment from To Update or Not to update</strong>
Along the same lines, Chou et. al [6] propose a policy that bypasses the cache with 90% probability (we call this policy 90%-Bypass).
<strong>Me</strong>
This comment from to update or not to update is not accurate, the bear paper mentioned that &quot;Overall, the speed up from probabilistic bypass is negligible, and we may deem PB to be ineffective at improving performance.&quot; Then it prefers set-duleling.</p> <hr> <h3 id="_7-to-update-or-not-to-update-bandwidth-efficient-intelligent-replacement-policies-for-dram-caches"><a href="#_7-to-update-or-not-to-update-bandwidth-efficient-intelligent-replacement-policies-for-dram-caches" class="header-anchor">#</a> 7.To Update or Not To Update?: Bandwidth-Efficient Intelligent Replacement Policies for DRAM Caches</h3> <p>Year: 2019</p> <p><strong>Me</strong>
Previous dram cache is stateless, due to the fact that maintaining state of cache would require significant bandwidth.</p> <p><strong>Cite from org paper</strong>
We propose a stateful replacement/bypass policy called RRIP Age-On-Bypass (RRIP-AOB), that tracks reuse state for high-reuse lines, protects such lines by bypassing other lines, and Ages the state On cache Bypass.</p> <p><strong>The DRAM cache in KNL [4, 5],for example, employs an Always-Install policy.</strong> The DRAM cache places each tag information in the unused bits in the ECC space and streams out the data and tag (contained in ECC) on each access.</p> <p><img src="https://github.com/hitqshao/qishao-notes/assets/23403286/979e9ae0-0138-4259-9ffc-ede35c44c056" alt="image"></p> <p>Our goal is to increase the hit-rate of such DRAM caches. In fact, the DRAM cache only uses about 8-10 bits from the unused 28 bits in the ECC space, so we have 18-20 bits per line available for managing the DRAM cache intelligently.</p> <p>To reduce significant bandwidth to update state,  we propose Efficient Tracking of Reuse (ETR). ETR makes state tracking efficient by accurately tracking the state of only one line from a region, and using the state of that line to guide the replacement decisions for other lines in that region.</p> <ol><li><p>We propose a bypass version of RRIP (RRIP-AOB) suitable for caches with limited associativity. However, we find an effective replacement policy for DRAM caches must optimize not only hit-rate but also state update cost.
We introduce two properties, <strong>coresidency and eviction-locality</strong>, that can be exploited to reduce state update cost for implementing intelligent replacement.</p> <p><img src="https://github.com/hitqshao/qishao-notes/assets/23403286/a1545088-5b17-4983-bc49-c4b21e7d2cf6" alt="image"></p> <p>Coresidency indicates that at any given time if a line is present, then several other line belonging to that 4KB region are also present in the cache.
Eviction-Locality indicates that when a line gets evicted from the cache, the replacement-state of the other coresident lines belonging to that region tend to have similar replacement state as the line being evicted.
<strong>Me</strong>
Just a synonym for spacial locality. This granularity is 4KB. Doubt about its authenticity.</p></li> <li><p>We propose Efficient Tracking of Reuse (ETR), a design that performs updates for only a subset of lines and uses their state to guide the replacement decisions of
other lines.</p></li></ol> <p><img src="https://github.com/hitqshao/qishao-notes/assets/23403286/2033799b-814f-495f-b9ef-93ad9c33b411" alt="image"></p> <p><strong>Me</strong>
This is similar to set dueling.</p> <p>The design of ETR consists of three parts:
(1) Selecting a Representative-Line in the region.
(2) Keeping accurate RRPV for only the Representative-Line.
(3) Using the representative’s RRPV to infer coresident lines’ RRPV to make bypass decisions.</p> <hr> <h3 id="_8-accord-enabling-associativity-for-gigascale-dram-caches-by-coordinating-way-install-and-way-prediction"><a href="#_8-accord-enabling-associativity-for-gigascale-dram-caches-by-coordinating-way-install-and-way-prediction" class="header-anchor">#</a> 8.ACCORD: Enabling Associativity for Gigascale DRAM Caches by Coordinating Way-Install and Way-Prediction</h3> <p>A method to optimize prediction way of dram.</p> <hr> <h3 id="_9-a-survey-of-cache-bypassing-techniques"><a href="#_9-a-survey-of-cache-bypassing-techniques" class="header-anchor">#</a> 9. A Survey of Cache Bypassing Techniques</h3> <hr> <h3 id="_10-the-evicted-address-filter-a-unified-mechanism-to-address-both-cache-pollution-and-thrashing-not-read-yet-intel"><a href="#_10-the-evicted-address-filter-a-unified-mechanism-to-address-both-cache-pollution-and-thrashing-not-read-yet-intel" class="header-anchor">#</a> 10. The Evicted-Address Filter: A Unified Mechanism to Address Both Cache Pollution and Thrashing - Not Read Yet Intel</h3> <hr> <h3 id="_11-bypass-and-insertion-algorithms-for-exclusive-last-level-caches"><a href="#_11-bypass-and-insertion-algorithms-for-exclusive-last-level-caches" class="header-anchor">#</a> 11. Bypass and Insertion Algorithms for Exclusive Last-level Caches</h3> <hr> <h3 id="_12-counter-based-cache-replacement-and-bypassing-algorithms"><a href="#_12-counter-based-cache-replacement-and-bypassing-algorithms" class="header-anchor">#</a> 12. Counter-Based Cache Replacement and Bypassing Algorithms</h3> <hr> <h3 id="_13-techniques-for-bandwidth-efficient-prefetching-of-linked-data-structures-in-hybrid-prefetching-systems-lds-prefetch"><a href="#_13-techniques-for-bandwidth-efficient-prefetching-of-linked-data-structures-in-hybrid-prefetching-systems-lds-prefetch" class="header-anchor">#</a> 13. Techniques for Bandwidth-Efficient Prefetching of Linked Data Structures in Hybrid Prefetching Systems (LDS Prefetch)</h3></div></div> <!----> <div class="page-edit"><div class="edit-link"><a href="https://github.com/hitqshao/qishao-notes/edit/main/docs/01.hbm/02.hbm_dead_block_predictor.md" target="_blank" rel="noopener noreferrer">帮助我们改善此页面</a> <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></div> <!----> <div class="last-updated"><span class="prefix">上次更新:</span> <span class="time">2023/11/21, 20:25:48</span></div></div> <div class="page-nav-wapper"><div class="page-nav-centre-wrap"><a href="/qishao-notes/pages/24769e/" class="page-nav-centre page-nav-centre-prev"><div class="tooltip">HBM Paper List</div></a> <a href="/qishao-notes/pages/24769f/" class="page-nav-centre page-nav-centre-next"><div class="tooltip">Dynamically Adapting  Page Migration Policies Based on Applications Memory Access Behaviors</div></a></div> <div class="page-nav"><p class="inner"><span class="prev">
        ←
        <a href="/qishao-notes/pages/24769e/" class="prev">HBM Paper List</a></span> <span class="next"><a href="/qishao-notes/pages/24769f/">Dynamically Adapting  Page Migration Policies Based on Applications Memory Access Behaviors</a>→
      </span></p></div></div></div> <!----></main></div> <div class="footer"><div class="icons"><a href="https://github.com/hitqshao" title="GitHub" target="_blank" class="iconfont icon-github"></a><a href="mailto:hitqshao@163.com" title="发邮件" target="_blank" class="iconfont icon-youjian"></a><a href="https://gitee.com/hitqshao" title="Gitee" target="_blank" class="iconfont icon-gitee"></a></div> 
  Theme by
  <a href="https://github.com/xugaoyi/vuepress-theme-vdoing" target="_blank" title="本站主题">Vdoing</a> 
    | Copyright © 2022-2023
    <span>Eryajf | <a href="https://github.com/hitqshao/qishao-notes/blob/main/LICENSE" target="_blank">MIT License</a></span></div> <div class="buttons"><div title="返回顶部" class="button blur go-to-top iconfont icon-fanhuidingbu" style="display:none;"></div> <div title="去评论" class="button blur go-to-comment iconfont icon-pinglun" style="display:none;"></div> <div title="主题模式" class="button blur theme-mode-but iconfont icon-zhuti"><ul class="select-box" style="display:none;"><li class="iconfont icon-zidong">
          跟随系统
        </li><li class="iconfont icon-rijianmoshi">
          浅色模式
        </li><li class="iconfont icon-yejianmoshi">
          深色模式
        </li><li class="iconfont icon-yuedu">
          阅读模式
        </li></ul></div></div> <!----> <!----> <!----></div><div class="global-ui"><!----></div></div>
    <script src="/qishao-notes/assets/js/app.4cc8c1cf.js" defer></script><script src="/qishao-notes/assets/js/2.72ae8968.js" defer></script><script src="/qishao-notes/assets/js/11.4ef910c2.js" defer></script>
  </body>
</html>

<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>LLM KV Cache Management | CPU &amp; GPU Microarch. Qi Shao</title>
    <meta name="generator" content="VuePress 1.8.0">
    <link rel="stylesheet" href="custom.css">
    <script language="javascript" type="text/javascript" src="/qishao-notes/js/pgmanor-self.js"></script>
    <meta name="description" content="Computer System">
    <meta name="google-site-verification" content="66w5U9NY5gJWu7iBtHKMbhpXkV94jy31L_RHbvrZZzY">
    <meta name="keywords" content="Hitqishao,golang,vue,go-web,go-admin,go-ldap-admin">
    <meta name="theme-color" content="#11a8cd">
    <meta name="referrer" content="no-referrer-when-downgrade">
    
    <link rel="preload" href="/qishao-notes/assets/css/0.styles.b5ad55b3.css" as="style"><link rel="preload" href="/qishao-notes/assets/js/app.2e255673.js" as="script"><link rel="preload" href="/qishao-notes/assets/js/2.0833fe67.js" as="script"><link rel="preload" href="/qishao-notes/assets/js/107.de78e0fa.js" as="script"><link rel="prefetch" href="/qishao-notes/assets/js/10.1e500a78.js"><link rel="prefetch" href="/qishao-notes/assets/js/100.6e7464af.js"><link rel="prefetch" href="/qishao-notes/assets/js/101.09a2e4e5.js"><link rel="prefetch" href="/qishao-notes/assets/js/102.992683c3.js"><link rel="prefetch" href="/qishao-notes/assets/js/103.9351ee37.js"><link rel="prefetch" href="/qishao-notes/assets/js/104.e71d94d2.js"><link rel="prefetch" href="/qishao-notes/assets/js/105.5c4685e8.js"><link rel="prefetch" href="/qishao-notes/assets/js/106.d0319e1a.js"><link rel="prefetch" href="/qishao-notes/assets/js/108.78c2a71f.js"><link rel="prefetch" href="/qishao-notes/assets/js/109.3a1c8f02.js"><link rel="prefetch" href="/qishao-notes/assets/js/11.8a8e0de2.js"><link rel="prefetch" href="/qishao-notes/assets/js/110.6c6f8b65.js"><link rel="prefetch" href="/qishao-notes/assets/js/111.aacd5f7e.js"><link rel="prefetch" href="/qishao-notes/assets/js/112.81f0de70.js"><link rel="prefetch" href="/qishao-notes/assets/js/113.4c05e110.js"><link rel="prefetch" href="/qishao-notes/assets/js/114.e9cf2d63.js"><link rel="prefetch" href="/qishao-notes/assets/js/115.e954bd37.js"><link rel="prefetch" href="/qishao-notes/assets/js/116.e5d5d049.js"><link rel="prefetch" href="/qishao-notes/assets/js/117.39139532.js"><link rel="prefetch" href="/qishao-notes/assets/js/118.1bb8fb73.js"><link rel="prefetch" href="/qishao-notes/assets/js/119.76dca3a9.js"><link rel="prefetch" href="/qishao-notes/assets/js/12.8535d463.js"><link rel="prefetch" href="/qishao-notes/assets/js/120.a6092545.js"><link rel="prefetch" href="/qishao-notes/assets/js/121.f011f41c.js"><link rel="prefetch" href="/qishao-notes/assets/js/122.f96c6ac5.js"><link rel="prefetch" href="/qishao-notes/assets/js/123.77fce597.js"><link rel="prefetch" href="/qishao-notes/assets/js/124.39c82446.js"><link rel="prefetch" href="/qishao-notes/assets/js/125.b30edeb3.js"><link rel="prefetch" href="/qishao-notes/assets/js/126.38d7c1e0.js"><link rel="prefetch" href="/qishao-notes/assets/js/127.f46fbb4c.js"><link rel="prefetch" href="/qishao-notes/assets/js/128.3cccc814.js"><link rel="prefetch" href="/qishao-notes/assets/js/129.0c613cce.js"><link rel="prefetch" href="/qishao-notes/assets/js/13.7de2e04b.js"><link rel="prefetch" href="/qishao-notes/assets/js/130.cba1fd9b.js"><link rel="prefetch" href="/qishao-notes/assets/js/131.a264725c.js"><link rel="prefetch" href="/qishao-notes/assets/js/132.5cb71761.js"><link rel="prefetch" href="/qishao-notes/assets/js/133.85a37ee1.js"><link rel="prefetch" href="/qishao-notes/assets/js/134.625552e0.js"><link rel="prefetch" href="/qishao-notes/assets/js/135.f2db76c7.js"><link rel="prefetch" href="/qishao-notes/assets/js/136.a8b4aa20.js"><link rel="prefetch" href="/qishao-notes/assets/js/137.c756b4b7.js"><link rel="prefetch" href="/qishao-notes/assets/js/14.466ec3ac.js"><link rel="prefetch" href="/qishao-notes/assets/js/15.bea831d7.js"><link rel="prefetch" href="/qishao-notes/assets/js/16.05da202f.js"><link rel="prefetch" href="/qishao-notes/assets/js/17.63fdd997.js"><link rel="prefetch" href="/qishao-notes/assets/js/18.bc4a5b1d.js"><link rel="prefetch" href="/qishao-notes/assets/js/19.a2c2ac4d.js"><link rel="prefetch" href="/qishao-notes/assets/js/20.a4b6fb1c.js"><link rel="prefetch" href="/qishao-notes/assets/js/21.8a5b62d4.js"><link rel="prefetch" href="/qishao-notes/assets/js/22.4d84fdc5.js"><link rel="prefetch" href="/qishao-notes/assets/js/23.4d4cd4e1.js"><link rel="prefetch" href="/qishao-notes/assets/js/24.88ca611d.js"><link rel="prefetch" href="/qishao-notes/assets/js/25.54245a6c.js"><link rel="prefetch" href="/qishao-notes/assets/js/26.ab4d38ce.js"><link rel="prefetch" href="/qishao-notes/assets/js/27.ae348b88.js"><link rel="prefetch" href="/qishao-notes/assets/js/28.781915d4.js"><link rel="prefetch" href="/qishao-notes/assets/js/29.7232bd8c.js"><link rel="prefetch" href="/qishao-notes/assets/js/3.3d907fd4.js"><link rel="prefetch" href="/qishao-notes/assets/js/30.0858b5b0.js"><link rel="prefetch" href="/qishao-notes/assets/js/31.f46e7aaf.js"><link rel="prefetch" href="/qishao-notes/assets/js/32.584d6540.js"><link rel="prefetch" href="/qishao-notes/assets/js/33.530df744.js"><link rel="prefetch" href="/qishao-notes/assets/js/34.54012013.js"><link rel="prefetch" href="/qishao-notes/assets/js/35.01d6cf82.js"><link rel="prefetch" href="/qishao-notes/assets/js/36.c355ce28.js"><link rel="prefetch" href="/qishao-notes/assets/js/37.6cb48c78.js"><link rel="prefetch" href="/qishao-notes/assets/js/38.9f9585d9.js"><link rel="prefetch" href="/qishao-notes/assets/js/39.7f09c090.js"><link rel="prefetch" href="/qishao-notes/assets/js/4.2dcb8de5.js"><link rel="prefetch" href="/qishao-notes/assets/js/40.5f352ae8.js"><link rel="prefetch" href="/qishao-notes/assets/js/41.bcc7509d.js"><link rel="prefetch" href="/qishao-notes/assets/js/42.350453bb.js"><link rel="prefetch" href="/qishao-notes/assets/js/43.18008ea4.js"><link rel="prefetch" href="/qishao-notes/assets/js/44.331b7e8f.js"><link rel="prefetch" href="/qishao-notes/assets/js/45.acbac3e6.js"><link rel="prefetch" href="/qishao-notes/assets/js/46.5ad3e7da.js"><link rel="prefetch" href="/qishao-notes/assets/js/47.ad15993e.js"><link rel="prefetch" href="/qishao-notes/assets/js/48.74d6845e.js"><link rel="prefetch" href="/qishao-notes/assets/js/49.837fe395.js"><link rel="prefetch" href="/qishao-notes/assets/js/5.9d58ea7e.js"><link rel="prefetch" href="/qishao-notes/assets/js/50.50e7ab9a.js"><link rel="prefetch" href="/qishao-notes/assets/js/51.26a65cae.js"><link rel="prefetch" href="/qishao-notes/assets/js/52.df456841.js"><link rel="prefetch" href="/qishao-notes/assets/js/53.00cfb273.js"><link rel="prefetch" href="/qishao-notes/assets/js/54.0467e711.js"><link rel="prefetch" href="/qishao-notes/assets/js/55.545b33b8.js"><link rel="prefetch" href="/qishao-notes/assets/js/56.85482b52.js"><link rel="prefetch" href="/qishao-notes/assets/js/57.5b3e3c24.js"><link rel="prefetch" href="/qishao-notes/assets/js/58.a1fbdc11.js"><link rel="prefetch" href="/qishao-notes/assets/js/59.5a90503c.js"><link rel="prefetch" href="/qishao-notes/assets/js/6.bca7e213.js"><link rel="prefetch" href="/qishao-notes/assets/js/60.257e363f.js"><link rel="prefetch" href="/qishao-notes/assets/js/61.df4a5b47.js"><link rel="prefetch" href="/qishao-notes/assets/js/62.f1be6ae5.js"><link rel="prefetch" href="/qishao-notes/assets/js/63.b9c3a1f9.js"><link rel="prefetch" href="/qishao-notes/assets/js/64.eeb3f036.js"><link rel="prefetch" href="/qishao-notes/assets/js/65.db55939d.js"><link rel="prefetch" href="/qishao-notes/assets/js/66.02f7a734.js"><link rel="prefetch" href="/qishao-notes/assets/js/67.4fb49cdd.js"><link rel="prefetch" href="/qishao-notes/assets/js/68.b7cb5686.js"><link rel="prefetch" href="/qishao-notes/assets/js/69.f45db467.js"><link rel="prefetch" href="/qishao-notes/assets/js/7.3eecfe51.js"><link rel="prefetch" href="/qishao-notes/assets/js/70.cef4957c.js"><link rel="prefetch" href="/qishao-notes/assets/js/71.abfe714d.js"><link rel="prefetch" href="/qishao-notes/assets/js/72.d2933de4.js"><link rel="prefetch" href="/qishao-notes/assets/js/73.73c3f331.js"><link rel="prefetch" href="/qishao-notes/assets/js/74.65018581.js"><link rel="prefetch" href="/qishao-notes/assets/js/75.2cc978a8.js"><link rel="prefetch" href="/qishao-notes/assets/js/76.f83e87e1.js"><link rel="prefetch" href="/qishao-notes/assets/js/77.0fcdf383.js"><link rel="prefetch" href="/qishao-notes/assets/js/78.911c1624.js"><link rel="prefetch" href="/qishao-notes/assets/js/79.7186ac8a.js"><link rel="prefetch" href="/qishao-notes/assets/js/8.b6a1e324.js"><link rel="prefetch" href="/qishao-notes/assets/js/80.0c6a4d23.js"><link rel="prefetch" href="/qishao-notes/assets/js/81.6973a6ed.js"><link rel="prefetch" href="/qishao-notes/assets/js/82.f9aa4894.js"><link rel="prefetch" href="/qishao-notes/assets/js/83.0b6a61fe.js"><link rel="prefetch" href="/qishao-notes/assets/js/84.975e2bf3.js"><link rel="prefetch" href="/qishao-notes/assets/js/85.46751589.js"><link rel="prefetch" href="/qishao-notes/assets/js/86.352afce0.js"><link rel="prefetch" href="/qishao-notes/assets/js/87.10b1aa96.js"><link rel="prefetch" href="/qishao-notes/assets/js/88.b6460627.js"><link rel="prefetch" href="/qishao-notes/assets/js/89.b48cdf4e.js"><link rel="prefetch" href="/qishao-notes/assets/js/9.eaed4e75.js"><link rel="prefetch" href="/qishao-notes/assets/js/90.c440100e.js"><link rel="prefetch" href="/qishao-notes/assets/js/91.3250e6fd.js"><link rel="prefetch" href="/qishao-notes/assets/js/92.59be3e8e.js"><link rel="prefetch" href="/qishao-notes/assets/js/93.7463a61b.js"><link rel="prefetch" href="/qishao-notes/assets/js/94.ebf130d8.js"><link rel="prefetch" href="/qishao-notes/assets/js/95.6f481d6f.js"><link rel="prefetch" href="/qishao-notes/assets/js/96.caee7198.js"><link rel="prefetch" href="/qishao-notes/assets/js/97.754ba5da.js"><link rel="prefetch" href="/qishao-notes/assets/js/98.2f73cb53.js"><link rel="prefetch" href="/qishao-notes/assets/js/99.a5869103.js">
    <link rel="stylesheet" href="/qishao-notes/assets/css/0.styles.b5ad55b3.css">
  </head>
  <body class="theme-mode-light">
    <div id="app" data-server-rendered="true"><div class="theme-container sidebar-open have-rightmenu"><header class="navbar blur"><div title="ÁõÆÂΩï" class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/qishao-notes/" class="home-link router-link-active"><!----> <span class="site-name">CPU &amp; GPU Microarch. Qi Shao</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/qishao-notes/" class="nav-link">Home</a></div><div class="nav-item"><a href="/qishao-notes/gpu/" class="nav-link">gpu</a></div><div class="nav-item"><a href="/qishao-notes/cpu/" class="nav-link">cpu</a></div><div class="nav-item"><a href="/qishao-notes/llm/" class="nav-link">ml&amp;llm</a></div><div class="nav-item"><a href="/qishao-notes/compiler/" class="nav-link">compiler</a></div><div class="nav-item"><a href="/qishao-notes/hbm/" class="nav-link">hbm</a></div><div class="nav-item"><a href="/qishao-notes/mix/" class="nav-link">program</a></div><div class="nav-item"><a href="/qishao-notes/unix/" class="nav-link">unix</a></div><div class="nav-item"><a href="https://blog.csdn.net/hit_shaoqi" target="_blank" rel="noopener noreferrer" class="nav-link external">
  CSDN
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></div> <a href="https://github.com/hitqshao/qishao-notes" target="_blank" rel="noopener noreferrer" class="repo-link">
    GitHub
    <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></nav></div></header> <div class="sidebar-mask"></div> <div class="sidebar-hover-trigger"></div> <aside class="sidebar" style="display:none;"><!----> <nav class="nav-links"><div class="nav-item"><a href="/qishao-notes/" class="nav-link">Home</a></div><div class="nav-item"><a href="/qishao-notes/gpu/" class="nav-link">gpu</a></div><div class="nav-item"><a href="/qishao-notes/cpu/" class="nav-link">cpu</a></div><div class="nav-item"><a href="/qishao-notes/llm/" class="nav-link">ml&amp;llm</a></div><div class="nav-item"><a href="/qishao-notes/compiler/" class="nav-link">compiler</a></div><div class="nav-item"><a href="/qishao-notes/hbm/" class="nav-link">hbm</a></div><div class="nav-item"><a href="/qishao-notes/mix/" class="nav-link">program</a></div><div class="nav-item"><a href="/qishao-notes/unix/" class="nav-link">unix</a></div><div class="nav-item"><a href="https://blog.csdn.net/hit_shaoqi" target="_blank" rel="noopener noreferrer" class="nav-link external">
  CSDN
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></div> <a href="https://github.com/hitqshao/qishao-notes" target="_blank" rel="noopener noreferrer" class="repo-link">
    GitHub
    <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></nav>  <ul class="sidebar-links"><li><a href="/qishao-notes/pages/dc7035/" class="sidebar-link">how LLM works</a></li><li><a href="/qishao-notes/pages/dc7036/" class="sidebar-link">LLM Hardware Optimization</a></li><li><a href="/qishao-notes/pages/dc7037/" class="sidebar-link">How to run llama.cpp with gem5</a></li><li><a href="/qishao-notes/pages/dc7038/" class="sidebar-link">Memory Usage in Training LLM</a></li><li><a href="/qishao-notes/pages/dc7039/" class="sidebar-link">LLM optimizations</a></li><li><a href="/qishao-notes/pages/dc7040/" class="sidebar-link">LLM flash algorthms</a></li><li><a href="/qishao-notes/pages/dc7041/" class="sidebar-link">LLM compute &amp; memory bound</a></li><li><a href="/qishao-notes/pages/dc7042/" class="sidebar-link">LLM Paper List</a></li><li><a href="/qishao-notes/pages/dc7043/" class="sidebar-link">Efficient LLM</a></li><li><a href="/qishao-notes/pages/dc7045/" class="sidebar-link">Estimation of LLM</a></li><li><a href="/qishao-notes/pages/dc7046/" class="sidebar-link">Summery of Inner Workings of LLM</a></li><li><a href="/qishao-notes/pages/dc7047/" class="sidebar-link">List of LLM Optimization Techniques</a></li><li><a href="/qishao-notes/pages/dc7048/" class="sidebar-link">Memory Optimizations in LLM</a></li><li><a href="/qishao-notes/pages/dc7049/" class="sidebar-link">Reasoning in LLM</a></li><li><a href="/qishao-notes/pages/dc7050/" class="sidebar-link">LLM Mixed Precision &amp; Quantization &amp; Outlier</a></li><li><a href="/qishao-notes/pages/dc7051/" class="sidebar-link">LLM Sparsity</a></li><li><a href="/qishao-notes/pages/dc7052/" class="sidebar-link">LLM Scaling Law</a></li><li><a href="/qishao-notes/pages/dc7055/" class="sidebar-link">LLM Attention</a></li><li><a href="/qishao-notes/pages/dc7056/" aria-current="page" class="active sidebar-link">LLM KV Cache Management</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header level2"><a href="/qishao-notes/pages/dc7056/#_1-2025-new-can-llms-maintain-fundamental-abilities-under-kv-cache-compression" class="sidebar-link">1. [2025 New] Can LLMs Maintain Fundamental Abilities under KV Cache Compression? üëç</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header level3"><a href="/qishao-notes/pages/dc7056/#key-findings" class="sidebar-link">Key Findings</a></li><li class="sidebar-sub-header level3"><a href="/qishao-notes/pages/dc7056/#proposed-method" class="sidebar-link">Proposed Method</a></li><li class="sidebar-sub-header level3"><a href="/qishao-notes/pages/dc7056/#insights" class="sidebar-link">Insights:</a></li><li class="sidebar-sub-header level3"><a href="/qishao-notes/pages/dc7056/#conclusion" class="sidebar-link">Conclusion:</a></li><li class="sidebar-sub-header level3"><a href="/qishao-notes/pages/dc7056/#impact-statement" class="sidebar-link">Impact Statement:</a></li></ul></li></ul></li><li><a href="/qishao-notes/pages/dc7057/" class="sidebar-link">LLM Distributed Machine Learning</a></li><li><a href="/qishao-notes/pages/dc7059/" class="sidebar-link">LLM Internals</a></li><li><a href="/qishao-notes/pages/dc7058/" class="sidebar-link">LLM Posttraining/Finetuning</a></li><li><a href="/qishao-notes/pages/dc7060/" class="sidebar-link">LLM MOE Inference</a></li><li><a href="/qishao-notes/pages/dc7061/" class="sidebar-link">LLM Compression</a></li><li><a href="/qishao-notes/pages/dc7062/" class="sidebar-link">LLM Optimizer Optimization</a></li><li><a href="/qishao-notes/pages/dc7063/" class="sidebar-link">LLM Posttraining</a></li><li><a href="/qishao-notes/pages/dc7064/" class="sidebar-link">LLM MICRO - ISCA - HPCA</a></li><li><a href="/qishao-notes/pages/dc7066/" class="sidebar-link">LLM Prefilling &amp; Decoding Split</a></li><li><a href="/qishao-notes/pages/dc7067/" class="sidebar-link">Thinking of LLM Prefilling &amp; Decoding Split</a></li><li><a href="/qishao-notes/pages/dc7068/" class="sidebar-link">From Attention Sink to Massive Activation</a></li><li><a href="/qishao-notes/pages/dc7069/" class="sidebar-link">LLM CPU &amp; GPU Workloads</a></li></ul> </aside> <div><main class="page"><div class="theme-vdoing-wrapper bg-style-6"><div class="articleInfo-wrap" data-v-06225672><div class="articleInfo" data-v-06225672><ul class="breadcrumbs" data-v-06225672><li data-v-06225672><a href="/qishao-notes/" title="È¶ñÈ°µ" class="iconfont icon-home router-link-active" data-v-06225672></a></li> <li data-v-06225672><a href="/qishao-notes/llm/#llm" data-v-06225672>llm</a></li></ul> <div class="info" data-v-06225672><div title="‰ΩúËÄÖ" class="author iconfont icon-touxiang" data-v-06225672><a href="https://github.com/hitqshao" target="_blank" title="‰ΩúËÄÖ" class="beLink" data-v-06225672>hitqishao</a></div> <div title="ÂàõÂª∫Êó∂Èó¥" class="date iconfont icon-riqi" data-v-06225672><a href="javascript:;" data-v-06225672>2025-02-05</a></div> <!----></div></div></div> <!----> <div class="content-wrapper"><div class="right-menu-wrapper"><div class="right-menu-margin"><div class="right-menu-title">ÁõÆÂΩï</div> <div class="right-menu-content"></div></div></div> <h1><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAB4AAAAeCAYAAAA7MK6iAAAAAXNSR0IArs4c6QAABKFJREFUSA3tVl1oFVcQnrMbrak3QUgkya1akpJYcrUtIqW1JvFBE9LiQ5v6JmJpolbMg32rVrhgoYK0QiMY6i9Y6EMaW5D+xFJaTYItIuK2Kr3+BJNwkxBj05sQY3b3nM6cs2dv9t7NT/vQJw/sndk5M/PNzJkzewGerP+pAmy+ON8lLzUJgA8ZYxYIYZmGYRnctDaWvJJAmTtfP1pvXsBCCPP8QFcCaRkZYACgDZFO4stNIcBCajEOlmmC9XpJ9bAGCaPaPmzPl32dvLSVu3BWCTQs0XQQ6g0DYgwLIoAZbBCdW/i+781o1VVlm/410mw4h06Y7bIPHNyWDyL4FHkX03Q8SrzNhZTZriieckWt7cL6MM85YcLpsi/7O9/iXFT6MswI0DmmpkSaJ0qLxFIm3+i1THHB3zmBH3PYx9CcykcLOeQVVa7QtdxTgQgEleX2AjHYfwA+2ddV77ruGoJUbhGDI09YSNXyMpUt5ylOzxgbUmtOp7NmbNt8v3arjTBfYELmLUV+M+nSawNNAUqpT3ClJWg5I3BLT+cGW/DXNGCa6tx1aakCGEigArTn4TDIPdrXXYKCZNrHLMCOEPvHBlLQ99s9eHB7EB6NTki73CVPQ2F5MSx/uRQixfmq7rK0wYD8w8E905bnPDfwoWs/rfv93NWN/ZfvwsLIU7A09gxECyISeGJkHAau98L97tuw7NXnoPyNF8FcYGLGKsOs0mN3OEyec9esGW/ZEl945dTP34wlR2FZVQWU1q0Cw8Tr7p+hgLLNL0FPxx/Q35mA8aEUrH6nCgwEl0tn7wUiZYJnNRh6DK4UH/k0lfyrsBKdPVv/AriGIQcEDQZ65LBAGe2Rzui9Ybjz7XUppz1/uKBbyVPGkN3ZAeC6hr0x7Nr38N5+EqkoOm17xpoqR9ohQF55ERSvr4Dkr3chNfC3DMzGJlNBElW8w9nsGQvhNGIzDkXzCg8cLK951xHsFBlTJspJNi3ZFIMF2AeDV3q8DNOB+YHi6QTrChDIWDBRi5U5f+ZMfJLu3ccrqxtdxk4SKH336LFxSmkqefwU5T8fhdSdQf9IVKD6aNiwI/hnmcAZ91isYMJIaCUCx9W098+LgruikeTqzqqxKPUwqJyCPJiyemVVZBOijDGjD38Os0jOiSPL1z3SPjXNANbiNPXAdzTfukjjuknNBbyz3nwgTd3AVFqUJ5hpHlq9MveLnWwttUfoygBmvVjuikxND3znrhsELnZk7k+OjIGxeNEkomyLVta0xxn+HZhjBc4YZ/AFjHjz9u3xRZl2BN4aq9nFwWh16IrQ1aHHEd3j1+4/dB9OtH4e29A2H1DyHQRmOSfQZ1Fy7MHBTGB6J/Djq6p3OxyO2cB+4Car7v/o3GXgfAkj23+x9ID1Teoamo/SXcbvSf2PX7Vc8DdCmE1vN9di+32P9/5YR3vLnhCVGUWBjEkr3yh4H8v9CzmsbdhzOKzsJKM90iFdaTMjRPhGVsakRvOaRidljo6H6G7j+ctrJpsP+4COhDIl0La2+FS4+5mlocBaXY5QnGZysIBYoeSsl5qQzrSj/cgNrfuEzlWBfwA+EjrZyWUvpAAAAABJRU5ErkJggg==">LLM KV Cache Management<!----></h1> <!----> <div class="theme-vdoing-content content__default"><ol><li>[2025 New] Can LLMs Maintain Fundamental Abilities under KV Cache Compression? üëç</li> <li>[2025 New] ChunkKV: Semantic-Preserving KV Cache Compression for Efficient Long-Context LLM Inference</li> <li>Deep Learning 101: Lesson 30: Understanding Text with Attention Heatmaps</li> <li>[136] Model Tells You What to Discard: Adaptive KV Cache Compression for LLMs</li> <li>[527] SparseGPT: Massive Language Models Can be Accurately Pruned in One-Shot üëç</li> <li>[77] Token Merging for Fast Stable Diffusion</li> <li>[382] Token Merging: Your ViT But Faster</li></ol> <hr> <h2 id="_1-2025-new-can-llms-maintain-fundamental-abilities-under-kv-cache-compression"><a href="#_1-2025-new-can-llms-maintain-fundamental-abilities-under-kv-cache-compression" class="header-anchor">#</a> 1. [2025 New] Can LLMs Maintain Fundamental Abilities under KV Cache Compression? üëç</h2> <p><em>This is a good paper....but no source code</em></p> <p>This paper investigates the impact of Key-Value (KV) cache compression on the fundamental capabilities of Large Language Models (LLMs).</p> <p>The authors conduct a comprehensive empirical study to evaluate how different KV cache compression methods affect various tasks, including world knowledge, common-sense reasoning, arithmetic reasoning, code generation, safety, and long-context understanding and generation.</p> <p>The study reveals that <strong>KV cache compression methods exhibit task-specific performance degradation, with arithmetic reasoning tasks being particularly sensitive to aggressive compression</strong>.</p> <blockquote><p>The key insight is that the prefill phase KV cache, which contains crucial prompt information, should be compressed once and remain fixed, while the decoding phase KV cache can be dynamically compressed with different strategies.
Given a prefill compression ratio rp, we prioritize shots with higher scores while ensuring the total number of preserved tokens does not exceed the KV cache limit.
Specifically, shots are ranked by their scores and selected in descending order until reaching the compression budget rp √ó |KVprefill|.
This shot-level selection strategy helps maintain the semantic coherence of important examples while adhering to memory constraints.</p></blockquote> <h3 id="key-findings"><a href="#key-findings" class="header-anchor">#</a> Key Findings</h3> <ul><li><p><strong>Task-Specific Performance Degradation:</strong></p> <p>Different tasks show varying levels of sensitivity to KV cache compression.</p> <p>Arithmetic reasoning tasks are the most sensitive, with performance drops ranging from 17.4% to 43.3% under aggressive compression.</p> <p>In contrast, tasks like world knowledge and common-sense reasoning are more resilient.</p></li> <li><p><strong>Robustness of Multi-Step Reasoning Models:</strong></p> <p>Multi-step reasoning LLMs, such as the DeepSeek R1 Distill model, exhibit more robust compression tolerance compared to instruction-tuned models.</p> <p>The DeepSeek R1 Distill model shows only 9.67%-25.53% performance degradation under compression.</p></li> <li><p><strong>Impact of Prompt Length:</strong></p> <p>Shorter prompts are more vulnerable to compression effects.</p> <p>Performance degradation is more pronounced in one-shot and two-shot scenarios compared to prompts with more examples.</p></li> <li><p><strong>Chunk-Level Compression:</strong></p> <p>Chunk-level compression strategies are more effective for complex long-context arithmetic reasoning tasks.</p> <p>These strategies help maintain semantic coherence and improve performance under aggressive compression.</p></li> <li><p><strong>Long-Context Generation Sensitivity:</strong></p> <p>Long-context generation tasks are particularly sensitive to compression, with significant performance degradation observed at low compression ratios.</p></li></ul> <h3 id="proposed-method"><a href="#proposed-method" class="header-anchor">#</a> Proposed Method</h3> <p><strong>ShotKV:</strong> The authors propose ShotKV, a novel compression approach that distinctly handles the prefill and decoding phases while maintaining shot-level semantic coherence.</p> <p>ShotKV achieves 9%-18% performance improvements on long-context generation tasks under aggressive compression ratios.</p> <h3 id="insights"><a href="#insights" class="header-anchor">#</a> Insights:</h3> <ul><li><p><strong>Attention Patterns:</strong></p> <p>The study highlights that attention patterns vary significantly across different tasks.</p> <p>Arithmetic reasoning tasks display increased attention sparsity, while safety tasks show concentrated attention on system prompts. These patterns provide insights into how compression affects various tasks.</p></li> <li><p><strong>Compression Trade-offs:</strong></p> <p>The findings suggest a trade-off between memory efficiency and task performance.</p> <p>While KV cache compression reduces memory usage, it can significantly impact model performance, especially in tasks requiring complex reasoning or extensive knowledge retrieval.</p></li> <li><p><strong>Model Design Implications:</strong>
The higher sensitivity of instruction-tuned models to compression raises questions about the relationship between model training objectives and compression robustness.</p> <p>Future research could explore training techniques that optimize for compression resilience while maintaining instruction-following capabilities.</p></li></ul> <h3 id="conclusion"><a href="#conclusion" class="header-anchor">#</a> Conclusion:</h3> <p>The paper provides valuable insights into the impact of KV cache compression on LLMs' core capabilities.</p> <p>It highlights the need for task-adaptive compression strategies and suggests that multi-step reasoning models are more robust to compression.</p> <p>The proposed ShotKV method demonstrates significant improvements in performance, particularly for long-context generation tasks, making it a promising approach for efficient LLM deployment in resource-constrained environments.</p> <h3 id="impact-statement"><a href="#impact-statement" class="header-anchor">#</a> Impact Statement:</h3> <p>The research has positive implications for reducing computational resources and energy consumption, making AI technology more accessible.</p> <p>However, it also raises concerns about the potential acceleration of LLM adoption and its broader societal impacts, such as employment and privacy. The authors emphasize the importance of responsible deployment and ethical considerations in the application of these technologies.</p></div></div> <!----> <div class="page-edit"><div class="edit-link"><a href="https://github.com/hitqshao/qishao-notes/edit/main/docs/05.llm/19.llm_kv_manage.md" target="_blank" rel="noopener noreferrer">Â∏ÆÂä©Êàë‰ª¨ÊîπÂñÑÊ≠§È°µÈù¢</a> <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></div> <!----> <div class="last-updated"><span class="prefix">‰∏äÊ¨°Êõ¥Êñ∞:</span> <span class="time">2025/05/17, 23:37:52</span></div></div> <div class="page-nav-wapper"><div class="page-nav-centre-wrap"><a href="/qishao-notes/pages/dc7055/" class="page-nav-centre page-nav-centre-prev"><div class="tooltip">LLM Attention</div></a> <a href="/qishao-notes/pages/dc7057/" class="page-nav-centre page-nav-centre-next"><div class="tooltip">LLM Distributed Machine Learning</div></a></div> <div class="page-nav"><p class="inner"><span class="prev">
        ‚Üê
        <a href="/qishao-notes/pages/dc7055/" class="prev">LLM Attention</a></span> <span class="next"><a href="/qishao-notes/pages/dc7057/">LLM Distributed Machine Learning</a>‚Üí
      </span></p></div></div></div> <!----></main></div> <div class="footer"><div class="icons"><a href="https://github.com/hitqshao" title="GitHub" target="_blank" class="iconfont icon-github"></a><a href="mailto:hitqshao@163.com" title="ÂèëÈÇÆ‰ª∂" target="_blank" class="iconfont icon-youjian"></a><a href="https://gitee.com/hitqshao" title="Gitee" target="_blank" class="iconfont icon-gitee"></a></div> 
  Theme by
  <a href="https://github.com/xugaoyi/vuepress-theme-vdoing" target="_blank" title="Êú¨Á´ô‰∏ªÈ¢ò">Vdoing</a> 
    | Copyright ¬© 2022-2025
    <span>Eryajf | <a href="https://github.com/hitqshao/qishao-notes/blob/main/LICENSE" target="_blank">MIT License</a></span></div> <div class="buttons"><div title="ËøîÂõûÈ°∂ÈÉ®" class="button blur go-to-top iconfont icon-fanhuidingbu" style="display:none;"></div> <div title="ÂéªËØÑËÆ∫" class="button blur go-to-comment iconfont icon-pinglun" style="display:none;"></div> <div title="‰∏ªÈ¢òÊ®°Âºè" class="button blur theme-mode-but iconfont icon-zhuti"><ul class="select-box" style="display:none;"><li class="iconfont icon-zidong">
          Ë∑üÈöèÁ≥ªÁªü
        </li><li class="iconfont icon-rijianmoshi">
          ÊµÖËâ≤Ê®°Âºè
        </li><li class="iconfont icon-yejianmoshi">
          Ê∑±Ëâ≤Ê®°Âºè
        </li><li class="iconfont icon-yuedu">
          ÈòÖËØªÊ®°Âºè
        </li></ul></div></div> <!----> <!----> <!----></div><div class="global-ui"><!----></div></div>
    <script src="/qishao-notes/assets/js/app.2e255673.js" defer></script><script src="/qishao-notes/assets/js/2.0833fe67.js" defer></script><script src="/qishao-notes/assets/js/107.de78e0fa.js" defer></script>
  </body>
</html>

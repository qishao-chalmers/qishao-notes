(window.webpackJsonp=window.webpackJsonp||[]).push([[93],{547:function(e,t,n){"use strict";n.r(t);var a=n(9),s=Object(a.a)({},(function(){var e=this,t=e._self._c;return t("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[t("p",[e._v("1.[148] Data Movement is All You Need: A Case Study on Optimizing Transformers\n2.[70 2024] Splitwise: Efficient Generative LLM Inference Using Phase Splitting")]),e._v(" "),t("hr"),e._v(" "),t("h3",{attrs:{id:"_1-data-movement-is-all-you-need-a-case-study-on-optimizing-transformers"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-data-movement-is-all-you-need-a-case-study-on-optimizing-transformers"}},[e._v("#")]),e._v(" 1. Data Movement is All You Need: A Case Study on Optimizing Transformers")]),e._v(" "),t("p",[e._v("Contributions:")]),e._v(" "),t("ul",[t("li",[e._v("We find transformer training to be memory-bound and significantly underperforming on GPUs.")]),e._v(" "),t("li",[e._v("We develop a generic recipe for optimizing training using dataflow analyses.")])]),e._v(" "),t("p",[t("img",{attrs:{src:"https://github.com/user-attachments/assets/26739a63-f1c3-46f6-b0d1-b2aea2e953fa",alt:"image"}})]),e._v(" "),t("p",[t("strong",[e._v("Tensor Constraction")]),e._v(": matrix-matrix multiplication")]),e._v(" "),t("p",[e._v("We consider only MMMs and batched MMMs for simplicity, as these are efficiently supported by cuBLAS."),t("br"),e._v("\nIn transformers, these are linear layers and components of MHA."),t("br"),e._v("\nThese operations are the most compute-intensive part of training a transformer."),t("br"),e._v("\nFor good performance, data layout and algorithm selection (e.g., tiling strategy) are critical.")]),e._v(" "),t("p",[t("strong",[e._v("Statistical Normalization")]),e._v(": softmax and layer normalization"),t("br"),e._v("\nLess compute-intensive than tensors"),t("br"),e._v("\nThis compute pattern means that data layout and vectorization is important for operator performance.")]),e._v(" "),t("p",[t("strong",[e._v("Element-wise Operators")]),e._v(": biases, dropout, activations, and residual connections"),t("br"),e._v("\nThese are the least compute-intensive operations.")]),e._v(" "),t("p",[t("img",{attrs:{src:"https://github.com/user-attachments/assets/791880f1-a512-4778-a0d4-20d29282f898",alt:"image"}})]),e._v(" "),t("hr"),e._v(" "),t("h3",{attrs:{id:"_2-splitwise-efficient-generative-llm-inference-using-phase-splitting"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-splitwise-efficient-generative-llm-inference-using-phase-splitting"}},[e._v("#")]),e._v(" 2. Splitwise: Efficient Generative LLM Inference Using Phase Splitting")]),e._v(" "),t("p",[e._v("First, "),t("strong",[e._v("the prompt computation phase")]),e._v(", in which all the input prompt tokens run through the forward pass of the model in parallel to generate the first output token."),t("br"),e._v("\nThis phase tends to be computationally intensive and requires the high FLOPs (floating point operations per second) of the latest GPUs today."),t("br"),e._v("\nSecond, "),t("strong",[e._v("the token generation phase")]),e._v(", in which subsequent output tokens are generated sequentially based on the forward pass of the last token and all the cached context from previous tokens in the sequence."),t("br"),e._v("\nGiven the lack of compute parallelism, this phase tends to be more memory bandwidth and capacity bound, despite state-of-the-art batching.")]),e._v(" "),t("p",[e._v("The context generated from the attention layers during the prompt computation is saved in the key-value (KV) cache, since it is needed for all the future token generation iterations."),t("br"),e._v("\nAfter the first token is generated, the following tokens only use the last generated token and the KV-cache as inputs to the forward pass of the model."),t("br"),e._v("\nThis makes the subsequent token generation more memory bandwidth and capacity intensive than the computationally heavy prompt phase.")]),e._v(" "),t("p",[t("img",{attrs:{src:"https://github.com/user-attachments/assets/6fcf7ec7-9dc5-460a-8a64-0c85965f15ef",alt:"image"}})])])}),[],!1,null,null,null);t.default=s.exports}}]);
(window.webpackJsonp=window.webpackJsonp||[]).push([[71],{523:function(e,t,a){"use strict";a.r(t);var s=a(9),r=Object(s.a)({},(function(){var e=this,t=e._self._c;return t("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[t("h2",{attrs:{id:"notes-from-youtube-link"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#notes-from-youtube-link"}},[e._v("#")]),e._v(" Notes from "),t("a",{attrs:{href:"https://www.youtube.com/playlist?list=PL6RdenZrxrw-zNX7uuGppWETdxt_JxdMj",target:"_blank",rel:"noopener noreferrer"}},[e._v("Youtube Link"),t("OutboundLink")],1)]),e._v(" "),t("h2",{attrs:{id:"_1-shared-memory"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-shared-memory"}},[e._v("#")]),e._v(" 1. Shared Memory")]),e._v(" "),t("ul",[t("li",[e._v("logicall per block resource")]),e._v(" "),t("li",[e._v("on-chip memory fast")]),e._v(" "),t("li",[e._v("shared by threads in block, but non-visible to threads in other blocks.")])]),e._v(" "),t("p",[t("img",{attrs:{src:"https://github.com/user-attachments/assets/24d08063-cc17-45f1-a11d-78bc6d8e3b82",alt:"image"}})]),e._v(" "),t("h3",{attrs:{id:"stencil-kernel"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#stencil-kernel"}},[e._v("#")]),e._v(" Stencil Kernel")]),e._v(" "),t("p",[e._v("First load the green cells."),t("br"),e._v("\nLoad the boundary cells using boundary threads.")]),e._v(" "),t("p",[t("img",{attrs:{src:"https://github.com/user-attachments/assets/4635a871-e801-4882-9a89-203c5070dec5",alt:"image"}})]),e._v(" "),t("h3",{attrs:{id:"syncthreads"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#syncthreads"}},[e._v("#")]),e._v(" __syncthreads()")]),e._v(" "),t("p",[t("strong",[e._v("Execution Barrier")])]),e._v(" "),t("p",[e._v("synchronize all threads within a block.")]),e._v(" "),t("p",[e._v("Not grid level.")]),e._v(" "),t("p",[t("strong",[e._v("48KB hardware limit")])]),e._v(" "),t("h3",{attrs:{id:"sync-within-blocks-or-throughout-blocks-cooperative-groups"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#sync-within-blocks-or-throughout-blocks-cooperative-groups"}},[e._v("#")]),e._v(" Sync within blocks or throughout blocks: Cooperative Groups")]),e._v(" "),t("p",[t("img",{attrs:{src:"https://github.com/user-attachments/assets/18832079-c094-453e-b7bc-8e95c91fe08c",alt:"image"}})]),e._v(" "),t("hr"),e._v(" "),t("h2",{attrs:{id:"_5-atomics-reductions"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_5-atomics-reductions"}},[e._v("#")]),e._v(" 5. Atomics Reductions")]),e._v(" "),t("p",[e._v("Classic Sweep Reduction\n"),t("img",{attrs:{src:"https://github.com/user-attachments/assets/77e87165-58a8-43ff-a049-495c6c8ec8f4",alt:"image"}})]),e._v(" "),t("p",[t("img",{attrs:{src:"https://github.com/user-attachments/assets/ad2ec91a-307a-4589-bf38-fec7fd489af2",alt:"image"}})]),e._v(" "),t("hr"),e._v(" "),t("h2",{attrs:{id:"_6-managed-memory"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_6-managed-memory"}},[e._v("#")]),e._v(" 6. Managed Memory")]),e._v(" "),t("p",[e._v("Managed Memory does not promise performance."),t("br"),e._v("\nIt only paves ways for software programmer. For example, deepcopy.")]),e._v(" "),t("p",[e._v("We could restore the performance by using cudaMemPrefetchAsync")]),e._v(" "),t("p",[t("img",{attrs:{src:"https://github.com/user-attachments/assets/1466b29c-f4d9-4b8f-9535-b9f70de68b11",alt:"image"}})]),e._v(" "),t("p",[t("strong",[e._v("UM cannot do better than expertly written manual data movement, in most cases")])]),e._v(" "),t("ul",[t("li",[e._v("Unified Memory: Page-faulting")]),e._v(" "),t("li",[e._v("ATS: Nvidia with Power9. ATS service allows GPU to access CPU (Malloc) Memory"),t("br"),e._v("\nOnly works in Power9, not for X86.")]),e._v(" "),t("li",[e._v("HMM: Nvidia is working on HMM to allow similar with ATS.")])]),e._v(" "),t("p",[t("img",{attrs:{src:"https://github.com/user-attachments/assets/4ed00e8e-9afb-45d6-bf56-7faf95801a64",alt:"image"}})]),e._v(" "),t("p",[t("strong",[e._v("cudaDeviceSynchronize() function is necessary")])]),e._v(" "),t("p",[e._v("After cudaLaunch kernel, CPU can execute immedidately, which might read data that has not been processed by GPU yet."),t("br"),e._v("\nThus, synchronize to wait GPU finishing the processing.")]),e._v(" "),t("hr"),e._v(" "),t("h2",{attrs:{id:"_7-concurrency"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_7-concurrency"}},[e._v("#")]),e._v(" 7. Concurrency")]),e._v(" "),t("h3",{attrs:{id:"pin-memory"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#pin-memory"}},[e._v("#")]),e._v(" Pin Memory")]),e._v(" "),t("ul",[t("li",[e._v("Statically allocated in Physical Memory.")]),e._v(" "),t("li",[e._v("Stay out of paging system.")])]),e._v(" "),t("h3",{attrs:{id:"streams"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#streams"}},[e._v("#")]),e._v(" Streams")]),e._v(" "),t("ul",[t("li",[e._v("Sequential in Stream")]),e._v(" "),t("li",[e._v("No order among Streams")])]),e._v(" "),t("p",[t("img",{attrs:{src:"https://github.com/user-attachments/assets/5f2b4794-c6ab-46b5-89c8-97e8d95a0a16",alt:"image"}})]),e._v(" "),t("p",[e._v("host Code could also be put into streams.")]),e._v(" "),t("p",[t("strong",[e._v("Migration(unified memory) call could be more expensive than memcopy.")])]),e._v(" "),t("ul",[t("li",[e._v("memcopy is handled by hardware engine")]),e._v(" "),t("li",[e._v("unfied memory operate at page level and needs update of page tables.")])]),e._v(" "),t("h3",{attrs:{id:"cuda-event"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#cuda-event"}},[e._v("#")]),e._v(" CUDA Event")]),e._v(" "),t("p",[e._v("Most used in timing.")]),e._v(" "),t("h3",{attrs:{id:"concurrent-kernels"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#concurrent-kernels"}},[e._v("#")]),e._v(" Concurrent Kernels")]),e._v(" "),t("p",[t("em",[e._v("Less efficient than saturating the device with a single kernel.")])]),e._v(" "),t("p",[e._v("Scheduler might launch blocks from one kernel as much as much possible, try to exhaust the GPU."),t("br"),e._v("\nIf any resource is totally token, other kenel cannot launch.")]),e._v(" "),t("h3",{attrs:{id:"cuda-graph"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#cuda-graph"}},[e._v("#")]),e._v(" CUDA Graph")]),e._v(" "),t("hr"),e._v(" "),t("h2",{attrs:{id:"_8-gpu-performance-analysis"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_8-gpu-performance-analysis"}},[e._v("#")]),e._v(" 8. GPU Performance Analysis")]),e._v(" "),t("h3",{attrs:{id:"top-level"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#top-level"}},[e._v("#")]),e._v(" TOP-Level")]),e._v(" "),t("ul",[t("li",[e._v("Memory Bound")]),e._v(" "),t("li",[e._v("Compute Bound")]),e._v(" "),t("li",[e._v("Latency Bound\n"),t("ul",[t("li",[e._v("view the issue from idle time of scheduler")]),e._v(" "),t("li",[e._v("view the issue that the workloads shoule be in memory bound or compute bound")])])])]),e._v(" "),t("h3",{attrs:{id:"example"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#example"}},[e._v("#")]),e._v(" Example")]),e._v(" "),t("p",[e._v("If SM Utilization is low, it indicates that there might be latency problem since GPU cannot schedule enough threads.")]),e._v(" "),t("h2",{attrs:{id:"compile"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#compile"}},[e._v("#")]),e._v(" Compile")]),e._v(" "),t("p",[t("em",[e._v("nvcc -o t5 t5.cu -arch=sm_70 -lineinfo")])]),e._v(" "),t("p",[t("em",[e._v("nsys profile --stats=true ./t5")])]),e._v(" "),t("h3",{attrs:{id:"nvidia-nsight-system"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#nvidia-nsight-system"}},[e._v("#")]),e._v(" NVIDIA Nsight System")]),e._v(" "),t("p",[e._v("Mainly for CPU and GPU. Initial timeline, find where to optimize.\nnsys-ui -> open *.qdrep")]),e._v(" "),t("h3",{attrs:{id:"nvidia-compute"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#nvidia-compute"}},[e._v("#")]),e._v(" NVIDIA Compute")]),e._v(" "),t("p",[e._v("Targeting at Kernel\n"),t("em",[e._v("ncu-cli --page details -f -o t5.profout ./t5")])]),e._v(" "),t("p",[e._v("we could find bottleneck from source code.")]),e._v(" "),t("p",[t("img",{attrs:{src:"https://github.com/user-attachments/assets/f93475fb-e6a5-4eac-a4fb-ce467c15f1d8",alt:"image"}})]),e._v(" "),t("hr"),e._v(" "),t("h2",{attrs:{id:"_9-cooperative-groups"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_9-cooperative-groups"}},[e._v("#")]),e._v(" 9. Cooperative Groups")]),e._v(" "),t("h3",{attrs:{id:"block-level-sync"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#block-level-sync"}},[e._v("#")]),e._v(" Block Level Sync")]),e._v(" "),t("p",[t("img",{attrs:{src:"https://github.com/user-attachments/assets/fa0baf0e-e17d-4257-9331-d6d4bf8e9c4f",alt:"image"}})]),e._v(" "),t("h3",{attrs:{id:"coalesced-group-grid-wide-sync"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#coalesced-group-grid-wide-sync"}},[e._v("#")]),e._v(" Coalesced Group & Grid Wide Sync")]),e._v(" "),t("p",[t("img",{attrs:{src:"https://github.com/user-attachments/assets/379f94a2-1e79-4136-8813-c09318a377bc",alt:"image"}})]),e._v(" "),t("p",[t("img",{attrs:{src:"https://github.com/user-attachments/assets/7d532030-7fbd-4342-a92a-64cf8e500975",alt:"image"}})]),e._v(" "),t("p",[e._v("Sync is not just execution barrier but also visualability barrier.")]),e._v(" "),t("ul",[t("li",[t("p",[e._v("This reduce utilize shuffle."),t("br"),e._v("\nDo not need shared memory in this case. Only thread-inter communication is necessary.\n"),t("img",{attrs:{src:"https://github.com/user-attachments/assets/4688af49-b16f-4542-8596-fa3105aa094e",alt:"image"}})])]),e._v(" "),t("li",[t("p",[e._v("This reduce utilize shared memory and sync.\n"),t("img",{attrs:{src:"https://github.com/user-attachments/assets/316c510c-a285-4e84-b064-91303a3a4751",alt:"image"}})])])]),e._v(" "),t("h3",{attrs:{id:"cooperative-launch-kernel"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#cooperative-launch-kernel"}},[e._v("#")]),e._v(" Cooperative Launch Kernel")]),e._v(" "),t("p",[t("em",[e._v("Deadlock might be introduced.")]),t("br"),e._v("\nIf too many threads in kernel, SM is full of threads waiting in "),t("em",[e._v("grid.sync()")]),e._v(". They are waiting in the queue and idle thread cannot be scheduled."),t("br"),e._v("\nThus, deadlock happens.")]),e._v(" "),t("p",[e._v("use this "),t("em",[e._v("cudaOccupancyMaxActiveBlocksPerMultiprocessor")]),e._v(".")]),e._v(" "),t("p",[t("img",{attrs:{src:"https://github.com/user-attachments/assets/75b09e76-8fdb-4e09-b419-63f1aadc2c21",alt:"image"}})]),e._v(" "),t("h3",{attrs:{id:"persistent-kernel"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#persistent-kernel"}},[e._v("#")]),e._v(" Persistent Kernel")]),e._v(" "),t("p",[e._v("Persistent kernel could keep state in register and shared memory.")]),e._v(" "),t("p",[e._v("Without persistent kernel, kernel communation might need to shuttle state into global memory.")]),e._v(" "),t("h3",{attrs:{id:"coalesced-group"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#coalesced-group"}},[e._v("#")]),e._v(" Coalesced Group")]),e._v(" "),t("p",[t("em",[e._v("force sync of group")]),e._v(": active.group().")]),e._v(" "),t("p",[t("img",{attrs:{src:"https://github.com/user-attachments/assets/f33bf4d9-403a-4c77-89f1-a5d11440a741",alt:"image"}})]),e._v(" "),t("hr"),e._v(" "),t("h2",{attrs:{id:"_10-multithreading-and-cuda-concurrency"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_10-multithreading-and-cuda-concurrency"}},[e._v("#")]),e._v(" 10 Multithreading and CUDA Concurrency")]),e._v(" "),t("hr"),e._v(" "),t("h2",{attrs:{id:"_11-cuda-multi-process-service"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_11-cuda-multi-process-service"}},[e._v("#")]),e._v(" 11 CUDA Multi Process Service")]),e._v(" "),t("hr"),e._v(" "),t("h2",{attrs:{id:"_12-cuda-debugging"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_12-cuda-debugging"}},[e._v("#")]),e._v(" 12 CUDA Debugging")]),e._v(" "),t("h3",{attrs:{id:"cuda-error-codes"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#cuda-error-codes"}},[e._v("#")]),e._v(" CUDA Error Codes")]),e._v(" "),t("p",[t("img",{attrs:{src:"https://github.com/user-attachments/assets/40b8f0b3-e932-4815-9d16-0822dc22fe6c",alt:"image"}})]),e._v(" "),t("h3",{attrs:{id:"compute-sanitizer-tool"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#compute-sanitizer-tool"}},[e._v("#")]),e._v(" Compute Sanitizer Tool")]),e._v(" "),t("ul",[t("li",[e._v("Synchronous Error VS Asynchronous Error")]),e._v(" "),t("li",[e._v("Sticky VS Non-Sticky Error")])]),e._v(" "),t("h3",{attrs:{id:"gdb"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#gdb"}},[e._v("#")]),e._v(" GDB")]),e._v(" "),t("ul",[t("li",[e._v("-g debug host code")]),e._v(" "),t("li",[e._v("-G debug device code")]),e._v(" "),t("li",[e._v("-arch=")])]),e._v(" "),t("p",[t("strong",[e._v("Make sure the kernel is launched.")])]),e._v(" "),t("p",[e._v("nsys profile --stats=true ./my_exe")]),e._v(" "),t("p",[t("img",{attrs:{src:"https://github.com/user-attachments/assets/5f9ad3bc-3b46-400d-9bb8-7487eb5da322",alt:"image"}})]),e._v(" "),t("p",[e._v("swith to another thread: "),t("strong",[e._v("cuda thread(100)")])]),e._v(" "),t("div",{staticClass:"language- line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[e._v("// break at specific line\nb file:linenumber\n\n// set condition\n// hit break point 1 when block id == 2\ncondition 1 b==2\n\n\n// step, not just one step, even step into the function\ns\n\n// print out\np s[0]\n\n// print array of 8 elements\np s[0]@8\n\n// change to another block\ncuda block 1\ncuda thread 2\n\ninfo cuda device\n\nhelp info cuda\n")])]),e._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[e._v("1")]),t("br"),t("span",{staticClass:"line-number"},[e._v("2")]),t("br"),t("span",{staticClass:"line-number"},[e._v("3")]),t("br"),t("span",{staticClass:"line-number"},[e._v("4")]),t("br"),t("span",{staticClass:"line-number"},[e._v("5")]),t("br"),t("span",{staticClass:"line-number"},[e._v("6")]),t("br"),t("span",{staticClass:"line-number"},[e._v("7")]),t("br"),t("span",{staticClass:"line-number"},[e._v("8")]),t("br"),t("span",{staticClass:"line-number"},[e._v("9")]),t("br"),t("span",{staticClass:"line-number"},[e._v("10")]),t("br"),t("span",{staticClass:"line-number"},[e._v("11")]),t("br"),t("span",{staticClass:"line-number"},[e._v("12")]),t("br"),t("span",{staticClass:"line-number"},[e._v("13")]),t("br"),t("span",{staticClass:"line-number"},[e._v("14")]),t("br"),t("span",{staticClass:"line-number"},[e._v("15")]),t("br"),t("span",{staticClass:"line-number"},[e._v("16")]),t("br"),t("span",{staticClass:"line-number"},[e._v("17")]),t("br"),t("span",{staticClass:"line-number"},[e._v("18")]),t("br"),t("span",{staticClass:"line-number"},[e._v("19")]),t("br"),t("span",{staticClass:"line-number"},[e._v("20")]),t("br"),t("span",{staticClass:"line-number"},[e._v("21")]),t("br"),t("span",{staticClass:"line-number"},[e._v("22")]),t("br"),t("span",{staticClass:"line-number"},[e._v("23")]),t("br"),t("span",{staticClass:"line-number"},[e._v("24")]),t("br")])]),t("p",[t("img",{attrs:{src:"https://github.com/user-attachments/assets/41e2009e-a9af-4615-8580-c5a67c377f86",alt:"image"}})]),e._v(" "),t("p",[e._v("When debug CUDA code, notice that "),t("em",[e._v("the thread that you are current debugging, is asynchronous with other threads.")])]),e._v(" "),t("p",[t("img",{attrs:{src:"https://github.com/user-attachments/assets/d7cd30c5-d474-42ad-b6c4-19b58d1f0a63",alt:"image"}})]),e._v(" "),t("p",[e._v("/usr/loca/cuda/include/driver_types.h")]),e._v(" "),t("p",[e._v("The Defined MACRO of errors.")]),e._v(" "),t("hr"),e._v(" "),t("h2",{attrs:{id:"_11-cuda-multi-process-service-2"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_11-cuda-multi-process-service-2"}},[e._v("#")]),e._v(" 11 CUDA Multi Process Service")]),e._v(" "),t("h3",{attrs:{id:"simple-overscription"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#simple-overscription"}},[e._v("#")]),e._v(" Simple Overscription")]),e._v(" "),t("p",[e._v("If the compute resource stays the same, we only divide the compute task by 1/4 and the number of task increase by 4 times,")]),e._v(" "),t("p",[e._v("in each kernel, even in the waveform, it seems like four kernels are running parallelly.")]),e._v(" "),t("p",[e._v("In face, only one kernel is makeing progress. 1/4 workload and 4 kernel switching, the cost of time will stays or even longer, considering overload.")]),e._v(" "),t("p",[t("img",{attrs:{src:"https://github.com/user-attachments/assets/7413d1a4-59ca-4821-9ce6-f767cd2c4211",alt:"image"}})]),e._v(" "),t("p",[e._v("Context overhead ~300MB")]),e._v(" "),t("p",[t("img",{attrs:{src:"https://github.com/user-attachments/assets/549cf21e-5914-4a42-863a-d052bfbf6c06",alt:"image"}})]),e._v(" "),t("h2",{attrs:{id:"multi-process-service"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#multi-process-service"}},[e._v("#")]),e._v(" Multi Process Service")]),e._v(" "),t("p",[t("img",{attrs:{src:"https://github.com/user-attachments/assets/8cb3cc89-53e6-4aa4-9e43-bd3ec4a0fa9a",alt:"image"}})]),e._v(" "),t("p",[t("img",{attrs:{src:"https://github.com/user-attachments/assets/518cd413-e278-485a-970b-dfc2791d95f8",alt:"image"}})]),e._v(" "),t("p",[e._v("Please notice that if the kernel is too small, using multi rank with multi process might not be optimial, considering the overhead of kernel launching.")]),e._v(" "),t("h2",{attrs:{id:"multi-instance-gpu-mig"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#multi-instance-gpu-mig"}},[e._v("#")]),e._v(" Multi-Instance GPU(MIG)")]),e._v(" "),t("p",[e._v("From A100, MIG is supported.")]),e._v(" "),t("p",[e._v("MPS does not guarantee quality of service.")]),e._v(" "),t("p",[e._v("MIG support isolation, guarantee the quality of service.")]),e._v(" "),t("p",[t("img",{attrs:{src:"https://github.com/user-attachments/assets/5047b71e-eb93-4d36-b3cf-5088b844ac6d",alt:"image"}})]),e._v(" "),t("p",[t("img",{attrs:{src:"https://github.com/user-attachments/assets/f303b295-4575-49e7-9251-8696f5de206d",alt:"image"}})])])}),[],!1,null,null,null);t.default=r.exports}}]);
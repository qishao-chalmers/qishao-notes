(window.webpackJsonp=window.webpackJsonp||[]).push([[127],{589:function(e,a,t){"use strict";t.r(a);var s=t(12),n=Object(s.a)({},(function(){var e=this,a=e._self._c;return a("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[a("h1",{attrs:{id:"trl-repo"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#trl-repo"}},[e._v("#")]),e._v(" TRL Repo")]),e._v(" "),a("p",[a("a",{attrs:{href:"https://github.com/huggingface/trl",target:"_blank",rel:"noopener noreferrer"}},[e._v("repo"),a("OutboundLink")],1)]),e._v(" "),a("h2",{attrs:{id:"_1-repository-overview"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_1-repository-overview"}},[e._v("#")]),e._v(" 1. Repository Overview")]),e._v(" "),a("p",[a("strong",[e._v("TRL (Transformer Reinforcement Learning)")])]),e._v(" "),a("ul",[a("li",[e._v("Library for post-training foundation models")]),e._v(" "),a("li",[e._v("Key trainers: "),a("code",[e._v("SFTTrainer")]),e._v(", "),a("code",[e._v("GRPOTrainer")]),e._v(", "),a("code",[e._v("DPOTrainer")]),e._v(", "),a("code",[e._v("RLOOTrainer")]),e._v(", "),a("code",[e._v("PPOTrainer")]),e._v(", "),a("code",[e._v("RewardTrainer")])]),e._v(" "),a("li",[a("strong",[e._v("GRPO")]),e._v(": Group Relative Policy Optimization (memory-efficient RL variant)")])]),e._v(" "),a("hr"),e._v(" "),a("h2",{attrs:{id:"_2-reward-functions"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_2-reward-functions"}},[e._v("#")]),e._v(" 2. Reward Functions")]),e._v(" "),a("h3",{attrs:{id:"types-of-rewards"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#types-of-rewards"}},[e._v("#")]),e._v(" Types of Rewards")]),e._v(" "),a("ul",[a("li",[a("strong",[e._v("Token-wise rewards")]),e._v(": Per-token signals (e.g., MiniLLM teacher-student log prob differences)")]),e._v(" "),a("li",[a("strong",[e._v("Final result rewards")]),e._v(": Single scalar per completion (common in custom reward functions)")])]),e._v(" "),a("h3",{attrs:{id:"built-in-reward-functions"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#built-in-reward-functions"}},[e._v("#")]),e._v(" Built-in Reward Functions")]),e._v(" "),a("h4",{attrs:{id:"accuracy-reward"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#accuracy-reward"}},[e._v("#")]),e._v(" "),a("code",[e._v("accuracy_reward")])]),e._v(" "),a("ul",[a("li",[e._v("Checks if completion matches ground truth (math verification)")]),e._v(" "),a("li",[e._v("Returns: "),a("code",[e._v("1.0")]),e._v(" (correct), "),a("code",[e._v("0.0")]),e._v(" (incorrect), "),a("code",[e._v("None")]),e._v(" (unparseable)")])]),e._v(" "),a("h4",{attrs:{id:"think-format-reward"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#think-format-reward"}},[e._v("#")]),e._v(" "),a("code",[e._v("think_format_reward")])]),e._v(" "),a("ul",[a("li",[e._v("Checks if reasoning is enclosed in "),a("code",[e._v("<think>...</think>")]),e._v(" tags")]),e._v(" "),a("li",[e._v("Returns: "),a("code",[e._v("1.0")]),e._v(" (correct format), "),a("code",[e._v("0.0")]),e._v(" (wrong format)")])]),e._v(" "),a("h4",{attrs:{id:"get-soft-overlong-punishment"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#get-soft-overlong-punishment"}},[e._v("#")]),e._v(" "),a("code",[e._v("get_soft_overlong_punishment")])]),e._v(" "),a("ul",[a("li",[e._v("Penalizes overly long completions")]),e._v(" "),a("li",[e._v("Formula:\n"),a("ul",[a("li",[a("code",[e._v("0.0")]),e._v(" if length ‚â§ L_max - L_cache")]),e._v(" "),a("li",[e._v("Linear penalty if between")]),e._v(" "),a("li",[a("code",[e._v("-1.0")]),e._v(" if > L_max")])])])]),e._v(" "),a("h3",{attrs:{id:"multiple-reward-functions"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#multiple-reward-functions"}},[e._v("#")]),e._v(" Multiple Reward Functions")]),e._v(" "),a("ul",[a("li",[a("code",[e._v("rewards_per_func")]),e._v(" shape: "),a("code",[e._v("(num_completions, num_reward_functions)")])]),e._v(" "),a("li",[e._v("Each column = one reward function")]),e._v(" "),a("li",[e._v("Combined via weighted sum:"),a("div",{staticClass:"language-python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[e._v("rewards "),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("=")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("(")]),e._v("rewards_per_func "),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("*")]),e._v(" reward_weights"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(".")]),e._v("nansum"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("(")]),e._v("dim"),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[e._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(")")]),e._v("\n")])]),e._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[e._v("1")]),a("br")])])])]),e._v(" "),a("hr"),e._v(" "),a("h2",{attrs:{id:"_3-grpo-mechanism"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_3-grpo-mechanism"}},[e._v("#")]),e._v(" 3. GRPO Mechanism")]),e._v(" "),a("h3",{attrs:{id:"core-algorithm-steps"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#core-algorithm-steps"}},[e._v("#")]),e._v(" Core Algorithm Steps")]),e._v(" "),a("ol",[a("li",[a("strong",[e._v("Generation")]),e._v(": Generate "),a("code",[e._v("G")]),e._v(" completions per prompt (default "),a("code",[e._v("G=8")]),e._v(")")]),e._v(" "),a("li",[a("strong",[e._v("Reward Computation")]),e._v(": Compute rewards for each completion")]),e._v(" "),a("li",[a("strong",[e._v("Group-Relative Advantage")]),e._v(":"),a("div",{staticClass:"language-python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[e._v("advantages "),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("=")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("(")]),e._v("rewards "),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("-")]),e._v(" mean_grouped_rewards"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(")")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("/")]),e._v(" std_grouped_rewards\n")])]),e._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[e._v("1")]),a("br")])]),a("ul",[a("li",[e._v("Normalized within each group (prompt)")])])]),e._v(" "),a("li",[a("strong",[e._v("Loss Computation")]),e._v(": Clipped surrogate objective with KL regularization")]),e._v(" "),a("li",[a("strong",[e._v("Backpropagation")]),e._v(": Gradients flow back to update model")])]),e._v(" "),a("h3",{attrs:{id:"loss-types"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#loss-types"}},[e._v("#")]),e._v(" Loss Types")]),e._v(" "),a("table",[a("thead",[a("tr",[a("th",[e._v("Loss Type")]),e._v(" "),a("th",[e._v("Normalization Method")]),e._v(" "),a("th",[e._v("Notes")])])]),e._v(" "),a("tbody",[a("tr",[a("td",[a("code",[e._v('"grpo"')])]),e._v(" "),a("td",[e._v("Per completion, then average")]),e._v(" "),a("td",[e._v("Has length bias")])]),e._v(" "),a("tr",[a("td",[a("code",[e._v('"dapo"')])]),e._v(" "),a("td",[e._v("Global token count")]),e._v(" "),a("td",[a("strong",[e._v("Recommended")]),e._v(" (no length bias)")])]),e._v(" "),a("tr",[a("td",[a("code",[e._v('"dr_grpo"')])]),e._v(" "),a("td",[a("code",[e._v("batch_size √ó max_completion_length")])]),e._v(" "),a("td",[e._v("Fixed constant")])]),e._v(" "),a("tr",[a("td",[a("code",[e._v('"bnpo"')])]),e._v(" "),a("td",[e._v("Local batch token count")]),e._v(" "),a("td",[e._v("Varies with batch size")])]),e._v(" "),a("tr",[a("td",[a("code",[e._v('"cispo"')])]),e._v(" "),a("td",[e._v("Clips importance sampling weights")]),e._v(" "),a("td",[e._v("Different clipping strategy")])]),e._v(" "),a("tr",[a("td",[a("code",[e._v('"sapo"')])]),e._v(" "),a("td",[e._v("Soft adaptive policy optimization")]),e._v(" "),a("td",[e._v("Temperature-controlled")])])])]),e._v(" "),a("h3",{attrs:{id:"verification-against-theory"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#verification-against-theory"}},[e._v("#")]),e._v(" Verification Against Theory")]),e._v(" "),a("p",[e._v("‚úÖ "),a("strong",[e._v("Implementation matches theory")]),e._v(":")]),e._v(" "),a("ul",[a("li",[e._v("Group-relative advantages ‚úì")]),e._v(" "),a("li",[e._v("Clipped surrogate loss ‚úì")]),e._v(" "),a("li",[e._v("KL regularization ‚úì")])]),e._v(" "),a("hr"),e._v(" "),a("h2",{attrs:{id:"_4-loss-computation-details"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_4-loss-computation-details"}},[e._v("#")]),e._v(" 4. Loss Computation Details")]),e._v(" "),a("h3",{attrs:{id:"per-completion-vs-final-loss"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#per-completion-vs-final-loss"}},[e._v("#")]),e._v(" Per-Completion vs Final Loss")]),e._v(" "),a("ul",[a("li",[a("strong",[e._v("Per-token losses")]),e._v(": Computed for each token in each completion ‚Üí shape "),a("code",[e._v("(B, T)")])]),e._v(" "),a("li",[a("strong",[e._v("Per-completion losses")]),e._v(": Aggregated per completion ‚Üí shape "),a("code",[e._v("(B,)")])]),e._v(" "),a("li",[a("strong",[e._v("Final scalar loss")]),e._v(": Averaged across completions ‚Üí shape "),a("code",[e._v("()")]),e._v(" (scalar)")])]),e._v(" "),a("h3",{attrs:{id:"loss-aggregation-for-grpo"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#loss-aggregation-for-grpo"}},[e._v("#")]),e._v(" Loss Aggregation (for "),a("code",[e._v('"grpo"')]),e._v(")")]),e._v(" "),a("div",{staticClass:"language-python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[e._v("per_completion_loss "),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("=")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("(")]),e._v("per_token_loss "),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("*")]),e._v(" mask"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(".")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[e._v("sum")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("(")]),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("-")]),a("span",{pre:!0,attrs:{class:"token number"}},[e._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(")")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("/")]),e._v(" mask"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(".")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[e._v("sum")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("(")]),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("-")]),a("span",{pre:!0,attrs:{class:"token number"}},[e._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(")")]),e._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[e._v("# (B,)")]),e._v("\nfinal_loss "),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("=")]),e._v(" per_completion_loss"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(".")]),e._v("mean"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(")")]),e._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[e._v("# scalar")]),e._v("\n")])]),e._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[e._v("1")]),a("br"),a("span",{staticClass:"line-number"},[e._v("2")]),a("br")])]),a("h3",{attrs:{id:"each-completion-contributes-differently"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#each-completion-contributes-differently"}},[e._v("#")]),e._v(" Each Completion Contributes Differently")]),e._v(" "),a("ul",[a("li",[e._v("‚úÖ "),a("strong",[e._v("Good completions")]),e._v(" (positive advantage) ‚Üí negative loss contribution (encouraged)")]),e._v(" "),a("li",[e._v("‚ùå "),a("strong",[e._v("Bad completions")]),e._v(" (negative advantage) ‚Üí positive loss contribution (discouraged)")]),e._v(" "),a("li",[e._v("‚ö™ "),a("strong",[e._v("Average completions")]),e._v(" (zero advantage) ‚Üí neutral contribution")])]),e._v(" "),a("hr"),e._v(" "),a("h2",{attrs:{id:"_5-forward-pass-hidden-states"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_5-forward-pass-hidden-states"}},[e._v("#")]),e._v(" 5. Forward Pass & Hidden States")]),e._v(" "),a("h3",{attrs:{id:"hidden-states"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#hidden-states"}},[e._v("#")]),e._v(" Hidden States")]),e._v(" "),a("ul",[a("li",[a("strong",[e._v("Shape at each layer")]),e._v(": "),a("code",[e._v("(B, L, H)")]),e._v(" where:\n"),a("ul",[a("li",[a("code",[e._v("B")]),e._v(" = total completions")]),e._v(" "),a("li",[a("code",[e._v("L")]),e._v(" = sequence length")]),e._v(" "),a("li",[a("code",[e._v("H")]),e._v(" = hidden dimension")])])]),e._v(" "),a("li",[a("strong",[e._v("Each completion has independent hidden states")]),e._v(" (NOT averaged)")]),e._v(" "),a("li",[a("strong",[e._v("Processed in parallel")]),e._v(" as a batch")])]),e._v(" "),a("h3",{attrs:{id:"forward-pass-flow"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#forward-pass-flow"}},[e._v("#")]),e._v(" Forward Pass Flow")]),e._v(" "),a("div",{staticClass:"language- line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v("input_ids (B, L)\n    ‚Üì\nModel\n    ‚Üì\nHidden States Layer 1 (B, L, H)\n    ‚Üì\nHidden States Layer 2 (B, L, H)\n    ‚Üì\n... (all layers)\n    ‚Üì\nLogits (B, L, vocab_size)\n    ‚Üì\nPer-token logprobs (B, T)\n    ‚Üì\nPer-token losses (B, T)\n    ‚Üì\nPer-completion losses (B,)\n    ‚Üì\nFinal scalar loss ()\n")])]),e._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[e._v("1")]),a("br"),a("span",{staticClass:"line-number"},[e._v("2")]),a("br"),a("span",{staticClass:"line-number"},[e._v("3")]),a("br"),a("span",{staticClass:"line-number"},[e._v("4")]),a("br"),a("span",{staticClass:"line-number"},[e._v("5")]),a("br"),a("span",{staticClass:"line-number"},[e._v("6")]),a("br"),a("span",{staticClass:"line-number"},[e._v("7")]),a("br"),a("span",{staticClass:"line-number"},[e._v("8")]),a("br"),a("span",{staticClass:"line-number"},[e._v("9")]),a("br"),a("span",{staticClass:"line-number"},[e._v("10")]),a("br"),a("span",{staticClass:"line-number"},[e._v("11")]),a("br"),a("span",{staticClass:"line-number"},[e._v("12")]),a("br"),a("span",{staticClass:"line-number"},[e._v("13")]),a("br"),a("span",{staticClass:"line-number"},[e._v("14")]),a("br"),a("span",{staticClass:"line-number"},[e._v("15")]),a("br"),a("span",{staticClass:"line-number"},[e._v("16")]),a("br"),a("span",{staticClass:"line-number"},[e._v("17")]),a("br"),a("span",{staticClass:"line-number"},[e._v("18")]),a("br"),a("span",{staticClass:"line-number"},[e._v("19")]),a("br")])]),a("hr"),e._v(" "),a("h2",{attrs:{id:"_6-backpropagation-gradients"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_6-backpropagation-gradients"}},[e._v("#")]),e._v(" 6. Backpropagation & Gradients")]),e._v(" "),a("h3",{attrs:{id:"why-final-scalar-loss-is-needed"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#why-final-scalar-loss-is-needed"}},[e._v("#")]),e._v(" Why Final Scalar Loss is Needed")]),e._v(" "),a("ul",[a("li",[e._v("‚ùå "),a("strong",[e._v("Cannot call "),a("code",[e._v(".backward()")])]),e._v(" on tensor with shape "),a("code",[e._v("(B,)")])]),e._v(" "),a("li",[e._v("‚úÖ "),a("strong",[e._v("PyTorch requires scalar")]),e._v(" for "),a("code",[e._v(".backward()")])]),e._v(" "),a("li",[e._v("‚úÖ "),a("strong",[e._v("Final scalar loss")]),e._v(" enables backpropagation")])]),e._v(" "),a("h3",{attrs:{id:"gradient-flow-through-mean"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#gradient-flow-through-mean"}},[e._v("#")]),e._v(" Gradient Flow Through "),a("code",[e._v(".mean()")])]),e._v(" "),a("p",[e._v("When "),a("code",[e._v("final_loss = mean([loss_0, loss_1, ..., loss_B-1])")]),e._v(" and "),a("code",[e._v("final_loss.backward()")]),e._v(":")]),e._v(" "),a("ul",[a("li",[e._v("Each completion receives "),a("code",[e._v("1/B")]),e._v(" of the gradient")]),e._v(" "),a("li",[e._v("Gradients flow "),a("strong",[e._v("independently")]),e._v(" through each completion's computational graph")]),e._v(" "),a("li",[e._v("Model parameters "),a("strong",[e._v("accumulate")]),e._v(" gradients from all completions")])]),e._v(" "),a("h3",{attrs:{id:"mathematical-flow"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#mathematical-flow"}},[e._v("#")]),e._v(" Mathematical Flow")]),e._v(" "),a("div",{staticClass:"language- line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v("Final Loss (scalar): loss = mean([loss_0, loss_1, loss_2])\n                              ‚Üì backward() with grad=1.0\n                              ‚Üì\nMean Operation:       grad_loss_i = 1.0 / B\n                              ‚Üì\nPer-Completion Losses:\n  loss_0: receives grad = 1/B ‚Üí flows to completion_0's tokens\n  loss_1: receives grad = 1/B ‚Üí flows to completion_1's tokens\n  loss_2: receives grad = 1/B ‚Üí flows to completion_2's tokens\n                              ‚Üì\nModel Parameters:\n  Gradients accumulate from all completions\n")])]),e._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[e._v("1")]),a("br"),a("span",{staticClass:"line-number"},[e._v("2")]),a("br"),a("span",{staticClass:"line-number"},[e._v("3")]),a("br"),a("span",{staticClass:"line-number"},[e._v("4")]),a("br"),a("span",{staticClass:"line-number"},[e._v("5")]),a("br"),a("span",{staticClass:"line-number"},[e._v("6")]),a("br"),a("span",{staticClass:"line-number"},[e._v("7")]),a("br"),a("span",{staticClass:"line-number"},[e._v("8")]),a("br"),a("span",{staticClass:"line-number"},[e._v("9")]),a("br"),a("span",{staticClass:"line-number"},[e._v("10")]),a("br"),a("span",{staticClass:"line-number"},[e._v("11")]),a("br"),a("span",{staticClass:"line-number"},[e._v("12")]),a("br")])]),a("hr"),e._v(" "),a("h2",{attrs:{id:"_7-pure-rl-trainers-no-teacher-model"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_7-pure-rl-trainers-no-teacher-model"}},[e._v("#")]),e._v(" 7. Pure RL Trainers (No Teacher Model)")]),e._v(" "),a("h3",{attrs:{id:"trainers-without-teacher-models"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#trainers-without-teacher-models"}},[e._v("#")]),e._v(" Trainers WITHOUT Teacher Models")]),e._v(" "),a("ul",[a("li",[a("strong",[a("code",[e._v("GRPOTrainer")])]),e._v(" (when "),a("code",[e._v("beta=0.0")]),e._v("): No reference model, pure RL")]),e._v(" "),a("li",[a("strong",[a("code",[e._v("RLOOTrainer")])]),e._v(": REINFORCE Leave-One-Out")]),e._v(" "),a("li",[a("strong",[a("code",[e._v("PPOTrainer")])]),e._v(": Proximal Policy Optimization")])]),e._v(" "),a("h3",{attrs:{id:"trainers-with-teacher-models"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#trainers-with-teacher-models"}},[e._v("#")]),e._v(" Trainers WITH Teacher Models")]),e._v(" "),a("ul",[a("li",[a("strong",[a("code",[e._v("MiniLLMTrainer")])]),e._v(": Uses teacher model for knowledge distillation\n"),a("ul",[a("li",[e._v("Rewards = "),a("code",[e._v("teacher_logprobs - student_logprobs")]),e._v(" (token-wise)")])])])]),e._v(" "),a("hr"),e._v(" "),a("h2",{attrs:{id:"_8-key-implementation-details"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_8-key-implementation-details"}},[e._v("#")]),e._v(" 8. Key Implementation Details")]),e._v(" "),a("h3",{attrs:{id:"token-wise-vs-sequence-wise"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#token-wise-vs-sequence-wise"}},[e._v("#")]),e._v(" Token-wise vs Sequence-wise")]),e._v(" "),a("ul",[a("li",[e._v("Advantages can be "),a("code",[e._v("(B,)")]),e._v(" (sequence-level) or "),a("code",[e._v("(B, T)")]),e._v(" (token-level)")]),e._v(" "),a("li",[e._v("Loss supports both via conditional unsqueeze")]),e._v(" "),a("li",[e._v("Importance sampling can be token-level or sequence-level")])]),e._v(" "),a("h3",{attrs:{id:"distributed-training"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#distributed-training"}},[e._v("#")]),e._v(" Distributed Training")]),e._v(" "),a("ul",[a("li",[e._v("Rewards gathered across processes before group normalization")]),e._v(" "),a("li",[e._v("Ensures correct group-relative advantage computation")])]),e._v(" "),a("h3",{attrs:{id:"memory-efficiency"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#memory-efficiency"}},[e._v("#")]),e._v(" Memory Efficiency")]),e._v(" "),a("ul",[a("li",[e._v("GRPO is memory-efficient compared to PPO")]),e._v(" "),a("li",[e._v("Supports gradient checkpointing")]),e._v(" "),a("li",[e._v("Optional reference model ("),a("code",[e._v("beta=0.0")]),e._v(" means no ref model)")])]),e._v(" "),a("hr"),e._v(" "),a("h2",{attrs:{id:"_9-key-takeaways"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_9-key-takeaways"}},[e._v("#")]),e._v(" 9. Key Takeaways")]),e._v(" "),a("h3",{attrs:{id:"core-concepts"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#core-concepts"}},[e._v("#")]),e._v(" Core Concepts")]),e._v(" "),a("ol",[a("li",[e._v("‚úÖ "),a("strong",[e._v("GRPO uses group-relative advantages")]),e._v(" (normalized within each prompt group)")]),e._v(" "),a("li",[e._v("‚úÖ "),a("strong",[e._v("Multiple completions per prompt")]),e._v(" enable comparative learning")]),e._v(" "),a("li",[e._v("‚úÖ "),a("strong",[e._v("Each completion contributes differently")]),e._v(" based on its advantage")]),e._v(" "),a("li",[e._v("‚úÖ "),a("strong",[e._v("Loss computed per-token")]),e._v(", aggregated per-completion, then averaged to scalar")]),e._v(" "),a("li",[e._v("‚úÖ "),a("strong",[e._v("Hidden states remain independent")]),e._v(" per completion (NOT averaged)")]),e._v(" "),a("li",[e._v("‚úÖ "),a("strong",[e._v("Gradients flow equally")]),e._v(" ("),a("code",[e._v("1/B")]),e._v(" each) through "),a("code",[e._v(".mean()")]),e._v(" operation")])]),e._v(" "),a("h3",{attrs:{id:"practical-insights"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#practical-insights"}},[e._v("#")]),e._v(" Practical Insights")]),e._v(" "),a("ul",[a("li",[e._v("üí° Use "),a("code",[e._v('"dapo"')]),e._v(" loss type to avoid length bias")]),e._v(" "),a("li",[e._v("üí° Multiple reward functions can be combined with weights")]),e._v(" "),a("li",[e._v("üí° Length penalties are optional (not automatic)")]),e._v(" "),a("li",[e._v("üí° "),a("code",[e._v("beta=0.0")]),e._v(" enables pure RL without reference model")]),e._v(" "),a("li",[e._v("üí° Token-level advantages enable fine-grained learning signals")])]),e._v(" "),a("h3",{attrs:{id:"technical-understanding"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#technical-understanding"}},[e._v("#")]),e._v(" Technical Understanding")]),e._v(" "),a("ul",[a("li",[e._v("üîß PyTorch requires scalar loss for backpropagation")]),e._v(" "),a("li",[e._v("üîß "),a("code",[e._v(".mean()")]),e._v(" distributes gradients equally ("),a("code",[e._v("1/B")]),e._v(" to each element)")]),e._v(" "),a("li",[e._v("üîß Batch processing enables parallel computation")]),e._v(" "),a("li",[e._v("üîß Gradients accumulate at shared model parameters")])]),e._v(" "),a("hr"),e._v(" "),a("p",[a("strong",[e._v("End of Summary")]),e._v(" ‚Äî This covers the main topics discussed today about TRL, GRPO, reward functions, loss computation, and backpropagation mechanics.")]),e._v(" "),a("hr"),e._v(" "),a("h2",{attrs:{id:"q1-does-trl-support-both-step-based-token-wise-and-final-result-rewards"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#q1-does-trl-support-both-step-based-token-wise-and-final-result-rewards"}},[e._v("#")]),e._v(" Q1: Does TRL support both step-based (token-wise) and final result rewards?")]),e._v(" "),a("p",[a("strong",[e._v("Initial Answer")]),e._v(": Not directly supported - reward functions typically return a single scalar per completion.")]),e._v(" "),a("p",[a("strong",[e._v("Clarification")]),e._v(":")]),e._v(" "),a("ul",[a("li",[e._v("‚úÖ "),a("strong",[e._v("Token-wise rewards ARE supported")]),e._v(" in "),a("code",[e._v("PPOTrainer")]),e._v(" and "),a("code",[e._v("GRPOTrainer")])]),e._v(" "),a("li",[e._v("‚úÖ While custom "),a("code",[e._v("reward_funcs")]),e._v(" typically return sequence-level scalars, these are used to compute "),a("strong",[e._v("advantages")]),e._v(" which can be applied token-wise")]),e._v(" "),a("li",[e._v("‚úÖ In "),a("code",[e._v("MiniLLMTrainer")]),e._v(", rewards are computed directly token-wise as "),a("code",[e._v("teacher_logprobs - student_logprobs")])]),e._v(" "),a("li",[e._v("‚úÖ "),a("code",[e._v("GRPOTrainer")]),e._v("'s "),a("code",[e._v("_compute_loss")]),e._v(" explicitly handles advantages of shape "),a("code",[e._v("(B, T)")]),e._v(" (token-wise) or "),a("code",[e._v("(B,)")]),e._v(" (sequence-wise)")])]),e._v(" "),a("p",[a("strong",[e._v("Key Insight")]),e._v(": The distinction is between "),a("strong",[e._v("reward functions")]),e._v(" (usually sequence-level) and "),a("strong",[e._v("advantages")]),e._v(" (can be token-level or sequence-level).")]),e._v(" "),a("hr"),e._v(" "),a("h2",{attrs:{id:"q2-how-are-token-wise-rewards-and-losses-computed-when-model-outputs-and-ground-truth-don-t-match"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#q2-how-are-token-wise-rewards-and-losses-computed-when-model-outputs-and-ground-truth-don-t-match"}},[e._v("#")]),e._v(" Q2: How are token-wise rewards and losses computed when model outputs and ground truth don't match?")]),e._v(" "),a("p",[a("strong",[e._v("Question")]),e._v(": How does the system handle cases where:")]),e._v(" "),a("ul",[a("li",[e._v("Answers have extra meaningless tokens but are correct?")]),e._v(" "),a("li",[e._v("Answers are totally wrong?")]),e._v(" "),a("li",[e._v("How are rewards/losses calculated token-wise?")])]),e._v(" "),a("p",[a("strong",[e._v("Answer")]),e._v(":")]),e._v(" "),a("ul",[a("li",[a("strong",[e._v("Padding and masking")]),e._v(": Variable-length sequences are handled with "),a("code",[e._v("completion_mask")]),e._v(" to mask out padding tokens")]),e._v(" "),a("li",[a("strong",[e._v("Token order matters")]),e._v(": "),a("code",[e._v("torch.gather")]),e._v(" is used to extract log probabilities for the "),a("strong",[e._v("actual generated tokens")]),e._v(" at each position")]),e._v(" "),a("li",[a("strong",[e._v("Same token, different positions")]),e._v(": The same token appearing at different positions receives different probabilities and rewards due to varying contexts")]),e._v(" "),a("li",[a("strong",[e._v("Per-token loss")]),e._v(": Each token position has its own loss based on:\n"),a("ul",[a("li",[e._v("The token's log probability")]),e._v(" "),a("li",[e._v("The completion's advantage (group-relative)")]),e._v(" "),a("li",[e._v("Importance sampling ratio (if using off-policy updates)")])])])]),e._v(" "),a("p",[a("strong",[e._v("Key Code")]),e._v(":")]),e._v(" "),a("div",{staticClass:"language-python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[e._v("# Extract log probs for generated tokens")]),e._v("\nlog_probs "),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("=")]),e._v(" torch"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(".")]),e._v("gather"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("(")]),e._v("log_probs"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),e._v(" dim"),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("=")]),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("-")]),a("span",{pre:!0,attrs:{class:"token number"}},[e._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),e._v(" index"),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("=")]),e._v("completion_ids"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(".")]),e._v("unsqueeze"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("(")]),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("-")]),a("span",{pre:!0,attrs:{class:"token number"}},[e._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(")")]),e._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[e._v("# Apply completion mask to ignore padding")]),e._v("\nper_token_loss "),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("=")]),e._v(" per_token_loss "),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("*")]),e._v(" completion_mask\n")])]),e._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[e._v("1")]),a("br"),a("span",{staticClass:"line-number"},[e._v("2")]),a("br"),a("span",{staticClass:"line-number"},[e._v("3")]),a("br"),a("span",{staticClass:"line-number"},[e._v("4")]),a("br")])]),a("hr"),e._v(" "),a("h2",{attrs:{id:"q3-is-there-a-teacher-model-in-minillm"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#q3-is-there-a-teacher-model-in-minillm"}},[e._v("#")]),e._v(" Q3: Is there a teacher model in MiniLLM?")]),e._v(" "),a("p",[a("strong",[e._v("Answer")]),e._v(":")]),e._v(" "),a("ul",[a("li",[e._v("‚úÖ "),a("strong",[e._v("Yes")]),e._v(", "),a("code",[e._v("MiniLLMTrainer")]),e._v(" explicitly uses a teacher model")]),e._v(" "),a("li",[e._v("Teacher model provides target log probabilities for knowledge distillation")]),e._v(" "),a("li",[e._v("Rewards are computed as: "),a("code",[e._v("teacher_logprobs - student_logprobs")]),e._v(" (token-wise)")]),e._v(" "),a("li",[e._v("This is different from a "),a("strong",[e._v("reference model")]),e._v(" used in PPO/GRPO for KL regularization")])]),e._v(" "),a("p",[a("strong",[e._v("Distinction")]),e._v(":")]),e._v(" "),a("ul",[a("li",[a("strong",[e._v("Teacher model")]),e._v(" (MiniLLM): Used for knowledge distillation, provides target probabilities")]),e._v(" "),a("li",[a("strong",[e._v("Reference model")]),e._v(" (PPO/GRPO): Used for KL regularization, prevents policy from deviating too much")])]),e._v(" "),a("hr"),e._v(" "),a("h2",{attrs:{id:"q4-are-there-training-methods-that-operate-purely-on-rl-without-a-teacher-model"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#q4-are-there-training-methods-that-operate-purely-on-rl-without-a-teacher-model"}},[e._v("#")]),e._v(" Q4: Are there training methods that operate purely on RL without a teacher model?")]),e._v(" "),a("p",[a("strong",[e._v("Answer")]),e._v(":")]),e._v(" "),a("ul",[a("li",[e._v("‚úÖ "),a("strong",[e._v("Yes")]),e._v(", several trainers operate purely on RL:\n"),a("ul",[a("li",[a("code",[e._v("GRPOTrainer")]),e._v(" (when "),a("code",[e._v("beta=0.0")]),e._v("): No reference model, pure RL")]),e._v(" "),a("li",[a("code",[e._v("RLOOTrainer")]),e._v(": REINFORCE Leave-One-Out")]),e._v(" "),a("li",[a("code",[e._v("PPOTrainer")]),e._v(": Proximal Policy Optimization")])])]),e._v(" "),a("li",[e._v("These use reward functions (not teacher models) to guide learning")])]),e._v(" "),a("hr"),e._v(" "),a("h2",{attrs:{id:"q5-why-does-rewards-per-func-have-two-columns"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#q5-why-does-rewards-per-func-have-two-columns"}},[e._v("#")]),e._v(" Q5: Why does "),a("code",[e._v("rewards_per_func")]),e._v(" have two columns?")]),e._v(" "),a("p",[a("strong",[e._v("Question")]),e._v(": In "),a("code",[e._v("_calculate_rewards")]),e._v(", why does "),a("code",[e._v("rewards_per_func")]),e._v(" have shape "),a("code",[e._v("(num_completions, num_reward_functions)")]),e._v("?")]),e._v(" "),a("p",[a("strong",[e._v("Answer")]),e._v(":")]),e._v(" "),a("ul",[a("li",[a("strong",[e._v("Number of columns = number of reward functions")])]),e._v(" "),a("li",[e._v("Each column represents rewards from one reward function")]),e._v(" "),a("li",[e._v("Allows combining multiple reward functions with different weights")]),e._v(" "),a("li",[e._v("Example: Column 0 = "),a("code",[e._v("accuracy_reward")]),e._v(", Column 1 = "),a("code",[e._v("format_reward")])]),e._v(" "),a("li",[e._v("Combined via: "),a("code",[e._v("rewards = (rewards_per_func * reward_weights).nansum(dim=1)")])])]),e._v(" "),a("p",[a("strong",[e._v("Visual Example")]),e._v(":")]),e._v(" "),a("div",{staticClass:"language- line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v("rewards_per_func = [\n    [1.0, 0.8],   # Completion 0: [accuracy_reward, format_reward]\n    [1.0, 0.7],   # Completion 1: [accuracy_reward, format_reward]\n    [0.0, -0.2],  # Completion 2: [accuracy_reward, format_reward]\n]\n")])]),e._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[e._v("1")]),a("br"),a("span",{staticClass:"line-number"},[e._v("2")]),a("br"),a("span",{staticClass:"line-number"},[e._v("3")]),a("br"),a("span",{staticClass:"line-number"},[e._v("4")]),a("br"),a("span",{staticClass:"line-number"},[e._v("5")]),a("br")])]),a("hr"),e._v(" "),a("h2",{attrs:{id:"q6-what-do-accuracy-reward-and-format-reward-mean"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#q6-what-do-accuracy-reward-and-format-reward-mean"}},[e._v("#")]),e._v(" Q6: What do "),a("code",[e._v("accuracy_reward")]),e._v(" and "),a("code",[e._v("format_reward")]),e._v(" mean?")]),e._v(" "),a("p",[a("strong",[e._v("Answer")]),e._v(":")]),e._v(" "),a("h3",{attrs:{id:"accuracy-reward-2"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#accuracy-reward-2"}},[e._v("#")]),e._v(" "),a("code",[e._v("accuracy_reward")])]),e._v(" "),a("ul",[a("li",[e._v("Checks if completion matches ground truth solution")]),e._v(" "),a("li",[e._v("Uses math verification for LaTeX expressions")]),e._v(" "),a("li",[e._v("Returns: "),a("code",[e._v("1.0")]),e._v(" (correct), "),a("code",[e._v("0.0")]),e._v(" (incorrect), "),a("code",[e._v("None")]),e._v(" (unparseable - skipped)")])]),e._v(" "),a("h3",{attrs:{id:"think-format-reward-format-reward"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#think-format-reward-format-reward"}},[e._v("#")]),e._v(" "),a("code",[e._v("think_format_reward")]),e._v(" (format reward)")]),e._v(" "),a("ul",[a("li",[e._v("Checks if reasoning is enclosed in "),a("code",[e._v("<think>...</think>")]),e._v(" tags")]),e._v(" "),a("li",[e._v("Returns: "),a("code",[e._v("1.0")]),e._v(" (correct format), "),a("code",[e._v("0.0")]),e._v(" (wrong format)")]),e._v(" "),a("li",[e._v("Ensures structured output format")])]),e._v(" "),a("p",[a("strong",[e._v("Usage")]),e._v(": Often combined with weights, e.g., 70% accuracy + 30% format")]),e._v(" "),a("hr"),e._v(" "),a("h2",{attrs:{id:"q7-does-grpo-put-a-penalty-on-the-length-of-answers"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#q7-does-grpo-put-a-penalty-on-the-length-of-answers"}},[e._v("#")]),e._v(" Q7: Does GRPO put a penalty on the length of answers?")]),e._v(" "),a("p",[a("strong",[e._v("Question")]),e._v(": Is there automatic length penalty?")]),e._v(" "),a("p",[a("strong",[e._v("Answer")]),e._v(":")]),e._v(" "),a("ul",[a("li",[e._v("‚ùå "),a("strong",[e._v("No automatic length penalty")])]),e._v(" "),a("li",[e._v("‚úÖ "),a("strong",[e._v("Optional length penalty")]),e._v(" available via "),a("code",[e._v("get_soft_overlong_punishment")])]),e._v(" "),a("li",[e._v("Must be explicitly added to "),a("code",[e._v("reward_funcs")]),e._v(" list")]),e._v(" "),a("li",[e._v("Formula:\n"),a("ul",[a("li",[a("code",[e._v("0.0")]),e._v(" if length ‚â§ L_max - L_cache")]),e._v(" "),a("li",[e._v("Linear penalty if between")]),e._v(" "),a("li",[a("code",[e._v("-1.0")]),e._v(" if > L_max")])])]),e._v(" "),a("li",[e._v("Default in scripts: "),a("code",[e._v("max_completion_len=1280")]),e._v(", "),a("code",[e._v("soft_punish_cache=256")])])]),e._v(" "),a("p",[a("strong",[e._v("Key Point")]),e._v(": Length penalties are "),a("strong",[e._v("optional")]),e._v(" and must be explicitly configured.")]),e._v(" "),a("hr"),e._v(" "),a("h2",{attrs:{id:"q8-does-grpo-implementation-match-the-theoretical-mechanism"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#q8-does-grpo-implementation-match-the-theoretical-mechanism"}},[e._v("#")]),e._v(" Q8: Does GRPO implementation match the theoretical mechanism?")]),e._v(" "),a("p",[a("strong",[e._v("Question")]),e._v(": Does the code implementation match the GRPO paper's algorithm?")]),e._v(" "),a("p",[a("strong",[e._v("Answer")]),e._v(":")]),e._v(" "),a("ul",[a("li",[e._v("‚úÖ "),a("strong",[e._v("Yes, verified match")]),e._v(":\n"),a("ul",[a("li",[e._v("Group-relative advantage computation ‚úì")]),e._v(" "),a("li",[e._v("Clipped surrogate objective ‚úì")]),e._v(" "),a("li",[e._v("KL divergence regularization ‚úì")]),e._v(" "),a("li",[e._v("Token-level loss aggregation ‚úì")])])])]),e._v(" "),a("p",[a("strong",[e._v("Verification Points")]),e._v(":")]),e._v(" "),a("ol",[a("li",[e._v("Advantages computed as: "),a("code",[e._v("(rewards - mean_grouped_rewards) / std_grouped_rewards")])]),e._v(" "),a("li",[e._v("Loss uses clipped importance sampling: "),a("code",[e._v("min(œÅA, clip(œÅ, 1-Œµ, 1+Œµ)A)")])]),e._v(" "),a("li",[e._v("KL regularization applied when "),a("code",[e._v("beta != 0.0")])]),e._v(" "),a("li",[e._v("Multiple loss normalization strategies supported")])]),e._v(" "),a("hr"),e._v(" "),a("h2",{attrs:{id:"q9-is-loss-calculated-for-each-completion"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#q9-is-loss-calculated-for-each-completion"}},[e._v("#")]),e._v(" Q9: Is loss calculated for each completion?")]),e._v(" "),a("p",[a("strong",[e._v("Question")]),e._v(": Does GRPO calculate loss for each completion separately?")]),e._v(" "),a("p",[a("strong",[e._v("Answer")]),e._v(":")]),e._v(" "),a("ul",[a("li",[e._v("‚úÖ "),a("strong",[e._v("Yes")]),e._v(", loss is computed per-token for each completion")]),e._v(" "),a("li",[a("strong",[e._v("Per-token losses")]),e._v(": Shape "),a("code",[e._v("(B, T)")]),e._v(" - one loss per token per completion")]),e._v(" "),a("li",[a("strong",[e._v("Per-completion losses")]),e._v(": Aggregated per completion ‚Üí shape "),a("code",[e._v("(B,)")])]),e._v(" "),a("li",[a("strong",[e._v("Final scalar loss")]),e._v(": Averaged across completions ‚Üí shape "),a("code",[e._v("()")]),e._v(" (scalar)")])]),e._v(" "),a("p",[a("strong",[e._v("Loss Flow")]),e._v(":")]),e._v(" "),a("div",{staticClass:"language- line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v("Per-token losses (B, T) \n    ‚Üí Per-completion losses (B,) \n    ‚Üí Final scalar loss ()\n")])]),e._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[e._v("1")]),a("br"),a("span",{staticClass:"line-number"},[e._v("2")]),a("br"),a("span",{staticClass:"line-number"},[e._v("3")]),a("br")])]),a("p",[a("strong",[e._v("Key Point")]),e._v(": Each completion contributes differently based on its advantage (good/bad/average).")]),e._v(" "),a("hr"),e._v(" "),a("h2",{attrs:{id:"q10-what-are-the-hidden-states-during-forward-backward-pass-are-they-averaged"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#q10-what-are-the-hidden-states-during-forward-backward-pass-are-they-averaged"}},[e._v("#")]),e._v(" Q10: What are the hidden states during forward/backward pass? Are they averaged?")]),e._v(" "),a("p",[a("strong",[e._v("Question")]),e._v(": During backpropagation, what are the hidden states at each layer? Are they averaged across completions?")]),e._v(" "),a("p",[a("strong",[e._v("Answer")]),e._v(":")]),e._v(" "),a("ul",[a("li",[e._v("‚ùå "),a("strong",[e._v("Hidden states are NOT averaged")]),e._v(" across completions")]),e._v(" "),a("li",[e._v("‚úÖ "),a("strong",[e._v("Each completion has independent hidden states")])]),e._v(" "),a("li",[a("strong",[e._v("Shape at each layer")]),e._v(": "),a("code",[e._v("(B, L, H)")]),e._v(" where:\n"),a("ul",[a("li",[a("code",[e._v("B")]),e._v(" = total completions (batch_size √ó num_generations)")]),e._v(" "),a("li",[a("code",[e._v("L")]),e._v(" = sequence length")]),e._v(" "),a("li",[a("code",[e._v("H")]),e._v(" = hidden dimension")])])]),e._v(" "),a("li",[a("strong",[e._v("Processed in parallel")]),e._v(" as a batch")]),e._v(" "),a("li",[a("strong",[e._v("Gradients accumulate")]),e._v(" at shared model parameters from all completions")])]),e._v(" "),a("p",[a("strong",[e._v("Key Insight")]),e._v(": Hidden states remain independent per completion; only gradients accumulate at parameters.")]),e._v(" "),a("hr"),e._v(" "),a("h2",{attrs:{id:"q11-do-different-completions-share-the-same-scalar-loss"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#q11-do-different-completions-share-the-same-scalar-loss"}},[e._v("#")]),e._v(" Q11: Do different completions share the same scalar loss?")]),e._v(" "),a("p",[a("strong",[e._v("Question")]),e._v(": Since there's a final scalar loss, do all completions share the same loss value?")]),e._v(" "),a("p",[a("strong",[e._v("Answer")]),e._v(":")]),e._v(" "),a("ul",[a("li",[e._v("‚ùå "),a("strong",[e._v("No")]),e._v(", each completion has its own loss contribution")]),e._v(" "),a("li",[e._v("‚úÖ "),a("strong",[e._v("Final scalar loss")]),e._v(" is the "),a("strong",[e._v("average")]),e._v(" of all per-completion losses")]),e._v(" "),a("li",[e._v("Each completion contributes differently:\n"),a("ul",[a("li",[a("strong",[e._v("Good completions")]),e._v(" (positive advantage) ‚Üí negative loss contribution (encouraged)")]),e._v(" "),a("li",[a("strong",[e._v("Bad completions")]),e._v(" (negative advantage) ‚Üí positive loss contribution (discouraged)")]),e._v(" "),a("li",[a("strong",[e._v("Average completions")]),e._v(" (zero advantage) ‚Üí neutral contribution")])])])]),e._v(" "),a("p",[a("strong",[e._v("Example")]),e._v(":")]),e._v(" "),a("div",{staticClass:"language- line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v("Completion 0 (Correct):  reward=1.0, advantage=+0.5  ‚Üí  per_completion_loss = -0.3\nCompletion 1 (Wrong):   reward=0.0, advantage=-0.5  ‚Üí  per_completion_loss = +0.2\nCompletion 2 (Partial): reward=0.5, advantage=0.0   ‚Üí  per_completion_loss = 0.0\n\nFinal scalar loss = mean([-0.3, +0.2, 0.0]) = -0.033\n")])]),e._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[e._v("1")]),a("br"),a("span",{staticClass:"line-number"},[e._v("2")]),a("br"),a("span",{staticClass:"line-number"},[e._v("3")]),a("br"),a("span",{staticClass:"line-number"},[e._v("4")]),a("br"),a("span",{staticClass:"line-number"},[e._v("5")]),a("br")])]),a("p",[a("strong",[e._v("Key Point")]),e._v(": The final scalar loss is an aggregation mechanism; each completion contributes differently based on quality.")]),e._v(" "),a("hr"),e._v(" "),a("h2",{attrs:{id:"q12-why-do-we-need-final-scalar-loss-for-backpropagation"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#q12-why-do-we-need-final-scalar-loss-for-backpropagation"}},[e._v("#")]),e._v(" Q12: Why do we need final scalar loss for backpropagation?")]),e._v(" "),a("p",[a("strong",[e._v("Question")]),e._v(": If we compute per-completion losses, why do we need to aggregate them into a final scalar loss?")]),e._v(" "),a("p",[a("strong",[e._v("Answer")]),e._v(":")]),e._v(" "),a("ul",[a("li",[e._v("‚ùå "),a("strong",[e._v("PyTorch cannot call "),a("code",[e._v(".backward()")])]),e._v(" on tensor with shape "),a("code",[e._v("(B,)")])]),e._v(" "),a("li",[e._v("‚úÖ "),a("strong",[e._v("PyTorch requires scalar")]),e._v(" for "),a("code",[e._v(".backward()")])]),e._v(" "),a("li",[e._v("‚úÖ "),a("strong",[e._v("Final scalar loss")]),e._v(" enables backpropagation")]),e._v(" "),a("li",[e._v("The "),a("code",[e._v(".mean()")]),e._v(" operation distributes gradients equally ("),a("code",[e._v("1/B")]),e._v(" to each completion)")])]),e._v(" "),a("p",[a("strong",[e._v("Mathematical Flow")]),e._v(":")]),e._v(" "),a("div",{staticClass:"language- line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v("final_loss = mean([loss_0, loss_1, ..., loss_B-1])\nfinal_loss.backward()\n\n# Each completion receives: grad_loss_i = 1.0 / B\n# Gradients flow independently through each completion's graph\n# Model parameters accumulate gradients from all completions\n")])]),e._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[e._v("1")]),a("br"),a("span",{staticClass:"line-number"},[e._v("2")]),a("br"),a("span",{staticClass:"line-number"},[e._v("3")]),a("br"),a("span",{staticClass:"line-number"},[e._v("4")]),a("br"),a("span",{staticClass:"line-number"},[e._v("5")]),a("br"),a("span",{staticClass:"line-number"},[e._v("6")]),a("br")])]),a("p",[a("strong",[e._v("Key Insight")]),e._v(": The final scalar loss is a "),a("strong",[e._v("technical requirement")]),e._v(" for PyTorch's autograd, not a conceptual necessity.")]),e._v(" "),a("hr"),e._v(" "),a("h2",{attrs:{id:"q13-do-completions-receive-mean-gradient-during-backpropagation"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#q13-do-completions-receive-mean-gradient-during-backpropagation"}},[e._v("#")]),e._v(" Q13: Do completions receive mean gradient during backpropagation?")]),e._v(" "),a("p",[a("strong",[e._v("Question")]),e._v(": When gradients flow back through "),a("code",[e._v(".mean()")]),e._v(", does each completion receive the mean gradient?")]),e._v(" "),a("p",[a("strong",[e._v("Answer")]),e._v(":")]),e._v(" "),a("ul",[a("li",[e._v("‚úÖ "),a("strong",[e._v("Yes")]),e._v(", each completion receives "),a("code",[e._v("1/B")]),e._v(" of the gradient (where B = number of completions)")]),e._v(" "),a("li",[e._v("This comes from the "),a("code",[e._v(".mean()")]),e._v(" operation's gradient: "),a("code",[e._v("‚àÇmean/‚àÇx[i] = 1/B")])]),e._v(" "),a("li",[e._v("Gradients flow "),a("strong",[e._v("independently")]),e._v(" through each completion's computational graph")]),e._v(" "),a("li",[e._v("Model parameters "),a("strong",[e._v("accumulate")]),e._v(" gradients from all completions")])]),e._v(" "),a("p",[a("strong",[e._v("Mathematical Flow")]),e._v(":")]),e._v(" "),a("div",{staticClass:"language- line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v("Final Loss: loss = mean([loss_0, loss_1, loss_2])\n    ‚Üì backward() with grad=1.0\n    ‚Üì\nMean Operation: grad_loss_i = 1.0 / B = 1/3\n    ‚Üì\nEach completion receives equal gradient share (1/B)\n    ‚Üì\nGradients flow independently through each completion\n    ‚Üì\nModel parameters accumulate gradients from all completions\n")])]),e._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[e._v("1")]),a("br"),a("span",{staticClass:"line-number"},[e._v("2")]),a("br"),a("span",{staticClass:"line-number"},[e._v("3")]),a("br"),a("span",{staticClass:"line-number"},[e._v("4")]),a("br"),a("span",{staticClass:"line-number"},[e._v("5")]),a("br"),a("span",{staticClass:"line-number"},[e._v("6")]),a("br"),a("span",{staticClass:"line-number"},[e._v("7")]),a("br"),a("span",{staticClass:"line-number"},[e._v("8")]),a("br"),a("span",{staticClass:"line-number"},[e._v("9")]),a("br"),a("span",{staticClass:"line-number"},[e._v("10")]),a("br")])]),a("p",[a("strong",[e._v("Key Point")]),e._v(": Equal gradient distribution ("),a("code",[e._v("1/B")]),e._v(" each) ensures all completions contribute equally to parameter updates.")]),e._v(" "),a("hr"),e._v(" "),a("h2",{attrs:{id:"summary-of-key-clarifications"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#summary-of-key-clarifications"}},[e._v("#")]),e._v(" Summary of Key Clarifications")]),e._v(" "),a("ol",[a("li",[a("strong",[e._v("Token-wise rewards")]),e._v(": Supported via advantages, not directly in reward functions")]),e._v(" "),a("li",[a("strong",[e._v("Loss computation")]),e._v(": Per-token ‚Üí per-completion ‚Üí scalar (each step serves a purpose)")]),e._v(" "),a("li",[a("strong",[e._v("Hidden states")]),e._v(": Independent per completion, NOT averaged")]),e._v(" "),a("li",[a("strong",[e._v("Gradients")]),e._v(": Distributed equally ("),a("code",[e._v("1/B")]),e._v(") through "),a("code",[e._v(".mean()")]),e._v(" operation")]),e._v(" "),a("li",[a("strong",[e._v("Final scalar loss")]),e._v(": Technical requirement for PyTorch, not conceptual necessity")]),e._v(" "),a("li",[a("strong",[e._v("Multiple reward functions")]),e._v(": Each gets its own column in "),a("code",[e._v("rewards_per_func")])]),e._v(" "),a("li",[a("strong",[e._v("Length penalties")]),e._v(": Optional, must be explicitly added")]),e._v(" "),a("li",[a("strong",[e._v("Teacher vs Reference")]),e._v(": Different concepts (knowledge distillation vs KL regularization)")])]),e._v(" "),a("h1",{attrs:{id:"grpo-mathematical-demo-rewards-‚Üí-advantages-‚Üí-loss"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#grpo-mathematical-demo-rewards-‚Üí-advantages-‚Üí-loss"}},[e._v("#")]),e._v(" GRPO Mathematical Demo: Rewards ‚Üí Advantages ‚Üí Loss")]),e._v(" "),a("p",[e._v("This document provides a concrete mathematical demonstration of how rewards (sequence-level/sparse) flow through advantages (sequence-level, broadcast) to token-level losses in GRPO.")]),e._v(" "),a("h2",{attrs:{id:"executive-summary"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#executive-summary"}},[e._v("#")]),e._v(" Executive Summary")]),e._v(" "),a("p",[a("strong",[e._v("GRPO uses two relative measures:")])]),e._v(" "),a("ol",[a("li",[a("p",[a("strong",[e._v("Advantages are group-relative")]),e._v(": "),a("code",[e._v("A_i = r_i - mean(r_group)")])]),e._v(" "),a("ul",[a("li",[e._v("Advantages are computed relative to the average reward of completions for the same prompt")]),e._v(" "),a("li",[e._v("This enables comparative learning within each prompt group")])])]),e._v(" "),a("li",[a("p",[a("strong",[e._v("Importance sampling ratio is policy-relative")]),e._v(": "),a("code",[e._v("œÅ = œÄ_Œ∏_current / œÄ_Œ∏_gen")])]),e._v(" "),a("ul",[a("li",[e._v("Measures how much the policy changed since generation")]),e._v(" "),a("li",[a("code",[e._v("old_per_token_logps")]),e._v(": Computed right after generation with "),a("code",[e._v("Œ∏_gen")])]),e._v(" "),a("li",[a("code",[e._v("per_token_logps")]),e._v(": Computed during training with "),a("code",[e._v("Œ∏_current")]),e._v(" (may have been updated)")]),e._v(" "),a("li",[e._v("Corrects for off-policy learning when reusing old completions")])])])]),e._v(" "),a("p",[a("strong",[e._v("Loss computation:")])]),e._v(" "),a("ul",[a("li",[e._v("Loss = Advantage √ó Importance Sampling Ratio (with clipping)")]),e._v(" "),a("li",[a("strong",[e._v("No ground truth comparison")]),e._v(" - purely reward-based learning")]),e._v(" "),a("li",[e._v("Rewards are sparse (one per completion), broadcast to all tokens")]),e._v(" "),a("li",[e._v("Each token's loss depends on completion quality (via advantage) and policy change (via importance ratio)")])]),e._v(" "),a("hr"),e._v(" "),a("h2",{attrs:{id:"setup"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#setup"}},[e._v("#")]),e._v(" Setup")]),e._v(" "),a("p",[a("strong",[e._v("Assumptions:")])]),e._v(" "),a("ul",[a("li",[e._v("1 prompt")]),e._v(" "),a("li",[e._v("3 completions per prompt ("),a("code",[e._v("num_generations = 3")]),e._v(")")]),e._v(" "),a("li",[e._v("Completion lengths: 5, 4, 6 tokens respectively")]),e._v(" "),a("li",[e._v("Batch size "),a("code",[e._v("B = 3")]),e._v(" (total completions)")])]),e._v(" "),a("hr"),e._v(" "),a("h2",{attrs:{id:"step-1-rewards-sequence-level-sparse"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#step-1-rewards-sequence-level-sparse"}},[e._v("#")]),e._v(" Step 1: Rewards (Sequence-Level, Sparse)")]),e._v(" "),a("h3",{attrs:{id:"reward-computation"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#reward-computation"}},[e._v("#")]),e._v(" Reward Computation")]),e._v(" "),a("p",[e._v("Rewards are computed "),a("strong",[e._v("once per completion")]),e._v(" (at the end, after seeing the full completion):")]),e._v(" "),a("div",{staticClass:"language-python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[e._v("# Reward function evaluates each completion")]),e._v("\nrewards "),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("=")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[e._v("1.0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[e._v("0.0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[e._v("0.5")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("]")]),e._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[e._v("# Shape: (3,)")]),e._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[e._v("#           ‚Üë    ‚Üë    ‚Üë")]),e._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[e._v("#        comp0 comp1 comp2")]),e._v("\n")])]),e._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[e._v("1")]),a("br"),a("span",{staticClass:"line-number"},[e._v("2")]),a("br"),a("span",{staticClass:"line-number"},[e._v("3")]),a("br"),a("span",{staticClass:"line-number"},[e._v("4")]),a("br")])]),a("p",[a("strong",[e._v("Mathematical representation:")])]),e._v(" "),a("p",[e._v("$$\n\\mathbf{r} = \\begin{bmatrix} r_0 \\ r_1 \\ r_2 \\end{bmatrix} = \\begin{bmatrix} 1.0 \\ 0.0 \\ 0.5 \\end{bmatrix}\n$$")]),e._v(" "),a("p",[a("strong",[e._v("Shape:")]),e._v(" "),a("code",[e._v("(B,) = (3,)")]),e._v(" - one scalar per completion")]),e._v(" "),a("p",[a("strong",[e._v("Key point:")]),e._v(" Rewards are "),a("strong",[e._v("sparse")]),e._v(" - computed only once per completion, not per token.")]),e._v(" "),a("hr"),e._v(" "),a("h2",{attrs:{id:"step-2-group-relative-advantages-sequence-level"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#step-2-group-relative-advantages-sequence-level"}},[e._v("#")]),e._v(" Step 2: Group-Relative Advantages (Sequence-Level)")]),e._v(" "),a("h3",{attrs:{id:"advantage-computation"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#advantage-computation"}},[e._v("#")]),e._v(" Advantage Computation")]),e._v(" "),a("p",[e._v("Advantages are computed from rewards, normalized within the group:")]),e._v(" "),a("div",{staticClass:"language-python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[e._v("# Group mean")]),e._v("\nmean_grouped_rewards "),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("=")]),e._v(" rewards"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(".")]),e._v("mean"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(")")]),e._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[e._v("# = (1.0 + 0.0 + 0.5) / 3 = 0.5")]),e._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[e._v("# Group std (for scaling)")]),e._v("\nstd_grouped_rewards "),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("=")]),e._v(" rewards"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(".")]),e._v("std"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(")")]),e._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[e._v("# ‚âà 0.408")]),e._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[e._v("# Advantages (sequence-level)")]),e._v("\nadvantages "),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("=")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("(")]),e._v("rewards "),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("-")]),e._v(" mean_grouped_rewards"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(")")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("/")]),e._v(" std_grouped_rewards\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[e._v("# advantages = [(1.0 - 0.5) / 0.408, (0.0 - 0.5) / 0.408, (0.5 - 0.5) / 0.408]")]),e._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[e._v("# advantages ‚âà [1.225, -1.225, 0.0]")]),e._v("\n")])]),e._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[e._v("1")]),a("br"),a("span",{staticClass:"line-number"},[e._v("2")]),a("br"),a("span",{staticClass:"line-number"},[e._v("3")]),a("br"),a("span",{staticClass:"line-number"},[e._v("4")]),a("br"),a("span",{staticClass:"line-number"},[e._v("5")]),a("br"),a("span",{staticClass:"line-number"},[e._v("6")]),a("br"),a("span",{staticClass:"line-number"},[e._v("7")]),a("br"),a("span",{staticClass:"line-number"},[e._v("8")]),a("br"),a("span",{staticClass:"line-number"},[e._v("9")]),a("br"),a("span",{staticClass:"line-number"},[e._v("10")]),a("br")])]),a("p",[a("strong",[e._v("Mathematical representation:")])]),e._v(" "),a("p",[e._v("$$\n\\bar{r} = \\frac{1}{B} \\sum_{i=0}^{B-1} r_i = \\frac{1.0 + 0.0 + 0.5}{3} = 0.5\n$$")]),e._v(" "),a("p",[e._v("$$\n\\sigma_r = \\sqrt{\\frac{1}{B-1} \\sum_{i=0}^{B-1} (r_i - \\bar{r})^2} \\approx 0.408\n$$")]),e._v(" "),a("p",[e._v("$$\n\\mathbf{A} = \\begin{bmatrix} A_0 \\ A_1 \\ A_2 \\end{bmatrix} = \\begin{bmatrix} \\frac{r_0 - \\bar{r}}{\\sigma_r} \\ \\frac{r_1 - \\bar{r}}{\\sigma_r} \\ \\frac{r_2 - \\bar{r}}{\\sigma_r} \\end{bmatrix} \\approx \\begin{bmatrix} 1.225 \\ -1.225 \\ 0.0 \\end{bmatrix}\n$$")]),e._v(" "),a("p",[a("strong",[e._v("Shape:")]),e._v(" "),a("code",[e._v("(B,) = (3,)")]),e._v(" - one scalar per completion")]),e._v(" "),a("p",[a("strong",[e._v("Key point:")]),e._v(" Advantages are "),a("strong",[e._v("sequence-level")]),e._v(" - one value per completion.")]),e._v(" "),a("hr"),e._v(" "),a("h2",{attrs:{id:"step-3-prepare-advantages-for-token-level-broadcasting"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#step-3-prepare-advantages-for-token-level-broadcasting"}},[e._v("#")]),e._v(" Step 3: Prepare Advantages for Token-Level Broadcasting")]),e._v(" "),a("h3",{attrs:{id:"unsqueeze-operation"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#unsqueeze-operation"}},[e._v("#")]),e._v(" Unsqueeze Operation")]),e._v(" "),a("p",[e._v("Advantages are unsqueezed to enable broadcasting to tokens:")]),e._v(" "),a("div",{staticClass:"language-python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[e._v("# Original advantages")]),e._v("\nadvantages "),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("=")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[e._v("1.225")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("-")]),a("span",{pre:!0,attrs:{class:"token number"}},[e._v("1.225")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[e._v("0.0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("]")]),e._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[e._v("# Shape: (3,)")]),e._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[e._v("# After unsqueeze")]),e._v("\nadvantages "),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("=")]),e._v(" advantages"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(".")]),e._v("unsqueeze"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[e._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(")")]),e._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[e._v("# Shape: (3, 1)")]),e._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[e._v("# advantages = [[1.225], [-1.225], [0.0]]")]),e._v("\n")])]),e._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[e._v("1")]),a("br"),a("span",{staticClass:"line-number"},[e._v("2")]),a("br"),a("span",{staticClass:"line-number"},[e._v("3")]),a("br"),a("span",{staticClass:"line-number"},[e._v("4")]),a("br"),a("span",{staticClass:"line-number"},[e._v("5")]),a("br"),a("span",{staticClass:"line-number"},[e._v("6")]),a("br")])]),a("p",[a("strong",[e._v("Mathematical representation:")])]),e._v(" "),a("p",[e._v("$$\n\\mathbf{A} = \\begin{bmatrix} A_0 \\ A_1 \\ A_2 \\end{bmatrix} \\rightarrow \\mathbf{A}_{broadcast} = \\begin{bmatrix} A_0 \\ A_1 \\ A_2 \\end{bmatrix} = \\begin{bmatrix} 1.225 \\ -1.225 \\ 0.0 \\end{bmatrix}\n$$")]),e._v(" "),a("p",[a("strong",[e._v("Shape:")]),e._v(" "),a("code",[e._v("(B, 1) = (3, 1)")]),e._v(" - ready for broadcasting")]),e._v(" "),a("hr"),e._v(" "),a("h2",{attrs:{id:"step-4-per-token-log-probabilities"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#step-4-per-token-log-probabilities"}},[e._v("#")]),e._v(" Step 4: Per-Token Log Probabilities")]),e._v(" "),a("h3",{attrs:{id:"token-level-log-probs"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#token-level-log-probs"}},[e._v("#")]),e._v(" Token-Level Log Probs")]),e._v(" "),a("p",[e._v("For each completion, we compute log probabilities for each token:")]),e._v(" "),a("div",{staticClass:"language-python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[e._v("# Completion 0: 5 tokens")]),e._v("\nper_token_logps_0 "),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("=")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("[")]),e._v("log_p"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("(")]),e._v("token_0"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),e._v(" log_p"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("(")]),e._v("token_1"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),e._v(" log_p"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("(")]),e._v("token_2"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),e._v(" log_p"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("(")]),e._v("token_3"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),e._v(" log_p"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("(")]),e._v("token_4"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("]")]),e._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[e._v("# Example values:")]),e._v("\nper_token_logps_0 "),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("=")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("[")]),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("-")]),a("span",{pre:!0,attrs:{class:"token number"}},[e._v("2.1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("-")]),a("span",{pre:!0,attrs:{class:"token number"}},[e._v("1.8")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("-")]),a("span",{pre:!0,attrs:{class:"token number"}},[e._v("2.3")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("-")]),a("span",{pre:!0,attrs:{class:"token number"}},[e._v("1.9")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("-")]),a("span",{pre:!0,attrs:{class:"token number"}},[e._v("2.0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("]")]),e._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[e._v("# Shape: (5,)")]),e._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[e._v("# Completion 1: 4 tokens")]),e._v("\nper_token_logps_1 "),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("=")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("[")]),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("-")]),a("span",{pre:!0,attrs:{class:"token number"}},[e._v("2.2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("-")]),a("span",{pre:!0,attrs:{class:"token number"}},[e._v("1.7")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("-")]),a("span",{pre:!0,attrs:{class:"token number"}},[e._v("2.4")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("-")]),a("span",{pre:!0,attrs:{class:"token number"}},[e._v("2.1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("]")]),e._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[e._v("# Shape: (4,)")]),e._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[e._v("# Completion 2: 6 tokens")]),e._v("\nper_token_logps_2 "),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("=")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("[")]),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("-")]),a("span",{pre:!0,attrs:{class:"token number"}},[e._v("2.0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("-")]),a("span",{pre:!0,attrs:{class:"token number"}},[e._v("1.9")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("-")]),a("span",{pre:!0,attrs:{class:"token number"}},[e._v("2.2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("-")]),a("span",{pre:!0,attrs:{class:"token number"}},[e._v("1.8")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("-")]),a("span",{pre:!0,attrs:{class:"token number"}},[e._v("2.3")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("-")]),a("span",{pre:!0,attrs:{class:"token number"}},[e._v("2.1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("]")]),e._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[e._v("# Shape: (6,)")]),e._v("\n")])]),e._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[e._v("1")]),a("br"),a("span",{staticClass:"line-number"},[e._v("2")]),a("br"),a("span",{staticClass:"line-number"},[e._v("3")]),a("br"),a("span",{staticClass:"line-number"},[e._v("4")]),a("br"),a("span",{staticClass:"line-number"},[e._v("5")]),a("br"),a("span",{staticClass:"line-number"},[e._v("6")]),a("br"),a("span",{staticClass:"line-number"},[e._v("7")]),a("br"),a("span",{staticClass:"line-number"},[e._v("8")]),a("br"),a("span",{staticClass:"line-number"},[e._v("9")]),a("br"),a("span",{staticClass:"line-number"},[e._v("10")]),a("br")])]),a("p",[a("strong",[e._v("After padding to max length (6 tokens):")])]),e._v(" "),a("div",{staticClass:"language-python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[e._v("per_token_logps "),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("=")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("[")]),e._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("[")]),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("-")]),a("span",{pre:!0,attrs:{class:"token number"}},[e._v("2.1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("-")]),a("span",{pre:!0,attrs:{class:"token number"}},[e._v("1.8")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("-")]),a("span",{pre:!0,attrs:{class:"token number"}},[e._v("2.3")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("-")]),a("span",{pre:!0,attrs:{class:"token number"}},[e._v("1.9")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("-")]),a("span",{pre:!0,attrs:{class:"token number"}},[e._v("2.0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("-")]),a("span",{pre:!0,attrs:{class:"token number"}},[e._v("100")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),e._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[e._v("# comp0, padded")]),e._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("[")]),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("-")]),a("span",{pre:!0,attrs:{class:"token number"}},[e._v("2.2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("-")]),a("span",{pre:!0,attrs:{class:"token number"}},[e._v("1.7")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("-")]),a("span",{pre:!0,attrs:{class:"token number"}},[e._v("2.4")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("-")]),a("span",{pre:!0,attrs:{class:"token number"}},[e._v("2.1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("-")]),a("span",{pre:!0,attrs:{class:"token number"}},[e._v("100")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("-")]),a("span",{pre:!0,attrs:{class:"token number"}},[e._v("100")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),e._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[e._v("# comp1, padded")]),e._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("[")]),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("-")]),a("span",{pre:!0,attrs:{class:"token number"}},[e._v("2.0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("-")]),a("span",{pre:!0,attrs:{class:"token number"}},[e._v("1.9")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("-")]),a("span",{pre:!0,attrs:{class:"token number"}},[e._v("2.2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("-")]),a("span",{pre:!0,attrs:{class:"token number"}},[e._v("1.8")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("-")]),a("span",{pre:!0,attrs:{class:"token number"}},[e._v("2.3")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("-")]),a("span",{pre:!0,attrs:{class:"token number"}},[e._v("2.1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("]")]),e._v("   "),a("span",{pre:!0,attrs:{class:"token comment"}},[e._v("# comp2")]),e._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("]")]),e._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[e._v("# Shape: (3, 6)")]),e._v("\n")])]),e._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[e._v("1")]),a("br"),a("span",{staticClass:"line-number"},[e._v("2")]),a("br"),a("span",{staticClass:"line-number"},[e._v("3")]),a("br"),a("span",{staticClass:"line-number"},[e._v("4")]),a("br"),a("span",{staticClass:"line-number"},[e._v("5")]),a("br")])]),a("p",[a("strong",[e._v("Mathematical representation:")])]),e._v(" "),a("p",[e._v("$$\n\\mathbf{L} = \\begin{bmatrix}\nL_{0,0} & L_{0,1} & L_{0,2} & L_{0,3} & L_{0,4} & -\\infty \\\nL_{1,0} & L_{1,1} & L_{1,2} & L_{1,3} & -\\infty & -\\infty \\\nL_{2,0} & L_{2,1} & L_{2,2} & L_{2,3} & L_{2,4} & L_{2,5}\n\\end{bmatrix}\n$$")]),e._v(" "),a("p",[a("strong",[e._v("Shape:")]),e._v(" "),a("code",[e._v("(B, T_max) = (3, 6)")]),e._v(" where "),a("code",[e._v("T_max = 6")]),e._v(" is the maximum sequence length")]),e._v(" "),a("hr"),e._v(" "),a("h2",{attrs:{id:"step-5-importance-sampling-ratios-token-level"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#step-5-importance-sampling-ratios-token-level"}},[e._v("#")]),e._v(" Step 5: Importance Sampling Ratios (Token-Level)")]),e._v(" "),a("h3",{attrs:{id:"policy-ratio-computation"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#policy-ratio-computation"}},[e._v("#")]),e._v(" Policy Ratio Computation")]),e._v(" "),a("p",[e._v("For each token, compute the importance sampling ratio:")]),e._v(" "),a("div",{staticClass:"language-python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[e._v("# Old log probs (from generation time)")]),e._v("\nold_per_token_logps "),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("=")]),e._v(" per_token_logps"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(".")]),e._v("detach"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(")")]),e._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[e._v("# Shape: (3, 6)")]),e._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[e._v("# Current log probs (from current forward pass)")]),e._v("\ncurrent_per_token_logps "),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("=")]),e._v(" per_token_logps  "),a("span",{pre:!0,attrs:{class:"token comment"}},[e._v("# Shape: (3, 6)")]),e._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[e._v("# Log ratio")]),e._v("\nlog_ratio "),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("=")]),e._v(" current_per_token_logps "),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("-")]),e._v(" old_per_token_logps  "),a("span",{pre:!0,attrs:{class:"token comment"}},[e._v("# Shape: (3, 6)")]),e._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[e._v("# Example (assuming small changes):")]),e._v("\nlog_ratio "),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("=")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("[")]),e._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[e._v("0.1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[e._v("0.05")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("-")]),a("span",{pre:!0,attrs:{class:"token number"}},[e._v("0.1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[e._v("0.08")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[e._v("0.02")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[e._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),e._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[e._v("# comp0")]),e._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("[")]),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("-")]),a("span",{pre:!0,attrs:{class:"token number"}},[e._v("0.05")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[e._v("0.1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("-")]),a("span",{pre:!0,attrs:{class:"token number"}},[e._v("0.08")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[e._v("0.05")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[e._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[e._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),e._v("   "),a("span",{pre:!0,attrs:{class:"token comment"}},[e._v("# comp1")]),e._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[e._v("0.08")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("-")]),a("span",{pre:!0,attrs:{class:"token number"}},[e._v("0.05")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[e._v("0.1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[e._v("0.05")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("-")]),a("span",{pre:!0,attrs:{class:"token number"}},[e._v("0.08")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[e._v("0.1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("]")]),e._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[e._v("# comp2")]),e._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("]")]),e._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[e._v("# Importance sampling ratio")]),e._v("\ncoef_1 "),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("=")]),e._v(" exp"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("(")]),e._v("log_ratio"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(")")]),e._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[e._v("# Shape: (3, 6)")]),e._v("\n")])]),e._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[e._v("1")]),a("br"),a("span",{staticClass:"line-number"},[e._v("2")]),a("br"),a("span",{staticClass:"line-number"},[e._v("3")]),a("br"),a("span",{staticClass:"line-number"},[e._v("4")]),a("br"),a("span",{staticClass:"line-number"},[e._v("5")]),a("br"),a("span",{staticClass:"line-number"},[e._v("6")]),a("br"),a("span",{staticClass:"line-number"},[e._v("7")]),a("br"),a("span",{staticClass:"line-number"},[e._v("8")]),a("br"),a("span",{staticClass:"line-number"},[e._v("9")]),a("br"),a("span",{staticClass:"line-number"},[e._v("10")]),a("br"),a("span",{staticClass:"line-number"},[e._v("11")]),a("br"),a("span",{staticClass:"line-number"},[e._v("12")]),a("br"),a("span",{staticClass:"line-number"},[e._v("13")]),a("br"),a("span",{staticClass:"line-number"},[e._v("14")]),a("br"),a("span",{staticClass:"line-number"},[e._v("15")]),a("br"),a("span",{staticClass:"line-number"},[e._v("16")]),a("br"),a("span",{staticClass:"line-number"},[e._v("17")]),a("br"),a("span",{staticClass:"line-number"},[e._v("18")]),a("br")])]),a("p",[a("strong",[e._v("Mathematical representation:")])]),e._v(" "),a("p",[e._v("$$\n\\rho_{i,t} = \\exp\\left(\\log \\pi_\\theta(o_{i,t} \\mid q, o_{i,1:t-1}) - \\log \\pi_{\\theta_{\\mathrm{old}}}(o_{i,t} \\mid q, o_{i,1:t-1})\\right)\n$$")]),e._v(" "),a("p",[e._v("where $o_{i,1:t-1}$ denotes tokens from position 1 to $t-1$ in completion $i$, and $\\pi_{\\theta_{\\mathrm{old}}}$ denotes the old policy (with parameters $\\theta_{\\mathrm{old}}$).")]),e._v(" "),a("p",[e._v("$$\n\\boldsymbol{\\rho} = \\begin{bmatrix}\n\\rho_{0,0} & \\rho_{0,1} & \\rho_{0,2} & \\rho_{0,3} & \\rho_{0,4} & 1 \\\n\\rho_{1,0} & \\rho_{1,1} & \\rho_{1,2} & \\rho_{1,3} & 1 & 1 \\\n\\rho_{2,0} & \\rho_{2,1} & \\rho_{2,2} & \\rho_{2,3} & \\rho_{2,4} & \\rho_{2,5}\n\\end{bmatrix}\n$$")]),e._v(" "),a("p",[a("strong",[e._v("Shape:")]),e._v(" "),a("code",[e._v("(B, T_max) = (3, 6)")]),e._v(" - token-level")]),e._v(" "),a("hr"),e._v(" "),a("h2",{attrs:{id:"step-6-token-level-loss-computation"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#step-6-token-level-loss-computation"}},[e._v("#")]),e._v(" Step 6: Token-Level Loss Computation")]),e._v(" "),a("h3",{attrs:{id:"broadcasting-advantages-to-tokens"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#broadcasting-advantages-to-tokens"}},[e._v("#")]),e._v(" Broadcasting Advantages to Tokens")]),e._v(" "),a("p",[e._v("Advantages are broadcast to match token dimensions:")]),e._v(" "),a("div",{staticClass:"language-python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[e._v("# Advantages (sequence-level, broadcast-ready)")]),e._v("\nadvantages "),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("=")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("[")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[e._v("1.225")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("[")]),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("-")]),a("span",{pre:!0,attrs:{class:"token number"}},[e._v("1.225")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[e._v("0.0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("]")]),e._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[e._v("# Shape: (3, 1)")]),e._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[e._v("# Broadcast to token-level")]),e._v("\nadvantages_broadcast "),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("=")]),e._v(" advantages"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(".")]),e._v("expand"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("(")]),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("-")]),a("span",{pre:!0,attrs:{class:"token number"}},[e._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[e._v("6")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(")")]),e._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[e._v("# Shape: (3, 6)")]),e._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[e._v("# advantages_broadcast = [")]),e._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[e._v("#     [1.225, 1.225, 1.225, 1.225, 1.225, 1.225],  # comp0: all tokens get same advantage")]),e._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[e._v("#     [-1.225, -1.225, -1.225, -1.225, -1.225, -1.225],  # comp1: all tokens get same advantage")]),e._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[e._v("#     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  # comp2: all tokens get same advantage")]),e._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[e._v("# ]")]),e._v("\n")])]),e._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[e._v("1")]),a("br"),a("span",{staticClass:"line-number"},[e._v("2")]),a("br"),a("span",{staticClass:"line-number"},[e._v("3")]),a("br"),a("span",{staticClass:"line-number"},[e._v("4")]),a("br"),a("span",{staticClass:"line-number"},[e._v("5")]),a("br"),a("span",{staticClass:"line-number"},[e._v("6")]),a("br"),a("span",{staticClass:"line-number"},[e._v("7")]),a("br"),a("span",{staticClass:"line-number"},[e._v("8")]),a("br"),a("span",{staticClass:"line-number"},[e._v("9")]),a("br"),a("span",{staticClass:"line-number"},[e._v("10")]),a("br")])]),a("p",[a("strong",[e._v("Mathematical representation:")])]),e._v(" "),a("p",[e._v("$$\n\\mathbf{A}_{broadcast} = \\begin{bmatrix}\nA_0 & A_0 & A_0 & A_0 & A_0 & A_0 \\\nA_1 & A_1 & A_1 & A_1 & A_1 & A_1 \\\nA_2 & A_2 & A_2 & A_2 & A_2 & A_2\n\\end{bmatrix} = \\begin{bmatrix}\n1.225 & 1.225 & 1.225 & 1.225 & 1.225 & 1.225 \\\n-1.225 & -1.225 & -1.225 & -1.225 & -1.225 & -1.225 \\\n0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0\n\\end{bmatrix}\n$$")]),e._v(" "),a("p",[a("strong",[e._v("Key insight:")]),e._v(" Each token in a completion receives the "),a("strong",[e._v("same advantage value")]),e._v(" (the completion's advantage).")]),e._v(" "),a("h3",{attrs:{id:"loss-computation"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#loss-computation"}},[e._v("#")]),e._v(" Loss Computation")]),e._v(" "),a("p",[a("strong",[e._v("‚ö†Ô∏è Critical Understanding: This is NOT a traditional supervised loss!")])]),e._v(" "),a("p",[e._v("The loss is "),a("strong",[e._v("purely reward-based")]),e._v(" - there is NO ground truth comparison:")]),e._v(" "),a("div",{staticClass:"language-python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[e._v("# Clipped importance sampling ratio")]),e._v("\ncoef_2 "),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("=")]),e._v(" clamp"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("(")]),e._v("coef_1"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[e._v("1")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("-")]),e._v(" epsilon"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[e._v("1")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("+")]),e._v(" epsilon"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(")")]),e._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[e._v("# epsilon = 0.2")]),e._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[e._v("# coef_2 = clamp(coef_1, 0.8, 1.2)")]),e._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[e._v("# Per-token loss components")]),e._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[e._v("# Loss = Advantage √ó Importance Sampling Ratio")]),e._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[e._v("# There is NO comparison to ground truth tokens!")]),e._v("\nper_token_loss1 "),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("=")]),e._v(" coef_1 "),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("*")]),e._v(" advantages_broadcast  "),a("span",{pre:!0,attrs:{class:"token comment"}},[e._v("# Shape: (3, 6)")]),e._v("\nper_token_loss2 "),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("=")]),e._v(" coef_2 "),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("*")]),e._v(" advantages_broadcast  "),a("span",{pre:!0,attrs:{class:"token comment"}},[e._v("# Shape: (3, 6)")]),e._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[e._v("# Per-token loss (clipped surrogate)")]),e._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[e._v('# This tells the model: "increase/decrease token probabilities based on completion quality"')]),e._v("\nper_token_loss "),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("=")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("-")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[e._v("min")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("(")]),e._v("per_token_loss1"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),e._v(" per_token_loss2"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(")")]),e._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[e._v("# Shape: (3, 6)")]),e._v("\n")])]),e._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[e._v("1")]),a("br"),a("span",{staticClass:"line-number"},[e._v("2")]),a("br"),a("span",{staticClass:"line-number"},[e._v("3")]),a("br"),a("span",{staticClass:"line-number"},[e._v("4")]),a("br"),a("span",{staticClass:"line-number"},[e._v("5")]),a("br"),a("span",{staticClass:"line-number"},[e._v("6")]),a("br"),a("span",{staticClass:"line-number"},[e._v("7")]),a("br"),a("span",{staticClass:"line-number"},[e._v("8")]),a("br"),a("span",{staticClass:"line-number"},[e._v("9")]),a("br"),a("span",{staticClass:"line-number"},[e._v("10")]),a("br"),a("span",{staticClass:"line-number"},[e._v("11")]),a("br"),a("span",{staticClass:"line-number"},[e._v("12")]),a("br"),a("span",{staticClass:"line-number"},[e._v("13")]),a("br")])]),a("p",[a("strong",[e._v("What this means")]),e._v(":")]),e._v(" "),a("ul",[a("li",[a("strong",[e._v("No ground truth")]),e._v(": Unlike supervised learning, we don't compare each token to a target token")]),e._v(" "),a("li",[a("strong",[e._v("Reward signal only")]),e._v(": The loss is computed as: "),a("code",[e._v("Loss = Advantage √ó Importance_Ratio")])]),e._v(" "),a("li",[a("strong",[e._v("Broadcast reward")]),e._v(": The completion's reward (via advantage) is broadcast to ALL tokens in that completion")]),e._v(" "),a("li",[a("strong",[e._v("Token-level learning")]),e._v(": Each token's probability is adjusted based on:\n"),a("ul",[a("li",[e._v("The completion's overall reward (via advantage)")]),e._v(" "),a("li",[e._v("How much the policy changed for that token (importance sampling ratio)")])])]),e._v(" "),a("li",[a("strong",[e._v("Good completion")]),e._v(" (advantage = +1.225): All tokens get positive signal ‚Üí increase probabilities")]),e._v(" "),a("li",[a("strong",[e._v("Bad completion")]),e._v(" (advantage = -1.225): All tokens get negative signal ‚Üí decrease probabilities")])]),e._v(" "),a("p",[a("strong",[e._v("Mathematical representation:")])]),e._v(" "),a("p",[e._v("For each token "),a("code",[e._v("(i, t)")]),e._v(":")]),e._v(" "),a("p",[e._v("$$\nl_{i,t} = -\\min\\left( \\rho_{i,t} \\cdot A_i, \\operatorname{clip}(\\rho_{i,t}, 1-\\epsilon, 1+\\epsilon) \\cdot A_i \\right)\n$$")]),e._v(" "),a("p",[e._v("$$\n\\mathbf{L}"),a("em",[e._v("{loss} = \\begin{bmatrix}\nl")]),e._v("{0,0} & l_{0,1} & l_{0,2} & l_{0,3} & l_{0,4} & l_{0,5} \\\nl_{1,0} & l_{1,1} & l_{1,2} & l_{1,3} & l_{1,4} & l_{1,5} \\\nl_{2,0} & l_{2,1} & l_{2,2} & l_{2,3} & l_{2,4} & l_{2,5}\n\\end{bmatrix}\n$$")]),e._v(" "),a("p",[a("strong",[e._v("Shape:")]),e._v(" "),a("code",[e._v("(B, T_max) = (3, 6)")]),e._v(" - "),a("strong",[e._v("token-level loss")])]),e._v(" "),a("p",[a("strong",[e._v("Key point:")]),e._v(" Loss is computed "),a("strong",[e._v("per token")]),e._v(", but each token in a completion uses the "),a("strong",[e._v("same advantage")]),e._v(" (the completion's advantage).")]),e._v(" "),a("hr"),e._v(" "),a("h2",{attrs:{id:"step-7-loss-aggregation"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#step-7-loss-aggregation"}},[e._v("#")]),e._v(" Step 7: Loss Aggregation")]),e._v(" "),a("h3",{attrs:{id:"mask-out-padding"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#mask-out-padding"}},[e._v("#")]),e._v(" Mask Out Padding")]),e._v(" "),a("div",{staticClass:"language-python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[e._v("# Completion mask (1 for real tokens, 0 for padding)")]),e._v("\ncompletion_mask "),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("=")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("[")]),e._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[e._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[e._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[e._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[e._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[e._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[e._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),e._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[e._v("# comp0: 5 real tokens")]),e._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[e._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[e._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[e._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[e._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[e._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[e._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),e._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[e._v("# comp1: 4 real tokens")]),e._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[e._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[e._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[e._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[e._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[e._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[e._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("]")]),e._v("   "),a("span",{pre:!0,attrs:{class:"token comment"}},[e._v("# comp2: 6 real tokens")]),e._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("]")]),e._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[e._v("# Shape: (3, 6)")]),e._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[e._v("# Masked loss")]),e._v("\nmasked_loss "),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("=")]),e._v(" per_token_loss "),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("*")]),e._v(" completion_mask  "),a("span",{pre:!0,attrs:{class:"token comment"}},[e._v("# Shape: (3, 6)")]),e._v("\n")])]),e._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[e._v("1")]),a("br"),a("span",{staticClass:"line-number"},[e._v("2")]),a("br"),a("span",{staticClass:"line-number"},[e._v("3")]),a("br"),a("span",{staticClass:"line-number"},[e._v("4")]),a("br"),a("span",{staticClass:"line-number"},[e._v("5")]),a("br"),a("span",{staticClass:"line-number"},[e._v("6")]),a("br"),a("span",{staticClass:"line-number"},[e._v("7")]),a("br"),a("span",{staticClass:"line-number"},[e._v("8")]),a("br"),a("span",{staticClass:"line-number"},[e._v("9")]),a("br")])]),a("h3",{attrs:{id:"aggregate-to-per-completion-loss"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#aggregate-to-per-completion-loss"}},[e._v("#")]),e._v(" Aggregate to Per-Completion Loss")]),e._v(" "),a("div",{staticClass:"language-python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[e._v("# Per-completion loss (sum tokens, normalize by length)")]),e._v("\nper_completion_loss "),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("=")]),e._v(" masked_loss"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(".")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[e._v("sum")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("(")]),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("-")]),a("span",{pre:!0,attrs:{class:"token number"}},[e._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(")")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("/")]),e._v(" completion_mask"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(".")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[e._v("sum")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("(")]),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("-")]),a("span",{pre:!0,attrs:{class:"token number"}},[e._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(")")]),e._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[e._v("# Shape: (3,)")]),e._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[e._v("# per_completion_loss = [")]),e._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[e._v("#     (l_0,0 + l_0,1 + l_0,2 + l_0,3 + l_0,4) / 5,  # comp0")]),e._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[e._v("#     (l_1,0 + l_1,1 + l_1,2 + l_1,3) / 4,           # comp1")]),e._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[e._v("#     (l_2,0 + l_2,1 + l_2,2 + l_2,3 + l_2,4 + l_2,5) / 6  # comp2")]),e._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[e._v("# ]")]),e._v("\n")])]),e._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[e._v("1")]),a("br"),a("span",{staticClass:"line-number"},[e._v("2")]),a("br"),a("span",{staticClass:"line-number"},[e._v("3")]),a("br"),a("span",{staticClass:"line-number"},[e._v("4")]),a("br"),a("span",{staticClass:"line-number"},[e._v("5")]),a("br"),a("span",{staticClass:"line-number"},[e._v("6")]),a("br"),a("span",{staticClass:"line-number"},[e._v("7")]),a("br")])]),a("p",[a("strong",[e._v("Mathematical representation:")])]),e._v(" "),a("p",[e._v("$$\n\\bar{l}"),a("em",[e._v("i = \\frac{1}{|o_i|} \\sum")]),e._v("{t=1}^{|o_i|} l_{i,t}\n$$")]),e._v(" "),a("p",[e._v("$$\n\\bar{\\mathbf{L}} = \\begin{bmatrix} \\bar{l}_0 \\ \\bar{l}_1 \\ \\bar{l}_2 \\end{bmatrix}\n$$")]),e._v(" "),a("p",[a("strong",[e._v("Shape:")]),e._v(" "),a("code",[e._v("(B,) = (3,)")]),e._v(" - per-completion loss")]),e._v(" "),a("h3",{attrs:{id:"final-scalar-loss"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#final-scalar-loss"}},[e._v("#")]),e._v(" Final Scalar Loss")]),e._v(" "),a("div",{staticClass:"language-python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[e._v("# Final scalar loss (average across completions)")]),e._v("\nfinal_loss "),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("=")]),e._v(" per_completion_loss"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(".")]),e._v("mean"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(")")]),e._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[e._v("# Shape: () - scalar")]),e._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[e._v("# final_loss = (l_0 + l_1 + l_2) / 3")]),e._v("\n")])]),e._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[e._v("1")]),a("br"),a("span",{staticClass:"line-number"},[e._v("2")]),a("br"),a("span",{staticClass:"line-number"},[e._v("3")]),a("br")])]),a("p",[a("strong",[e._v("Mathematical representation:")])]),e._v(" "),a("p",[e._v("$$\n\\mathcal{L} = \\frac{1}{B} \\sum_{i=0}^{B-1} \\bar{l}"),a("em",[e._v("i = \\frac{1}{B} \\sum")]),e._v("{i=0}^{B-1} \\frac{1}{|o_i|} \\sum_{t=1}^{|o_i|} l_{i,t}\n$$")]),e._v(" "),a("p",[a("strong",[e._v("Shape:")]),e._v(" "),a("code",[e._v("()")]),e._v(" - scalar")]),e._v(" "),a("hr"),e._v(" "),a("h2",{attrs:{id:"complete-flow-summary"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#complete-flow-summary"}},[e._v("#")]),e._v(" Complete Flow Summary")]),e._v(" "),a("div",{staticClass:"language- line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v("Rewards (sequence-level, sparse):\n  r = [1.0, 0.0, 0.5]  (B,)\n\n    ‚Üì Group-relative normalization\n\nAdvantages (sequence-level):\n  A = [1.225, -1.225, 0.0]  (B,)\n\n    ‚Üì Unsqueeze for broadcasting\n\nAdvantages (broadcast-ready):\n  A = [[1.225], [-1.225], [0.0]]  (B, 1)\n\n    ‚Üì Broadcast to tokens\n\nAdvantages (token-level, broadcast):\n  A = [[1.225, 1.225, 1.225, 1.225, 1.225, 1.225],\n       [-1.225, -1.225, -1.225, -1.225, -1.225, -1.225],\n       [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]]  (B, T)\n\n    ‚Üì Multiply with importance ratios\n\nPer-token loss:\n  L_loss = [[l_0,0, l_0,1, l_0,2, l_0,3, l_0,4, 0],\n            [l_1,0, l_1,1, l_1,2, l_1,3, 0, 0],\n            [l_2,0, l_2,1, l_2,2, l_2,3, l_2,4, l_2,5]]  (B, T)\n\n    ‚Üì Aggregate per completion\n\nPer-completion loss:\n  L_bar = [l_0, l_1, l_2]  (B,)\n\n    ‚Üì Average\n\nFinal scalar loss:\n  L = mean([l_0, l_1, l_2])  ()\n")])]),e._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[e._v("1")]),a("br"),a("span",{staticClass:"line-number"},[e._v("2")]),a("br"),a("span",{staticClass:"line-number"},[e._v("3")]),a("br"),a("span",{staticClass:"line-number"},[e._v("4")]),a("br"),a("span",{staticClass:"line-number"},[e._v("5")]),a("br"),a("span",{staticClass:"line-number"},[e._v("6")]),a("br"),a("span",{staticClass:"line-number"},[e._v("7")]),a("br"),a("span",{staticClass:"line-number"},[e._v("8")]),a("br"),a("span",{staticClass:"line-number"},[e._v("9")]),a("br"),a("span",{staticClass:"line-number"},[e._v("10")]),a("br"),a("span",{staticClass:"line-number"},[e._v("11")]),a("br"),a("span",{staticClass:"line-number"},[e._v("12")]),a("br"),a("span",{staticClass:"line-number"},[e._v("13")]),a("br"),a("span",{staticClass:"line-number"},[e._v("14")]),a("br"),a("span",{staticClass:"line-number"},[e._v("15")]),a("br"),a("span",{staticClass:"line-number"},[e._v("16")]),a("br"),a("span",{staticClass:"line-number"},[e._v("17")]),a("br"),a("span",{staticClass:"line-number"},[e._v("18")]),a("br"),a("span",{staticClass:"line-number"},[e._v("19")]),a("br"),a("span",{staticClass:"line-number"},[e._v("20")]),a("br"),a("span",{staticClass:"line-number"},[e._v("21")]),a("br"),a("span",{staticClass:"line-number"},[e._v("22")]),a("br"),a("span",{staticClass:"line-number"},[e._v("23")]),a("br"),a("span",{staticClass:"line-number"},[e._v("24")]),a("br"),a("span",{staticClass:"line-number"},[e._v("25")]),a("br"),a("span",{staticClass:"line-number"},[e._v("26")]),a("br"),a("span",{staticClass:"line-number"},[e._v("27")]),a("br"),a("span",{staticClass:"line-number"},[e._v("28")]),a("br"),a("span",{staticClass:"line-number"},[e._v("29")]),a("br"),a("span",{staticClass:"line-number"},[e._v("30")]),a("br"),a("span",{staticClass:"line-number"},[e._v("31")]),a("br"),a("span",{staticClass:"line-number"},[e._v("32")]),a("br"),a("span",{staticClass:"line-number"},[e._v("33")]),a("br"),a("span",{staticClass:"line-number"},[e._v("34")]),a("br"),a("span",{staticClass:"line-number"},[e._v("35")]),a("br"),a("span",{staticClass:"line-number"},[e._v("36")]),a("br")])]),a("hr"),e._v(" "),a("h2",{attrs:{id:"key-insights"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#key-insights"}},[e._v("#")]),e._v(" Key Insights")]),e._v(" "),a("ol",[a("li",[a("strong",[e._v("Rewards are sparse")]),e._v(": One scalar per completion, computed at the end (sequence-level)")]),e._v(" "),a("li",[a("strong",[e._v("Advantages are group-relative")]),e._v(": Advantages are computed relative to the "),a("strong",[e._v("group average")]),e._v(" (mean reward for all completions of the same prompt)\n"),a("ul",[a("li",[e._v("Formula: "),a("code",[e._v("A_i = r_i - mean(r_group)")])]),e._v(" "),a("li",[e._v('This enables comparative learning: "Is this completion better than others for the same prompt?"')])])]),e._v(" "),a("li",[a("strong",[e._v("Advantages are broadcast")]),e._v(": The same advantage value is applied to all tokens in a completion")]),e._v(" "),a("li",[a("strong",[e._v("Loss is reward-based, not ground-truth-based")]),e._v(": The loss does NOT compare tokens to ground truth. Instead:\n"),a("ul",[a("li",[e._v("Loss = Advantage √ó Importance Sampling Ratio (with clipping)")]),e._v(" "),a("li",[e._v("Each token's loss depends on:\n"),a("ul",[a("li",[e._v("The completion's overall reward (via advantage, which is group-relative)")]),e._v(" "),a("li",[e._v("The token's importance sampling ratio (how much the policy changed)")])])]),e._v(" "),a("li",[e._v("Good completions (positive advantage) ‚Üí negative loss ‚Üí increase token probabilities")]),e._v(" "),a("li",[e._v("Bad completions (negative advantage) ‚Üí positive loss ‚Üí decrease token probabilities")])])]),e._v(" "),a("li",[a("strong",[e._v("All tokens in a completion share the same advantage")]),e._v(": This is the key insight - the advantage reflects the overall quality of the completion relative to its group, not individual tokens")]),e._v(" "),a("li",[a("strong",[e._v("No direct token-level supervision")]),e._v(": Unlike supervised learning, there's no per-token ground truth comparison. The model learns purely from the reward signal.")]),e._v(" "),a("li",[a("strong",[e._v("Importance sampling ratio is relative to old log probs")]),e._v(":\n"),a("ul",[a("li",[a("code",[e._v("old_per_token_logps")]),e._v(": Computed right after generation with "),a("code",[e._v("Œ∏_gen")]),e._v(" (generation-time weights)")]),e._v(" "),a("li",[a("code",[e._v("per_token_logps")]),e._v(": Computed during training with "),a("code",[e._v("Œ∏_current")]),e._v(" (current weights, may have been updated)")]),e._v(" "),a("li",[e._v("Ratio: "),a("code",[e._v("œÅ = œÄ_Œ∏_current / œÄ_Œ∏_gen")]),e._v(" - measures how much the policy changed since generation")])])])]),e._v(" "),a("hr"),e._v(" "),a("h2",{attrs:{id:"why-this-design"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#why-this-design"}},[e._v("#")]),e._v(" Why This Design?")]),e._v(" "),a("ul",[a("li",[a("strong",[e._v("Rewards are naturally sequence-level")]),e._v(": Most reward functions evaluate the entire completion (e.g., accuracy, format)")]),e._v(" "),a("li",[a("strong",[e._v("Group-relative advantages normalize across prompts")]),e._v(": Different prompts may have different difficulty/reward scales. By comparing within groups, we normalize this bias")]),e._v(" "),a("li",[a("strong",[e._v("Token-level loss enables fine-grained learning")]),e._v(": Each token's probability is adjusted based on the completion's overall quality (relative to its group)")]),e._v(" "),a("li",[a("strong",[e._v("Broadcasting is efficient")]),e._v(": One advantage computation per completion, applied to all tokens")]),e._v(" "),a("li",[a("strong",[e._v("Reward-based learning")]),e._v(": Unlike supervised learning that compares each token to ground truth, RL-based training uses the reward signal to guide learning:\n"),a("ul",[a("li",[e._v("If a completion gets a high reward relative to its group ‚Üí all its tokens get positive signal ‚Üí increase their probabilities")]),e._v(" "),a("li",[e._v("If a completion gets a low reward relative to its group ‚Üí all its tokens get negative signal ‚Üí decrease their probabilities")]),e._v(" "),a("li",[e._v("The importance sampling ratio ensures we only update tokens proportionally to how much the policy changed since generation")])])])]),e._v(" "),a("h2",{attrs:{id:"timing-of-log-probabilities"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#timing-of-log-probabilities"}},[e._v("#")]),e._v(" Timing of Log Probabilities")]),e._v(" "),a("h3",{attrs:{id:"when-are-they-computed"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#when-are-they-computed"}},[e._v("#")]),e._v(" When are they computed?")]),e._v(" "),a("p",[a("strong",[a("code",[e._v("old_per_token_logps")])]),e._v(":")]),e._v(" "),a("ul",[a("li",[a("strong",[e._v("When")]),e._v(": Right after generation (in "),a("code",[e._v("_generate_and_score_completions")]),e._v(")")]),e._v(" "),a("li",[a("strong",[e._v("Model weights")]),e._v(": "),a("code",[e._v("Œ∏_gen")]),e._v(" (same as generation-time weights)")]),e._v(" "),a("li",[a("strong",[e._v("Purpose")]),e._v(": Capture what the generation-time policy thought about these completions")]),e._v(" "),a("li",[a("strong",[e._v("Stored")]),e._v(": Saved with completions for reuse across multiple training steps")])]),e._v(" "),a("p",[a("strong",[a("code",[e._v("per_token_logps")])]),e._v(":")]),e._v(" "),a("ul",[a("li",[a("strong",[e._v("When")]),e._v(": During training (in "),a("code",[e._v("_compute_loss")]),e._v(")")]),e._v(" "),a("li",[a("strong",[e._v("Model weights")]),e._v(": "),a("code",[e._v("Œ∏_current")]),e._v(" (may have been updated multiple times since generation)")]),e._v(" "),a("li",[a("strong",[e._v("Purpose")]),e._v(": Capture what the current policy thinks about the same completions")]),e._v(" "),a("li",[a("strong",[e._v("Computed")]),e._v(": Fresh forward pass with current weights")])]),e._v(" "),a("h3",{attrs:{id:"timeline-example"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#timeline-example"}},[e._v("#")]),e._v(" Timeline Example")]),e._v(" "),a("div",{staticClass:"language- line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v("Step 0 (Generation):\n  Model weights: Œ∏‚ÇÄ\n  ‚Üí Generate completions with Œ∏‚ÇÄ\n  ‚Üí Compute old_per_token_logps with Œ∏‚ÇÄ\n  ‚Üí Store: [completions, old_per_token_logps] (both from Œ∏‚ÇÄ)\n\nStep 1 (Training):\n  Model weights: Œ∏‚ÇÅ (updated)\n  ‚Üí Retrieve stored completions (from Œ∏‚ÇÄ)\n  ‚Üí Compute per_token_logps with Œ∏‚ÇÅ\n  ‚Üí Importance ratio: œÄ_Œ∏‚ÇÅ / œÄ_Œ∏‚ÇÄ\n  ‚Üí Update model: Œ∏‚ÇÅ ‚Üí Œ∏‚ÇÇ\n\nStep 2 (Training):\n  Model weights: Œ∏‚ÇÇ (updated again)\n  ‚Üí Retrieve same stored completions (still from Œ∏‚ÇÄ)\n  ‚Üí Compute per_token_logps with Œ∏‚ÇÇ\n  ‚Üí Importance ratio: œÄ_Œ∏‚ÇÇ / œÄ_Œ∏‚ÇÄ  ‚Üê Still comparing to Œ∏‚ÇÄ!\n  ‚Üí Update model: Œ∏‚ÇÇ ‚Üí Œ∏‚ÇÉ\n\nStep 3 (Training):\n  Model weights: Œ∏‚ÇÉ\n  ‚Üí Retrieve same stored completions (still from Œ∏‚ÇÄ)\n  ‚Üí Compute per_token_logps with Œ∏‚ÇÉ\n  ‚Üí Importance ratio: œÄ_Œ∏‚ÇÉ / œÄ_Œ∏‚ÇÄ\n\nStep 4 (NEW Generation):\n  Model weights: Œ∏‚ÇÑ\n  ‚Üí Generate NEW completions with Œ∏‚ÇÑ\n  ‚Üí Compute old_per_token_logps with Œ∏‚ÇÑ\n  ‚Üí Store: [new_completions, old_per_token_logps] (both from Œ∏‚ÇÑ)\n  ‚Üí Cycle repeats...\n")])]),e._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[e._v("1")]),a("br"),a("span",{staticClass:"line-number"},[e._v("2")]),a("br"),a("span",{staticClass:"line-number"},[e._v("3")]),a("br"),a("span",{staticClass:"line-number"},[e._v("4")]),a("br"),a("span",{staticClass:"line-number"},[e._v("5")]),a("br"),a("span",{staticClass:"line-number"},[e._v("6")]),a("br"),a("span",{staticClass:"line-number"},[e._v("7")]),a("br"),a("span",{staticClass:"line-number"},[e._v("8")]),a("br"),a("span",{staticClass:"line-number"},[e._v("9")]),a("br"),a("span",{staticClass:"line-number"},[e._v("10")]),a("br"),a("span",{staticClass:"line-number"},[e._v("11")]),a("br"),a("span",{staticClass:"line-number"},[e._v("12")]),a("br"),a("span",{staticClass:"line-number"},[e._v("13")]),a("br"),a("span",{staticClass:"line-number"},[e._v("14")]),a("br"),a("span",{staticClass:"line-number"},[e._v("15")]),a("br"),a("span",{staticClass:"line-number"},[e._v("16")]),a("br"),a("span",{staticClass:"line-number"},[e._v("17")]),a("br"),a("span",{staticClass:"line-number"},[e._v("18")]),a("br"),a("span",{staticClass:"line-number"},[e._v("19")]),a("br"),a("span",{staticClass:"line-number"},[e._v("20")]),a("br"),a("span",{staticClass:"line-number"},[e._v("21")]),a("br"),a("span",{staticClass:"line-number"},[e._v("22")]),a("br"),a("span",{staticClass:"line-number"},[e._v("23")]),a("br"),a("span",{staticClass:"line-number"},[e._v("24")]),a("br"),a("span",{staticClass:"line-number"},[e._v("25")]),a("br"),a("span",{staticClass:"line-number"},[e._v("26")]),a("br"),a("span",{staticClass:"line-number"},[e._v("27")]),a("br"),a("span",{staticClass:"line-number"},[e._v("28")]),a("br"),a("span",{staticClass:"line-number"},[e._v("29")]),a("br"),a("span",{staticClass:"line-number"},[e._v("30")]),a("br"),a("span",{staticClass:"line-number"},[e._v("31")]),a("br"),a("span",{staticClass:"line-number"},[e._v("32")]),a("br")])]),a("p",[a("strong",[e._v("Key insight")]),e._v(": "),a("code",[e._v("old_per_token_logps")]),e._v(" is computed with generation-time weights ("),a("code",[e._v("Œ∏_gen")]),e._v("), stored, and reused. "),a("code",[e._v("per_token_logps")]),e._v(" is computed with current weights ("),a("code",[e._v("Œ∏_current")]),e._v(") during training. The importance sampling ratio corrects for the policy drift between generation and training.")]),e._v(" "),a("hr"),e._v(" "),a("h2",{attrs:{id:"complete-summary"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#complete-summary"}},[e._v("#")]),e._v(" Complete Summary")]),e._v(" "),a("h3",{attrs:{id:"two-relative-measures-in-grpo"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#two-relative-measures-in-grpo"}},[e._v("#")]),e._v(" Two Relative Measures in GRPO")]),e._v(" "),a("ol",[a("li",[a("p",[a("strong",[e._v("Group-Relative Advantages")]),e._v(":")]),e._v(" "),a("ul",[a("li",[e._v("Formula: "),a("code",[e._v("A_i = r_i - mean(r_group)")])]),e._v(" "),a("li",[e._v("Group = all completions for the same prompt")]),e._v(" "),a("li",[e._v("Advantages normalize rewards within each prompt group")]),e._v(" "),a("li",[e._v('Enables comparative learning: "Is this completion better than others for the same prompt?"')])])]),e._v(" "),a("li",[a("p",[a("strong",[e._v("Policy-Relative Importance Sampling Ratio")]),e._v(":")]),e._v(" "),a("ul",[a("li",[e._v("Formula: "),a("code",[e._v("œÅ = œÄ_Œ∏_current / œÄ_Œ∏_gen")])]),e._v(" "),a("li",[e._v("Measures how much the policy changed since generation")]),e._v(" "),a("li",[a("code",[e._v("old_per_token_logps")]),e._v(": Computed right after generation with "),a("code",[e._v("Œ∏_gen")])]),e._v(" "),a("li",[a("code",[e._v("per_token_logps")]),e._v(": Computed during training with "),a("code",[e._v("Œ∏_current")]),e._v(" (updated weights)")]),e._v(" "),a("li",[e._v("Corrects for off-policy learning when reusing old completions")])])])]),e._v(" "),a("h3",{attrs:{id:"loss-computation-flow"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#loss-computation-flow"}},[e._v("#")]),e._v(" Loss Computation Flow")]),e._v(" "),a("div",{staticClass:"language- line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v("Rewards (sparse, sequence-level)\n    ‚Üì\nGroup-relative normalization\n    ‚Üì\nAdvantages (sequence-level, relative to group mean)\n    ‚Üì\nBroadcast to tokens\n    ‚Üì\nMultiply with Importance Sampling Ratio (policy-relative)\n    ‚Üì\nToken-level loss (reward-based, NOT ground-truth-based)\n    ‚Üì\nAggregate per completion\n    ‚Üì\nFinal scalar loss\n")])]),e._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[e._v("1")]),a("br"),a("span",{staticClass:"line-number"},[e._v("2")]),a("br"),a("span",{staticClass:"line-number"},[e._v("3")]),a("br"),a("span",{staticClass:"line-number"},[e._v("4")]),a("br"),a("span",{staticClass:"line-number"},[e._v("5")]),a("br"),a("span",{staticClass:"line-number"},[e._v("6")]),a("br"),a("span",{staticClass:"line-number"},[e._v("7")]),a("br"),a("span",{staticClass:"line-number"},[e._v("8")]),a("br"),a("span",{staticClass:"line-number"},[e._v("9")]),a("br"),a("span",{staticClass:"line-number"},[e._v("10")]),a("br"),a("span",{staticClass:"line-number"},[e._v("11")]),a("br"),a("span",{staticClass:"line-number"},[e._v("12")]),a("br"),a("span",{staticClass:"line-number"},[e._v("13")]),a("br"),a("span",{staticClass:"line-number"},[e._v("14")]),a("br"),a("span",{staticClass:"line-number"},[e._v("15")]),a("br")])]),a("h3",{attrs:{id:"key-takeaways"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#key-takeaways"}},[e._v("#")]),e._v(" Key Takeaways")]),e._v(" "),a("ul",[a("li",[e._v("‚úÖ "),a("strong",[e._v("Rewards")]),e._v(": Sparse, one scalar per completion")]),e._v(" "),a("li",[e._v("‚úÖ "),a("strong",[e._v("Advantages")]),e._v(": Group-relative (normalized within prompt groups)")]),e._v(" "),a("li",[e._v("‚úÖ "),a("strong",[e._v("Importance Ratio")]),e._v(": Policy-relative (measures policy change)")]),e._v(" "),a("li",[e._v("‚úÖ "),a("strong",[e._v("Loss")]),e._v(": Reward-based, no ground truth comparison")]),e._v(" "),a("li",[e._v("‚úÖ "),a("strong",[e._v("Timing")]),e._v(": "),a("code",[e._v("old_logprobs")]),e._v(" from generation-time weights, "),a("code",[e._v("current_logprobs")]),e._v(" from training-time weights")])]),e._v(" "),a("hr")])}),[],!1,null,null,null);a.default=n.exports}}]);
(window.webpackJsonp=window.webpackJsonp||[]).push([[84],{537:function(a,e,t){"use strict";t.r(e);var s=t(9),r=Object(s.a)({},(function(){var a=this,e=a._self._c;return e("ContentSlotsDistributor",{attrs:{"slot-key":a.$parent.slotKey}},[e("h3",{attrs:{id:"cache"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#cache"}},[a._v("#")]),a._v(" Cache")]),a._v(" "),e("h4",{attrs:{id:"structure"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#structure"}},[a._v("#")]),a._v(" Structure")]),a._v(" "),e("p",[e("img",{attrs:{src:"https://github.com/user-attachments/assets/8506005a-539e-4008-8ec1-d94149280757",alt:"image"}}),a._v(" "),e("a",{attrs:{href:"#1"}},[a._v("[1]")])]),a._v(" "),e("p",[e("a",{attrs:{href:"#1"}},[a._v("[1]")])]),a._v(" "),e("ul",[e("li",[a._v("Bank - A memory structure that consists of a data and a tag array. A cache is typically split into multiple banks and CACTI assumes enough bandwidth so that these banks can be accessed\nsimultaneously. The network topology that interconnects these banks can vary depending on the cache model.")]),a._v(" "),e("li",[a._v("Sub-arrays - A data or tag array is divided into a number of sub-arrays to reduce the delay due to wordline and bitline. Unlike banks, at any given time, these sub-arrays support only one single\naccess. The total number of sub-arrays in a cache is equal to the product of Ndwl and Ndbl.")]),a._v(" "),e("li",[a._v("Mat - A group of four sub-arrays (2x2) that share a common central predecoder. CACTIâ€™s exhaustive search starts from a minimum of at least one mat.")]),a._v(" "),e("li",[a._v("Sub-bank - In a typical cache, a cache block is scattered across multiple sub-arrays to improve the reliability of a cache. Irrespective of the cache organization, CACTI assumes that every cache\nblock in a cache is distributed across an entire row of mats and the row number corresponding to a particular block is determined based on the block address. Each row (of mats) in an array is\nreferred to as a sub-bank.")])]),a._v(" "),e("h4",{attrs:{id:"why-do-we-needs-bank"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#why-do-we-needs-bank"}},[a._v("#")]),a._v(" why do we needs bank")]),a._v(" "),e("p",[e("a",{attrs:{href:"#2"}},[a._v("[2]")]),a._v(" Support for more than one access to a memory structure at the same time can be provided by adding more ports to each memory cell.")]),a._v(" "),e("p",[a._v("Multiporting a cache makes the cache capable of handling as many read or write requests as ports of that type.")]),a._v(" "),e("p",[a._v("But multiporting a cache makes each bit cell much bigger and so the overall area of the memory array can increase enormously for large number of ports.\nThe extra length spanned by the cache also adds directly to the access time and power consumed by the cache.")]),a._v(" "),e("p",[a._v("Another way of supporting simultaneous multiple accesses to a cache is by banking with fully independent banks.")]),a._v(" "),e("p",[a._v("Each bank does not share address and data.")]),a._v(" "),e("p",[a._v("Banking also adds the decoding overhead of routing the appropriate address to the right bank and detecting collisions.")]),a._v(" "),e("p",[e("a",{attrs:{href:"#2"}},[a._v("[2]")])]),a._v(" "),e("p",[e("img",{attrs:{src:"https://github.com/user-attachments/assets/204a579a-2842-4b47-aa91-22d2d6977c8b",alt:"image"}})]),a._v(" "),e("p",[e("img",{attrs:{src:"https://github.com/user-attachments/assets/7814b591-fe1c-475d-aa75-4527fa8770d6",alt:"image"}})]),a._v(" "),e("p",[e("img",{attrs:{src:"https://github.com/user-attachments/assets/a90a8fac-267a-4613-94af-2722f50d2cfa",alt:"image"}})]),a._v(" "),e("p",[e("img",{attrs:{src:"https://github.com/user-attachments/assets/12f5955e-a86f-479a-827c-829d0f5af5f4",alt:"image"}})]),a._v(" "),e("p",[e("img",{attrs:{src:"https://github.com/user-attachments/assets/efca7dde-de2c-4d87-b054-0b2fb49b64cf",alt:"image"}})]),a._v(" "),e("p",[e("img",{attrs:{src:"https://github.com/user-attachments/assets/4ab60b37-d73c-4932-9241-8f5e517bd03e",alt:"image"}})]),a._v(" "),e("h4",{attrs:{id:"how-to-supply-64byte-at-each-time"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#how-to-supply-64byte-at-each-time"}},[a._v("#")]),a._v(" How to supply 64Byte at each time")]),a._v(" "),e("p",[a._v("Each sub-array outputs 128 bits, all 4 sub-array in the mat output 512bit together.\n"),e("a",{attrs:{href:"#3"}},[a._v("[3]")]),e("img",{attrs:{src:"https://github.com/user-attachments/assets/446c3960-664f-4686-8391-3bcb6ba5980c",alt:"image"}})]),a._v(" "),e("p",[e("a",{attrs:{href:"#4"}},[a._v("[4]")])]),a._v(" "),e("p",[a._v("A bank consists of Nsubbanks of identical sub-banks that are activated sequentially with each access. In turn, each sub-bank contains a number of identical mats.")]),a._v(" "),e("p",[a._v("A mat is a self-contained, compact memory array composed of four identical sub-arrays, with Nrows rows and Ncols columns, and accompanying predecoding logic, with\neach sub-array being a two-dimensional matrix of memory cells and associated peripheral circuitry.")]),a._v(" "),e("p",[a._v("Each mat holds a portion of a word in one of its four sub-arrays; "),e("em",[e("strong",[a._v("during cache access, all mats in a sub-bank are activated to form the whole word.")])])]),a._v(" "),e("p",[e("strong",[a._v("By whole word, he means a cacheline.")])]),a._v(" "),e("p",[a._v("H-tree distribution networks are often used to deliver address and data to mats.")]),a._v(" "),e("p",[a._v("In the following figure, each sub-array outputs 8 bits(1 byte), all mats in a subbank makesup 64 bytes.")]),a._v(" "),e("p",[e("img",{attrs:{src:"https://github.com/user-attachments/assets/f2f9a639-b8fd-491a-97c6-3d8b6169381d",alt:"image"}})]),a._v(" "),e("p",[e("a",{attrs:{href:"#5"}},[a._v("[5]")])]),a._v(" "),e("p",[e("img",{attrs:{src:"https://github.com/user-attachments/assets/e8906139-30b5-4691-8bd3-a2421c7b5002",alt:"image"}})]),a._v(" "),e("p",[a._v("why is there 10 bit in the above figure?")]),a._v(" "),e("p",[a._v("Parity and Error Correcting Codes(ECC).")]),a._v(" "),e("p",[e("img",{attrs:{src:"https://github.com/user-attachments/assets/b9cbc035-4b82-4960-84c8-9201bb036fb5",alt:"image"}})]),a._v(" "),e("p",[e("a",{attrs:{href:"#5"}},[a._v("[5]")]),a._v(" discussed the same flow.")]),a._v(" "),e("p",[a._v("Considering a number of input ports and a different/same number of banks, the controller detects the desired bank accesses, arbitrates eventual bank conflicts, and generates the required crossbar\nswitches selection signals.")]),a._v(" "),e("p",[a._v("At the highest level the address space is split across identical banks, four in this example, with each bank having its own address and data bus, thus allowing for concurrent bank accesses.")]),a._v(" "),e("p",[a._v("Each bank is composed of identical sub-banks, again four in this example, with only one being active per access.")]),a._v(" "),e("p",[a._v("Further, "),e("strong",[a._v("each sub-bank is partitioned into multiple mats that simultaneously provide parts of the required data (cache block in a cache data array).")])]),a._v(" "),e("p",[a._v("Finally, each mat is composed of four identical sub-arrays that share predecoding/decoding logic and peripheral circuitry, and which again deliver together the requested data.")]),a._v(" "),e("p",[a._v("An H-tree routing distribution network is used to drive addresses and data to/from the banks, and also to/from every mat inside a bank.")]),a._v(" "),e("h4",{attrs:{id:"how-to-index-into-bank"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#how-to-index-into-bank"}},[a._v("#")]),a._v(" How to index into bank")]),a._v(" "),e("p",[e("a",{attrs:{href:"#6"}},[a._v("[6]")]),a._v("In particular, the cache index, consisting of line number (LN) and line offset (LO), is divided into two portions: bank-internal address (BA) and bank index (BI). BA selects\na cache word or tag within a 1-port-memory-cell bank, and BI selects the respective bank within data/instruction or tag memory. BI uses the lower rank bits to assure that consecutive cache-lines and words within the same line are interleaved and located in different banks.")]),a._v(" "),e("p",[e("img",{attrs:{src:"https://github.com/user-attachments/assets/f9056bae-3fa9-4ea1-974f-dac88e5e5528",alt:"image"}})]),a._v(" "),e("p",[e("a",{attrs:{href:"#7"}},[a._v("[7]")])]),a._v(" "),e("p",[e("img",{attrs:{src:"https://github.com/user-attachments/assets/00b82429-1cda-47e8-b0ef-4c1cff45caec",alt:"image"}})]),a._v(" "),e("p",[e("img",{attrs:{src:"https://github.com/user-attachments/assets/740a8eb8-9c56-452a-8ea9-b453b80d9e4a",alt:"image"}})]),a._v(" "),e("h4",{attrs:{id:"conclusion"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#conclusion"}},[a._v("#")]),a._v(" conclusion")]),a._v(" "),e("p",[a._v("In summary, mat is the mininum unit to provide data. and all mat in a subbank provides  whole cache line.")]),a._v(" "),e("p",[a._v("Bank can only be accessed serially. Multi bank can provide mutiple request parallely.")]),a._v(" "),e("h3",{attrs:{id:"timing"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#timing"}},[a._v("#")]),a._v(" Timing")]),a._v(" "),e("p",[e("a",{attrs:{href:"#1"}},[a._v("[1]")]),a._v(" CACTI models the delay/power/area of eight major cache components: decoder, wordline, bitline, senseamp, comparator, multiplexor, output driver, and inter-bank wires. The wordline and bitline\ndelays are two of the most significant components of the access time. The wordline and bitline delays are quadratic functions of the width and height of each array, respectively.")]),a._v(" "),e("h3",{attrs:{id:"references"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#references"}},[a._v("#")]),a._v(" References")]),a._v(" "),e("p",[e("a",{attrs:{id:"1"}},[a._v("[1]")]),a._v("\nCACTI 6.0: A Tool to Understand Large Caches")]),a._v(" "),e("p",[e("a",{attrs:{id:"2"}},[a._v("[2]")]),a._v("\nCACTI 3.0: An Integrated Cache Timing, Power, and Area Model")]),a._v(" "),e("p",[e("a",{attrs:{id:"3"}},[a._v("[3]")]),a._v("\nFlexicache: Highly Reliable and Low Power Cache")]),a._v(" "),e("p",[e("a",{attrs:{id:"4"}},[a._v("[4]")]),a._v("\nBest Memory Architecture Exploration under Parameters Variations accelerated with Machine Learning")]),a._v(" "),e("p",[e("a",{attrs:{id:"5"}},[a._v("[5]")]),a._v("\nA Shared Polyhedral Cache for 3D Wide-I/O Multi-core Computing Platforms")]),a._v(" "),e("p",[e("a",{attrs:{id:"6"}},[a._v("[6]")]),a._v("\n4-Port Unified Data/Instruction Cache Design with Distributed Crossbar and Interleaved Cache-Line Words")]),a._v(" "),e("p",[e("a",{attrs:{id:"7"}},[a._v("[7]")]),a._v("\nUnified Data/Instruction Cache with Bank-Based Multi-Port Architecture")])])}),[],!1,null,null,null);e.default=r.exports}}]);
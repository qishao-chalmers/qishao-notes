(window.webpackJsonp=window.webpackJsonp||[]).push([[16],{472:function(e,t,a){"use strict";a.r(t);var i=a(8),r=Object(i.a)({},(function(){var e=this,t=e._self._c;return t("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[t("ol",[t("li",[e._v("CLOCK-DWF: A Write-History-Aware Page Replacement Algorithm for Hybrid PCM and DRAM Memory Architectures")]),e._v(" "),t("li",[e._v("An Operating System Level Data Migration Scheme in Hybrid DRAM-NVM Memory Architecture")]),e._v(" "),t("li",[e._v("APMigration: Improving Performance of Hybrid Memory Performance via An Adaptive Page Migration Method")]),e._v(" "),t("li",[e._v("Page Placement in Hybrid Memory Systems")])]),e._v(" "),t("hr"),e._v(" "),t("h4",{attrs:{id:"_1-clock-dwf-a-write-history-aware-page-replacement-algorithm-for-hybrid-pcm-and-dram-memory-architectures"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-clock-dwf-a-write-history-aware-page-replacement-algorithm-for-hybrid-pcm-and-dram-memory-architectures"}},[e._v("#")]),e._v(" 1. CLOCK-DWF: A Write-History-Aware Page Replacement Algorithm for Hybrid PCM and DRAM Memory Architectures")]),e._v(" "),t("p",[t("strong",[e._v("LRU")]),e._v(":\nEven though it requires only constant time and space overhead, LRU has a critical weakness in virtual memory environments. On every memory hit, LRU needs to move a page to the most recently used (MRU) position in the list. This involves list manipulations that cannot be handled by the paging unit hardware.\n"),t("strong",[e._v("CLOCK")]),e._v(":\nSpecifically, on a hit to a page, the paging unit hardware sets the reference bit of the page to 1 when a read or a write reference for that page occurs, and sets the dirty bit to 1 when a write reference occurs. Then, pages are maintained in a circular list.\nIn the course of the scan, for every page with reference bit 1, CLOCK clears it to zero, without removing the page from the list.")]),e._v(" "),t("p",[e._v("The reference bit of each page is an indication of whether that page has recently been accessed or not; and pages not referenced upon the return of the clock-hand to that page will be replaced. Even though CLOCK does not replace the least recently used page, it replaces a page that has not been referenced recently, that is, through the cycle of the circular list, so that temporal locality is exploited to some extent.")]),e._v(" "),t("p",[e._v("LRU maintains the temporal locality.\nFrequency of Write Reference collect statistics of reference cnter.")]),e._v(" "),t("img",{attrs:{src:"https://github.com/hitqshao/qishao-notes/assets/23403286/bb52315d-df24-4598-84e9-2d7b05db5683",alt:"Fig. 4",width:"600"}}),e._v(" "),t("img",{attrs:{src:"https://github.com/hitqshao/qishao-notes/assets/23403286/3743af17-f2fa-46d2-b527-54aedf9ff09a",alt:"Fig. 3",width:"600"}}),e._v(" "),t("p",[e._v("The shape of the curves in these figures can be modeled as a monotonic decreasing function, implying that a more recently referenced page is more likely to be written in the near future.")]),e._v(" "),t("p",[e._v("Specifically, we can observe ranking inversion of temporal locality, i.e., a more recently used page shows a smaller fraction of writes for some ranking ranges.")]),e._v(" "),t("img",{attrs:{src:"https://github.com/hitqshao/qishao-notes/assets/23403286/a3859015-7e6c-4064-a3b8-30091626880f",alt:"Fig. 4",width:"600"}}),e._v(" "),t("p",[e._v("In Fig. 3, x axis is the ranking by LRU.\ny axis represents the number of write references of the page ranking in x-axis.")]),e._v(" "),t("p",[e._v("In Fig. 4, the x-axis represents the ranking of pages based on their past write counts (black plot) and read/write counts (gray plot).\nThe y-axis represents the number of writes occurring on that ranking.")]),e._v(" "),t("p",[e._v("The reference bit of each page is an indication of whether that page has recently been accessed or not; and pages not referenced upon the return of the clock-hand to that page will be replaced. Even though CLOCK does not replace the least recently used page, it replaces a page that has not been referenced recently, that is, through the cycle of the circular list, so that temporal locality is exploited to some extent.")]),e._v(" "),t("p",[e._v("This indicates that frequency based estimations are more accurate compared to temporal locality based estimations for most cases. Specifically, frequency based stimations indicate that a wide range of top ranking pages, that is, pages that have been written to frequently in the past, are likely to be written to again in the future.")]),e._v(" "),t("p",[e._v("In summary, write frequency is generally a better estimator than temporal locality in predicting the re-reference likelihood of write references, but the very recent past write history is also a strong indicator of future writes.")]),e._v(" "),t("p",[t("strong",[e._v("Me")]),e._v("\nIn pic4, the axis x is also ranked by number of reference. That's why its x axis can correlates with y axis.\nMaybe 80% rule can also explain this.")]),e._v(" "),t("hr"),e._v(" "),t("h4",{attrs:{id:"_2-an-operating-system-level-data-migration-scheme-in-hybrid-dram-nvm-memory-architecture"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-an-operating-system-level-data-migration-scheme-in-hybrid-dram-nvm-memory-architecture"}},[e._v("#")]),e._v(" 2. An Operating System Level Data Migration Scheme in Hybrid DRAM-NVM Memory Architecture")]),e._v(" "),t("img",{attrs:{src:"https://github.com/hitqshao/qishao-notes/assets/23403286/83bec501-7aa0-4c08-a8dc-5cdb375ef834",alt:"System",width:"400"}}),e._v(" "),t("p",[e._v("Contrary to CLOCK-DWF that places page faults issued by read requests on NVM, the proposed scheme moves all pages from disk to DRAM area. This is motivated by the fact that moving to either NVM or DRAM will result in a page write in NVM since the DRAM is always full and moving a data page to DRAM will issue an eviction to NVM. Therefore, the cost of moving to NVM or DRAM is the same in terms of writes in NVM. The newly accessed data pages have higher probability of access compared to the older data pages and moving this new page to DRAM will result in increase in DRAM hit ratio instead of NVM hit ratio.")]),e._v(" "),t("p",[e._v("First,it requires an ordering scheme in order to identify data pages that are cold but will be accessed once in a long time. These data pages will reside long enough in NVM to have a high counter values and therefore will be moved to DRAM where they cannot compete with hot data pages and will return to NVM which makes their migration to DRAM without any benefits. Second, there is no difference between pages that are frequently accessed and typically reside near the head of the NVM LRU queue for the entire time and data pages which go back and forth in the queue.")]),e._v(" "),t("p",[e._v("The housekeeping information will be only stored for a few percentage of top positions in the NVM LRU queue. Once a data page moves to the end of this selected percentage of LRU, the corresponding counter will be reset to zero. This will handle both ordering scheme and identifying burst data accesses.")]),e._v(" "),t("p",[e._v("Finding the data page in DRAM will result in a normal LRU housekeeping. Otherwise, the extra housekeeping information in NVM will be updated based on the request type. The read and write counters will be stored for readperc and writeperc top data pages in the NVM, respectively.\n[Still confused why they have readperc and writeperc]")]),e._v(" "),t("p",[e._v("The values of read threshold and write threshold determine how aggressive we plan to prevent the migrations with low probability of being useful.")]),e._v(" "),t("img",{attrs:{src:"https://github.com/hitqshao/qishao-notes/assets/23403286/1e29cb59-437f-4499-adf9-c43d1388bc43",alt:" ",width:"400"}}),e._v(" "),t("p",[e._v("To this end, we use two Least Recently Used (LRU) queues (one for DRAM and one for NVM) and optimize the LRU queue for NVM to prevent nonbeneficial migrations to DRAM.")]),e._v(" "),t("h4",{attrs:{id:"_3-apmigration-improving-performance-of-hybrid-memory-performance-via-an-adaptive-page-migration-method"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3-apmigration-improving-performance-of-hybrid-memory-performance-via-an-adaptive-page-migration-method"}},[e._v("#")]),e._v(" 3. APMigration: Improving Performance of Hybrid Memory Performance via An Adaptive Page Migration Method")]),e._v(" "),t("p",[e._v("Comments on the previous paper:\nCLOCK-DWF [19]. CLOCK-DWF first proposes to load the write-request pages into DRAM. For new pages, if it is for a write request, it will be swapped into DRAM. Otherwise, it will be placed in NVRAM. For pages stored in NVRAM, if one is hit by a write request, it will be migrated from NVRAM to DRAM. At this time when DRAM is full, CLOCK-DWF will select a victim page that has the lowest number of writes or that has not been accessed for the longest period of time in DRAM to be evicted.\nDouble LRU [20]. Double LRU recognizes the high migration cost between NVRAM and DRAM, and tries to restrict the number of page migrations by setting some threshold. It uses two separate LRU linked lists to manage pages in DRAM and NVRAM. For each page in NVRAM, it maintains a read/write request count. When a page is accessed, Double LRU checks its read/write request count, and if the count reaches a certain threshold, it will be migrated from NVRAM to DRAM; otherwise, it will remain in NVRAM. In DRAM, the page at the end of the LRU list is always selected as the victim. For new pages, Double LRU stores them directly in DRAM, assuming new pages will be accessed frequently in the near future. regardless of the read or write requests.")]),e._v(" "),t("img",{attrs:{src:"https://github.com/hitqshao/qishao-notes/assets/23403286/ce0ed6ce-164f-4d40-b088-0060b4c3de7a",alt:" ",width:"300"}}),e._v(" "),t("p",[e._v("UIMigrate consists of three parts: unified hot page identification, page migration, and self-adaptive adjustment.")]),e._v(" "),t("p",[e._v("To consider both the number of accesses and access time,we add the attenuation factor to quantify the hotness of each page, hoping to quickly reduce the access counts for pages that are accessed a long time ago. Thus, while updating page hotness upon each access, UIMigrate also uses an attenuation coefficient to lower the page popularity of old accesses.")]),e._v(" "),t("p",[e._v("If all DRAM pages should be accessed in one cycle, (acc_count.global-acc.countpage)/DRAMsize denotes the number of cycles the page that has not been accessed.")]),e._v(" "),t("p",[e._v("the attenuation coefficient d is closely related to the value of hotold and the number of cycles the page that has not been accessed since last time.")]),e._v(" "),t("img",{attrs:{src:"https://github.com/hitqshao/qishao-notes/assets/23403286/81ee2ea8-9abb-43b0-a69f-dccebe4cbc3e",alt:" ",width:"300"}}),e._v(" "),t("p",[e._v("UIMigrate sets a threshold, called new page threshold, to measure the hotness of each victim page. When the quantified hotness of a selected victim is larger than the preset threshold, it means that this victim page is too hot to be evicted, and so UIMigrate will store the new page in NVRAM. Otherwise, it will be migrated to DRAM.")]),e._v(" "),t("p",[e._v("In order to effectively adapt to the change of access patterns, UIMigrate adjusts migration thresholds (new page threshold, hot page threshold and cold page threshold) automatically to promote or suppress the page migrations, according to real-time migration revenue.")]),e._v(" "),t("img",{attrs:{src:"https://github.com/hitqshao/qishao-notes/assets/23403286/d31942fa-876d-4eec-a2db-69d0d55ef0cb",alt:" ",width:"300"}}),e._v(" "),t("p",[e._v("When they are evicted from DRAM, UIMigrate calculates the migration revenue based on Equations (3) and (4).\nIf the migration revenue is below zero, it means that the migration cost is greater than the benefit. In this case, UIMigrate will increase hot page threshold to prevent certain pages from getting hot in NVRAM and decrease cold page threshold to prevent some pages from becoming cold in DRAM, thus retaining more pages in NVRAM. For new pages, UIMigrate will also reduce new page threshold, so that more new pages will go to NVRAM instead of DRAM. When the calculated migration benefit is larger than the migration cost, UIMigare will reduce hot page threshold and increase cold page threshold to make migrate more pages to DRAM, and increase new page threshold to keep more new pages in DRAM.")]),e._v(" "),t("h4",{attrs:{id:"_4-page-placement-in-hybrid-memory-systems"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_4-page-placement-in-hybrid-memory-systems"}},[e._v("#")]),e._v(" 4. Page Placement in Hybrid Memory Systems")]),e._v(" "),t("p",[e._v("Given the characteristics of DRAM and PCM, RaPP seeks to\n(1) place performance-critical pages and frequently written pages in DRAM\n(2) place non-critical pages and rarely written pages in PCM\n(3) spread writes to PCM across many physical frames.")]),e._v(" "),t("p",[e._v("Using this information, RaPP dynamically ranks frames based on frequency and recency of accesses, as detailed below. Frames that rank high are called “popular”, and frames that rank low are called “unpopular”.")]),e._v(" "),t("h5",{attrs:{id:"algorithm"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#algorithm"}},[e._v("#")]),e._v(" Algorithm")]),e._v(" "),t("ol",[t("li",[e._v("The descriptors in queue M − 1 represent the blocks that are most frequently used. On the first access to a block, its descriptor is placed in the tail of queue 0.")]),e._v(" "),t("li",[e._v("In addition, the block’s expiration time ExpirationTime is set to CurrentTime + LifeTime, where both times are measured in number of accesses and LifeT ime specifies the number of consecutive accesses that n must directed to other blocks before we expire the block.")]),e._v(" "),t("li",[e._v("Every time the block is accessed, its reference counter is incremented, its expiration time is reset to CurrentT ime + LifeT ime, and its descriptor is moved to the tail of its current queue.")]),e._v(" "),t("li",[e._v("The descriptor of a frequently used block is promoted to a higher queue (saturating at queue M − 1, of course) after a certain number of accesses to the block.")]),e._v(" "),t("li",[e._v("Specifically, if the descriptor is currently in queue i, it will be upgraded to queue i + 1 when its reference counter reaches 2i+1.")]),e._v(" "),t("li",[e._v("Conversely, MQ demotes blocks that have not been accessed recently. On each access, the descriptors at the heads of all M queues (representing the LRU block of each queue) are checked for expiration (CurrentT ime > ExpirationTime).")])]),e._v(" "),t("p",[e._v("If a block descriptor expires, it is placed at the tail of the immediately inferior queue, and has its expiration time again set to CurrentTime + LifeTime.")]),e._v(" "),t("img",{attrs:{src:"https://github.com/hitqshao/qishao-notes/assets/23403286/2da2a0b8-2914-41fd-b9c4-1815cfe898ff",alt:"System",width:"600"}}),e._v(" "),t("p",[e._v("First,instead of counting all accesses, we only count an access if it occurs more than a threshold time (measured in memory cycles) after the last access to the same frame. This latter threshold is called the “filter threshold”. The MC stores the time of the last access in the descriptor for the frame. Using a 2-competitive approach, we set the filter threshold to be MigrationCost/MigrationThreshold, where MigrationCost is the uncontended number of memory cycles needed to migrate a page. (MigrationCost is roughly 1.6µs in our experiments.)")]),e._v(" "),t("p",[e._v("Second, we modified the demotion policy in the following ways:\n(a) we use time, not number of accesses, as the metric for demotion to reduce space requirements (in our experiments, we set LifeT ime to 100µs, which works well for our workloads);\n(b) we only demote from one queue at a time (in round-robin fashion) to reduce runtime overhead;\n(c) a DRAM frame that is demoted twice without any intervening accesses leaves the MQ queues and becomes a candidate to receive a popular PCM page.")]),e._v(" "),t("p",[e._v("To select a destination DRAM frame for a page, the MC maintains an LRU list of victim DRAM frames. The victim frames are not in any of the LRU queues (the list is initialized with all DRAM frames).")]),e._v(" "),t("p",[e._v("To effect a page migration to DRAM, the MC (1) migrates the page stored in the selected DRAM frame to one of the unranked PCM frames, (2) migrates the content of this latter frame to the most popular PCM frame, and finally (3) migrates the content of the most popular PCM frame to the selected DRAM frame.")]),e._v(" "),t("h3",{attrs:{id:"me"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#me"}},[e._v("#")]),e._v(" Me")]),e._v(" "),t("p",[e._v("Why swap 3 time? not 2?")])])}),[],!1,null,null,null);t.default=r.exports}}]);
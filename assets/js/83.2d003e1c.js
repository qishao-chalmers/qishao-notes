(window.webpackJsonp=window.webpackJsonp||[]).push([[83],{537:function(e,a,t){"use strict";t.r(a);var s=t(9),i=Object(s.a)({},(function(){var e=this,a=e._self._c;return a("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[a("ol",[a("li",[e._v("[22] Adaptive Memory-Side Last-Level GPU Caching")]),e._v(" "),a("li",[e._v("[83 2015] Locality-Driven Dynamic GPU Cache Bypassing")])]),e._v(" "),a("hr"),e._v(" "),a("h2",{attrs:{id:"_1-22-adaptive-memory-side-last-level-gpu-caching"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_1-22-adaptive-memory-side-last-level-gpu-caching"}},[e._v("#")]),e._v(" 1. [22] Adaptive Memory-Side Last-Level GPU Caching")]),e._v(" "),a("ul",[a("li",[e._v("Private LLCs, which replicate shared data across multiple slices, provide higher bandwidth but suffer from higher miss rates.")]),e._v(" "),a("li",[e._v("Shared LLCs avoid redundancy, reducing miss rates, but suffer bandwidth contention under high sharing.")])]),e._v(" "),a("p",[a("img",{attrs:{src:"https://github.com/user-attachments/assets/fe7ab2e6-f43a-4881-b154-0782bb84bafc",alt:"image"}})]),e._v(" "),a("p",[e._v("In the shared LLC organization, an LLC slice is shared by all SMs.")]),e._v(" "),a("p",[e._v("The LLC slice for a given cache line is determined by a few address bits.")]),e._v(" "),a("p",[e._v("Collectively, all LLC slices associated with a given memory controller cache the entire memory address space served by the memory controller.")]),e._v(" "),a("p",[e._v("In the private LLC organization, an LLC slice is private to a cluster of SMs.")]),e._v(" "),a("p",[e._v("An LLC slice caches the entire memory partition served by the respective memory controller for only a single cluster of SMs.")]),e._v(" "),a("p",[e._v("The LLC slice for a cache line is thus determined by the cluster ID.")]),e._v(" "),a("p",[a("img",{attrs:{src:"https://github.com/user-attachments/assets/86193f2f-2ad3-45c3-a78d-4b4c79db370d",alt:"image"}})]),e._v(" "),a("h3",{attrs:{id:"dynamic-reconfiguration-rules"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#dynamic-reconfiguration-rules"}},[e._v("#")]),e._v(" Dynamic Reconfiguration Rules")]),e._v(" "),a("ul",[a("li",[e._v("Switch to private if:\n"),a("ul",[a("li",[e._v("Miss rate remains comparable (within 2%)")]),e._v(" "),a("li",[e._v("Bandwidth gain outweighs miss rate penalty")])])]),e._v(" "),a("li",[e._v("Revert to shared:\n"),a("ul",[a("li",[e._v("At new kernel or time epoch")])])])]),e._v(" "),a("p",[e._v("How to profile/")]),e._v(" "),a("p",[e._v("Set Dueling")]),e._v(" "),a("hr"),e._v(" "),a("h2",{attrs:{id:"_2-83-2015-locality-driven-dynamic-gpu-cache-bypassing"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_2-83-2015-locality-driven-dynamic-gpu-cache-bypassing"}},[e._v("#")]),e._v(" 2. [83 2015] Locality-Driven Dynamic GPU Cache Bypassing")]),e._v(" "),a("h3",{attrs:{id:"categories-of-applications"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#categories-of-applications"}},[e._v("#")]),e._v(" Categories of Applications")]),e._v(" "),a("p",[e._v("The paper classifies GPU applications into three categories based on how they benefit (or suffer) from the L1 D-cache:")]),e._v(" "),a("h4",{attrs:{id:"_1-cache-unfriendly-cnf"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_1-cache-unfriendly-cnf"}},[e._v("#")]),e._v(" 1. Cache-Unfriendly (CNF)")]),e._v(" "),a("p",[e._v("Definition: Applications that perform better when L1 D-cache is bypassed.")]),e._v(" "),a("p",[e._v("Cause:")]),e._v(" "),a("ul",[a("li",[e._v("Low data reuse.")]),e._v(" "),a("li",[e._v("Long reuse distances.")])]),e._v(" "),a("p",[e._v("Leads to cache pollution and resource contention.")]),e._v(" "),a("p",[e._v("Impact:")]),e._v(" "),a("ul",[a("li",[e._v("Memory pipeline stalls.")]),e._v(" "),a("li",[e._v("Unnecessary eviction of useful lines.")])]),e._v(" "),a("p",[e._v("Examples:")]),e._v(" "),a("ul",[a("li",[e._v("NW, SD2, LUD, HS, PTF, BH, SSSP")])]),e._v(" "),a("p",[e._v("Performance gain: Up to 36% IPC improvement by bypassing L1.")]),e._v(" "),a("h4",{attrs:{id:"_2-cache-insensitive-ci"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_2-cache-insensitive-ci"}},[e._v("#")]),e._v(" 2. Cache-Insensitive (CI)")]),e._v(" "),a("p",[e._v("Definition: Applications for which enabling/disabling L1 D-cache has little to no effect.")]),e._v(" "),a("p",[e._v("Cause:")]),e._v(" "),a("ul",[a("li",[e._v("Heavy use of shared memory.")]),e._v(" "),a("li",[e._v("Minimal or no global memory accesses.")])]),e._v(" "),a("p",[e._v("Low memory intensity or high control divergence.")]),e._v(" "),a("p",[e._v("Impact:")]),e._v(" "),a("ul",[a("li",[e._v("Cache behavior does not affect IPC.")])]),e._v(" "),a("p",[e._v("Examples:")]),e._v(" "),a("ul",[a("li",[e._v("CFD, MYC, FFT, GS, PF, LFK")])]),e._v(" "),a("h4",{attrs:{id:"_3-cache-friendly-cf"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_3-cache-friendly-cf"}},[e._v("#")]),e._v(" 3. Cache-Friendly (CF)")]),e._v(" "),a("p",[e._v("Definition: Applications that benefit from L1 D-cache.")]),e._v(" "),a("p",[e._v("Cause:")]),e._v(" "),a("ul",[a("li",[e._v("High data reuse.")]),e._v(" "),a("li",[e._v("Short reuse distances.")])]),e._v(" "),a("p",[e._v("Impact:")]),e._v(" "),a("ul",[a("li",[e._v("Disabling L1 severely degrades performance.")])]),e._v(" "),a("p",[e._v("Examples:")]),e._v(" "),a("ul",[a("li",[e._v("MM, HT, SD1, BT, BP")])]),e._v(" "),a("p",[e._v("Performance loss: Up to 77% IPC drop when bypassed.")]),e._v(" "),a("ul",[a("li",[e._v("🔁 Reuse Behavior Analysis")]),e._v(" "),a("li",[e._v("🔢 Reuse Count")])]),e._v(" "),a("p",[e._v("What it shows: Number of times a memory address is reused.")]),e._v(" "),a("p",[e._v("Observation:")]),e._v(" "),a("ul",[a("li",[e._v("CNF apps have few high-reuse accesses.")]),e._v(" "),a("li",[e._v("Example: >60% of accesses in NW, LUD are reused fewer than 3 times.")])]),e._v(" "),a("h4",{attrs:{id:"📏-reuse-distance-figure-4"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#📏-reuse-distance-figure-4"}},[e._v("#")]),e._v(" 📏 Reuse Distance (Figure 4)")]),e._v(" "),a("p",[e._v("Definition: The number of unique memory accesses between two accesses to the same address.")]),e._v(" "),a("p",[e._v("Example: Pattern A–B–C–A → reuse distance = 2.")]),e._v(" "),a("p",[e._v("Observation:")]),e._v(" "),a("ul",[a("li",[e._v("CNF apps have long reuse distances: often 512–2048.")])]),e._v(" "),a("p",[a("strong",[e._v("These accesses cannot fit in L1 (e.g., 128B lines × 512 = 64KB).")])]),e._v(" "),a("p",[e._v("🧠 L1 vs. L2 Cache Bottlenecks\nExperimental Setup (Figure 2)")]),e._v(" "),a("ul",[a("li",[e._v("The authors increase associativity and capacity of both L1 and L2 caches.")])]),e._v(" "),a("p",[e._v("Findings:")]),e._v(" "),a("p",[a("img",{attrs:{src:"https://github.com/user-attachments/assets/4dc6d668-e824-43ee-b0fd-ca229beb6ced",alt:"image"}})]),e._v(" "),a("p",[e._v("Cache Level\tObservation for CNF Apps")]),e._v(" "),a("ul",[a("li",[e._v("L2\tPerformance is insensitive to L2 size and associativity. L2 is not a bottleneck.")]),e._v(" "),a("li",[e._v("L1\tPerformance improves with larger/more associative L1. But needs impractically large L1 (e.g., 128-way, 16MB) to be effective. Still insufficient for some apps.")])]),e._v(" "),a("p",[e._v("Conclusion: "),a("strong",[e._v("The L1 D-cache is the performance bottleneck for CNF workloads, not L2.")])]),e._v(" "),a("h3",{attrs:{id:"bypassing-logic"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#bypassing-logic"}},[e._v("#")]),e._v(" Bypassing logic")]),e._v(" "),a("ul",[a("li",[e._v("On a tag store miss → insert into tag store with RC = 1 → bypass data store.")]),e._v(" "),a("li",[e._v("On subsequent hits:\n"),a("ul",[a("li",[e._v("RC incremented.")]),e._v(" "),a("li",[e._v("If RC > threshold (e.g., 2), allocate data in the data store.")])])]),e._v(" "),a("li",[e._v("Replacement:\n"),a("ul",[a("li",[e._v("Tag store uses LFU with aging (decays RC to evict stale entries).")])])]),e._v(" "),a("li",[e._v("Data store uses existing GPU policies like LRU, RRIP.")])]),e._v(" "),a("p",[a("img",{attrs:{src:"https://github.com/user-attachments/assets/01bb388a-a287-4514-b5b6-a628fc2453c2",alt:"image"}})]),e._v(" "),a("h3",{attrs:{id:"📊-summary-table"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#📊-summary-table"}},[e._v("#")]),e._v(" 📊 Summary Table")]),e._v(" "),a("p",[e._v("Category\tBehavior\tReuse Count\tReuse Distance\tL1 Role\tL2 Role")]),e._v(" "),a("ul",[a("li",[e._v("CNF\tCache hurts\tMostly low (1–2)\tLong (512–2048)\tBottleneck, polluted\tNot bottleneck")]),e._v(" "),a("li",[e._v("CI\tCache irrelevant\tN/A\tN/A\tIrrelevant\tIrrelevant")]),e._v(" "),a("li",[e._v("CF\tCache helps\tHigh\tShort\tCritical\tLess relevant")])]),e._v(" "),a("h3",{attrs:{id:"🧠-design-implications"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#🧠-design-implications"}},[e._v("#")]),e._v(" 🧠 Design Implications")]),e._v(" "),a("ul",[a("li",[e._v("L1 D-cache should selectively cache data.")]),e._v(" "),a("li",[e._v("A naive insert-everything policy causes: Thrashing in CNF apps.")]),e._v(" "),a("li",[e._v("Performance degradation in CF apps if cache is bypassed.")])]),e._v(" "),a("p",[e._v("The paper proposes a reuse-aware dynamic bypass mechanism that:")]),e._v(" "),a("ul",[a("li",[e._v("Tracks Reference Count (RC).")]),e._v(" "),a("li",[e._v("Filters accesses based on reuse patterns.")])]),e._v(" "),a("p",[e._v("Add extra information in the tag. But not the data.")]),e._v(" "),a("p",[a("img",{attrs:{src:"https://github.com/user-attachments/assets/192f1f93-4aa2-4957-a8b8-fe96ffacc85f",alt:"image"}})])])}),[],!1,null,null,null);a.default=i.exports}}]);